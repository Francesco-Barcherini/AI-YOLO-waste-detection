{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41668032",
   "metadata": {},
   "source": [
    "# Comprehensive Training Pipeline\n",
    "\n",
    "1. **1**: Train YOLO11n on all folds of `datasets/k_fold_cv`\n",
    "2. **2**: Train YOLO11n, s, and m on all folds of `datasets/k_fold_cv_augmented`\n",
    "3. **3**: Train YOLO11l and x on first fold of `datasets/k_fold_cv_augmented`\n",
    "4. **4**: Train RT-DETR-l and x on first fold of `datasets/k_fold_cv_augmented`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c748f420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in ./.venv/lib/python3.11/site-packages (8.3.167)\n",
      "Requirement already satisfied: torch in ./.venv/lib/python3.11/site-packages (2.7.1)\n",
      "Requirement already satisfied: torch in ./.venv/lib/python3.11/site-packages (2.7.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in ./.venv/lib/python3.11/site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: py-cpuinfo in ./.venv/lib/python3.11/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in ./.venv/lib/python3.11/site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in ./.venv/lib/python3.11/site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: scipy>=1.4.1 in ./.venv/lib/python3.11/site-packages (from ultralytics) (1.16.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in ./.venv/lib/python3.11/site-packages (from ultralytics) (2.32.4)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in ./.venv/lib/python3.11/site-packages (from ultralytics) (0.22.1)\n",
      "Requirement already satisfied: pandas>=1.1.4 in ./.venv/lib/python3.11/site-packages (from ultralytics) (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.23.0 in ./.venv/lib/python3.11/site-packages (from ultralytics) (2.2.6)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in ./.venv/lib/python3.11/site-packages (from ultralytics) (3.10.3)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in ./.venv/lib/python3.11/site-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: py-cpuinfo in ./.venv/lib/python3.11/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in ./.venv/lib/python3.11/site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in ./.venv/lib/python3.11/site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: scipy>=1.4.1 in ./.venv/lib/python3.11/site-packages (from ultralytics) (1.16.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in ./.venv/lib/python3.11/site-packages (from ultralytics) (2.32.4)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in ./.venv/lib/python3.11/site-packages (from ultralytics) (0.22.1)\n",
      "Requirement already satisfied: pandas>=1.1.4 in ./.venv/lib/python3.11/site-packages (from ultralytics) (2.3.1)\n",
      "Requirement already satisfied: numpy>=1.23.0 in ./.venv/lib/python3.11/site-packages (from ultralytics) (2.2.6)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in ./.venv/lib/python3.11/site-packages (from ultralytics) (3.10.3)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.11/site-packages (from ultralytics) (7.0.0)\n",
      "Requirement already satisfied: pillow>=7.1.2 in ./.venv/lib/python3.11/site-packages (from ultralytics) (11.3.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in ./.venv/lib/python3.11/site-packages (from ultralytics) (4.12.0.88)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.11/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in ./.venv/lib/python3.11/site-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in ./.venv/lib/python3.11/site-packages (from torch) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in ./.venv/lib/python3.11/site-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in ./.venv/lib/python3.11/site-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.11/site-packages (from ultralytics) (7.0.0)\n",
      "Requirement already satisfied: pillow>=7.1.2 in ./.venv/lib/python3.11/site-packages (from ultralytics) (11.3.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in ./.venv/lib/python3.11/site-packages (from ultralytics) (4.12.0.88)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.11/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in ./.venv/lib/python3.11/site-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in ./.venv/lib/python3.11/site-packages (from torch) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in ./.venv/lib/python3.11/site-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in ./.venv/lib/python3.11/site-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.1 in ./.venv/lib/python3.11/site-packages (from torch) (3.3.1)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.11/site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in ./.venv/lib/python3.11/site-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in ./.venv/lib/python3.11/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in ./.venv/lib/python3.11/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in ./.venv/lib/python3.11/site-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in ./.venv/lib/python3.11/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in ./.venv/lib/python3.11/site-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in ./.venv/lib/python3.11/site-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in ./.venv/lib/python3.11/site-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.11/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.11/site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in ./.venv/lib/python3.11/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in ./.venv/lib/python3.11/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: triton==3.3.1 in ./.venv/lib/python3.11/site-packages (from torch) (3.3.1)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.11/site-packages (from torch) (2025.5.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in ./.venv/lib/python3.11/site-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in ./.venv/lib/python3.11/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in ./.venv/lib/python3.11/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in ./.venv/lib/python3.11/site-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in ./.venv/lib/python3.11/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in ./.venv/lib/python3.11/site-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in ./.venv/lib/python3.11/site-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in ./.venv/lib/python3.11/site-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.11/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.11/site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in ./.venv/lib/python3.11/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in ./.venv/lib/python3.11/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in ./.venv/lib/python3.11/site-packages (from triton==3.3.1->torch) (59.6.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (4.58.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in ./.venv/lib/python3.11/site-packages (from triton==3.3.1->torch) (59.6.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (4.58.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.11/site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (2025.7.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.11/site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (2025.7.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install -U ultralytics torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f4a2a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 2.7.1+cu126 | CUDA: 12.6 | Device count: 1\n",
      "GPU: Tesla T4\n",
      "RAM: 270.0 GB\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import os\n",
    "import yaml\n",
    "import json\n",
    "import datetime\n",
    "import psutil\n",
    "from ultralytics import YOLO, RTDETR\n",
    "from pathlib import Path\n",
    "\n",
    "print('Torch:', torch.__version__, '| CUDA:', torch.version.cuda, '| Device count:', torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print('GPU:', torch.cuda.get_device_name(0))\n",
    "print('RAM:', f'{psutil.virtual_memory().total/1e9:.1f} GB')\n",
    "\n",
    "# Enable CUDNN benchmarking for faster training\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cd3ab76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration and helper functions loaded!\n"
     ]
    }
   ],
   "source": [
    "# Configuration and Helper Functions\n",
    "\n",
    "class TrainingConfig:\n",
    "    \"\"\"Configuration class for training parameters\"\"\"\n",
    "    \n",
    "    # Dataset paths - using absolute paths\n",
    "    K_FOLD_CV_PATH = \"/home/andrea/work/AI-waste-detection/datasets/k_fold_cv\"\n",
    "    K_FOLD_CV_AUGMENTED_PATH = \"/home/andrea/work/AI-waste-detection/datasets/k_fold_cv_augmented\"\n",
    "    \n",
    "    # Training parameters\n",
    "    EPOCHS = 100\n",
    "    PATIENCE = 20\n",
    "    IMGSZ = 640\n",
    "    BATCH_SIZE = 32\n",
    "    WORKERS = 8\n",
    "    \n",
    "    # Model configurations\n",
    "    YOLO_MODELS = {\n",
    "        'yolo11n': 'yolo11n.pt',\n",
    "        'yolo11s': 'yolo11s.pt', \n",
    "        'yolo11m': 'yolo11m.pt',\n",
    "        'yolo11l': 'yolo11l.pt',\n",
    "        'yolo11x': 'yolo11x.pt'\n",
    "    }\n",
    "    \n",
    "    RTDETR_MODELS = {\n",
    "        'rtdetr-l': 'rtdetr-l.pt',\n",
    "        'rtdetr-x': 'rtdetr-x.pt'\n",
    "    }\n",
    "\n",
    "def get_training_params(model_size):\n",
    "    \"\"\"Get training parameters based on model size\"\"\"\n",
    "    base_params = {\n",
    "        'epochs': TrainingConfig.EPOCHS,\n",
    "        'imgsz': TrainingConfig.IMGSZ,\n",
    "        'patience': TrainingConfig.PATIENCE,\n",
    "        'amp': True,\n",
    "        'optimizer': 'AdamW',\n",
    "        'save_period': 10,\n",
    "        'workers': TrainingConfig.WORKERS,\n",
    "        'cache': True,\n",
    "        'half': True,\n",
    "        'pretrained': True,\n",
    "        'lr0': 1e-4,\n",
    "        'lrf': 0.01,\n",
    "        'momentum': 0.937,\n",
    "        'weight_decay': 1e-4,\n",
    "        'augment': False\n",
    "    }\n",
    "    \n",
    "    # Adjust batch size based on model size\n",
    "    if model_size in ['yolo11n', 'yolo11s']:\n",
    "        base_params['batch'] = 32\n",
    "    elif model_size in ['yolo11m', 'rtdetr-l']:\n",
    "        base_params['batch'] = 16\n",
    "    elif model_size in ['yolo11l', 'yolo11x', 'rtdetr-x']:\n",
    "        base_params['batch'] = 8\n",
    "    \n",
    "    return base_params\n",
    "\n",
    "def save_results(results, filename):\n",
    "    \"\"\"Save training results to JSON file\"\"\"\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filepath = f\"training_results_{filename}_{timestamp}.json\"\n",
    "    \n",
    "    with open(filepath, 'w') as f:\n",
    "        json.dump(results, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"Results saved to: {filepath}\")\n",
    "    return filepath\n",
    "\n",
    "def train_model(model_type, model_name, data_yaml, fold_idx, experiment_name, project_dir=\"runs\"):\n",
    "    \"\"\"Train a single model on a specific fold\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Training {model_name} on Fold {fold_idx}\")\n",
    "    print(f\"Data: {data_yaml}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    try:\n",
    "        # Load model\n",
    "        if model_type == 'yolo':\n",
    "            model_path = TrainingConfig.YOLO_MODELS[model_name]\n",
    "            model = YOLO(model_path)\n",
    "        elif model_type == 'rtdetr':\n",
    "            model_path = TrainingConfig.RTDETR_MODELS[model_name]\n",
    "            model = RTDETR(model_path)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "        \n",
    "        # Get training parameters\n",
    "        train_params = get_training_params(model_name)\n",
    "        \n",
    "        # Set training-specific parameters\n",
    "        train_params.update({\n",
    "            'data': data_yaml,\n",
    "            'name': f\"{model_name}_fold_{fold_idx}\",\n",
    "            'project': f\"{project_dir}/{experiment_name}\"\n",
    "        })\n",
    "        \n",
    "        print(f\"Training parameters: {train_params}\")\n",
    "        \n",
    "        # Train the model\n",
    "        results = model.train(**train_params)\n",
    "        \n",
    "        # Extract metrics\n",
    "        fold_result = {\n",
    "            'model_type': model_type,\n",
    "            'model_name': model_name,\n",
    "            'fold': fold_idx,\n",
    "            'status': 'completed',\n",
    "            'best_epoch': results.best_epoch if hasattr(results, 'best_epoch') else None,\n",
    "            'best_fitness': results.best_fitness if hasattr(results, 'best_fitness') else None,\n",
    "            'model_path': model.ckpt_path if hasattr(model, 'ckpt_path') else None,\n",
    "            'experiment_name': experiment_name,\n",
    "            'data_yaml': data_yaml,\n",
    "            'training_params': train_params\n",
    "        }\n",
    "        \n",
    "        print(f\"\\n✅ {model_name} Fold {fold_idx} completed successfully!\")\n",
    "        print(f\"Best epoch: {fold_result['best_epoch']}\")\n",
    "        print(f\"Best fitness: {fold_result['best_fitness']:.4f}\" if fold_result['best_fitness'] else \"Best fitness: N/A\")\n",
    "        print(f\"Model saved: {fold_result['model_path']}\")\n",
    "        \n",
    "        return fold_result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error training {model_name} on fold {fold_idx}: {str(e)}\")\n",
    "        return {\n",
    "            'model_type': model_type,\n",
    "            'model_name': model_name,\n",
    "            'fold': fold_idx,\n",
    "            'status': 'failed',\n",
    "            'error': str(e),\n",
    "            'experiment_name': experiment_name,\n",
    "            'data_yaml': data_yaml\n",
    "        }\n",
    "\n",
    "print(\"Configuration and helper functions loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c13d56ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "DATASET VERIFICATION\n",
      "====================================================================================================\n",
      "\n",
      "📁 Verifying k_fold_cv: /home/andrea/work/AI-waste-detection/datasets/k_fold_cv\n",
      "  ✅ Fold 0: Train=3488, Val=873, Total=4361\n",
      "  ✅ Fold 1: Train=3489, Val=872, Total=4361\n",
      "  ✅ Fold 2: Train=3489, Val=872, Total=4361\n",
      "  ✅ Fold 3: Train=3489, Val=872, Total=4361\n",
      "  ✅ Fold 4: Train=3489, Val=872, Total=4361\n",
      "\n",
      "📁 Verifying k_fold_cv_augmented: /home/andrea/work/AI-waste-detection/datasets/k_fold_cv_augmented\n",
      "  ✅ Fold 0: Train=12864, Val=3217, Total=16081\n",
      "  ✅ Fold 1: Train=12865, Val=3216, Total=16081\n",
      "  ✅ Fold 2: Train=12865, Val=3216, Total=16081\n",
      "  ✅ Fold 3: Train=12865, Val=3216, Total=16081\n",
      "  ✅ Fold 4: Train=12865, Val=3216, Total=16081\n",
      "\n",
      "📊 VERIFICATION SUMMARY:\n",
      "k_fold_cv: ✅ Valid\n",
      "k_fold_cv_augmented: ✅ Valid\n",
      "\n",
      "🚀 All datasets verified! Ready to start training pipeline.\n"
     ]
    }
   ],
   "source": [
    "# Verify Dataset Structure\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"DATASET VERIFICATION\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "def verify_dataset_structure(dataset_path, dataset_name):\n",
    "    \"\"\"Verify the structure of a k-fold dataset\"\"\"\n",
    "    print(f\"\\n📁 Verifying {dataset_name}: {dataset_path}\")\n",
    "    \n",
    "    if not os.path.exists(dataset_path):\n",
    "        print(f\"❌ Dataset path not found: {dataset_path}\")\n",
    "        return False\n",
    "    \n",
    "    all_folds_valid = True\n",
    "    \n",
    "    for fold_idx in range(5):\n",
    "        fold_dir = os.path.join(dataset_path, f\"fold_{fold_idx}\")\n",
    "        data_yaml = os.path.join(fold_dir, \"data.yaml\")\n",
    "        \n",
    "        if os.path.exists(data_yaml):\n",
    "            # Count images in train and val\n",
    "            train_images = os.path.join(fold_dir, \"train\", \"images\")\n",
    "            val_images = os.path.join(fold_dir, \"val\", \"images\")\n",
    "            \n",
    "            train_count = len([f for f in os.listdir(train_images) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]) if os.path.exists(train_images) else 0\n",
    "            val_count = len([f for f in os.listdir(val_images) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]) if os.path.exists(val_images) else 0\n",
    "            \n",
    "            total = train_count + val_count\n",
    "            \n",
    "            if total > 0:\n",
    "                print(f\"  ✅ Fold {fold_idx}: Train={train_count}, Val={val_count}, Total={total}\")\n",
    "            else:\n",
    "                print(f\"  ❌ Fold {fold_idx}: No images found\")\n",
    "                all_folds_valid = False\n",
    "        else:\n",
    "            print(f\"  ❌ Fold {fold_idx}: data.yaml not found\")\n",
    "            all_folds_valid = False\n",
    "    \n",
    "    return all_folds_valid\n",
    "\n",
    "# Verify both datasets\n",
    "k_fold_cv_valid = verify_dataset_structure(TrainingConfig.K_FOLD_CV_PATH, \"k_fold_cv\")\n",
    "k_fold_cv_augmented_valid = verify_dataset_structure(TrainingConfig.K_FOLD_CV_AUGMENTED_PATH, \"k_fold_cv_augmented\")\n",
    "\n",
    "print(f\"\\n📊 VERIFICATION SUMMARY:\")\n",
    "print(f\"k_fold_cv: {'✅ Valid' if k_fold_cv_valid else '❌ Issues found'}\")\n",
    "print(f\"k_fold_cv_augmented: {'✅ Valid' if k_fold_cv_augmented_valid else '❌ Issues found'}\")\n",
    "\n",
    "if k_fold_cv_valid and k_fold_cv_augmented_valid:\n",
    "    print(f\"\\n🚀 All datasets verified! Ready to start training pipeline.\")\n",
    "else:\n",
    "    print(f\"\\n⚠️ Please fix dataset issues before proceeding with training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c383ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "STAGE 1: Training YOLO11n on all folds of k_fold_cv\n",
      "====================================================================================================\n",
      "📁 Dataset path: /home/andrea/work/AI-waste-detection/datasets/k_fold_cv\n",
      "\n",
      "================================================================================\n",
      "Training yolo11n on Fold 0\n",
      "Data: /home/andrea/work/AI-waste-detection/datasets/k_fold_cv/fold_0/data.yaml\n",
      "================================================================================\n",
      "Training parameters: {'epochs': 100, 'imgsz': 640, 'patience': 20, 'amp': True, 'optimizer': 'AdamW', 'save_period': 10, 'workers': 8, 'cache': True, 'half': True, 'pretrained': True, 'lr0': 0.0001, 'lrf': 0.01, 'momentum': 0.937, 'weight_decay': 0.0001, 'augment': False, 'batch': 32, 'data': '/home/andrea/work/AI-waste-detection/datasets/k_fold_cv/fold_0/data.yaml', 'name': 'yolo11n_fold_0', 'project': 'runs/stage1_yolo11n_k_fold_cv'}\n",
      "Ultralytics 8.3.167 🚀 Python-3.11.0rc1 torch-2.7.1+cu126 CUDA:0 (Tesla T4, 14914MiB)\n",
      "Training parameters: {'epochs': 100, 'imgsz': 640, 'patience': 20, 'amp': True, 'optimizer': 'AdamW', 'save_period': 10, 'workers': 8, 'cache': True, 'half': True, 'pretrained': True, 'lr0': 0.0001, 'lrf': 0.01, 'momentum': 0.937, 'weight_decay': 0.0001, 'augment': False, 'batch': 32, 'data': '/home/andrea/work/AI-waste-detection/datasets/k_fold_cv/fold_0/data.yaml', 'name': 'yolo11n_fold_0', 'project': 'runs/stage1_yolo11n_k_fold_cv'}\n",
      "Ultralytics 8.3.167 🚀 Python-3.11.0rc1 torch-2.7.1+cu126 CUDA:0 (Tesla T4, 14914MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/home/andrea/work/AI-waste-detection/datasets/k_fold_cv/fold_0/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=True, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo11n_fold_0, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/stage1_yolo11n_k_fold_cv, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/stage1_yolo11n_k_fold_cv/yolo11n_fold_0, save_frames=False, save_json=False, save_period=10, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/home/andrea/work/AI-waste-detection/datasets/k_fold_cv/fold_0/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=True, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo11n_fold_0, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/stage1_yolo11n_k_fold_cv, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/stage1_yolo11n_k_fold_cv/yolo11n_fold_0, save_frames=False, save_json=False, save_period=10, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    431647  ultralytics.nn.modules.head.Detect           [5, [64, 128, 256]]           \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    431647  ultralytics.nn.modules.head.Detect           [5, [64, 128, 256]]           \n",
      "YOLO11n summary: 181 layers, 2,590,815 parameters, 2,590,799 gradients, 6.4 GFLOPs\n",
      "\n",
      "YOLO11n summary: 181 layers, 2,590,815 parameters, 2,590,799 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1106.2±890.8 MB/s, size: 32.7 KB)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1106.2±890.8 MB/s, size: 32.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/andrea/work/AI-waste-detection/datasets/k_fold_cv/fold_0/train/labels.cache... 3488 images, \u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (3.0GB RAM): 100%|██████████| 3488/3488 [00:00<00:00, 4155.41it/s]\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 582.2±304.6 MB/s, size: 22.6 KB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 582.2±304.6 MB/s, size: 22.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/andrea/work/AI-waste-detection/datasets/k_fold_cv/fold_0/val/labels.cache... 873 images, 0 bac\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.8GB RAM): 100%|██████████| 873/873 [00:00<00:00, 3904.12it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.8GB RAM): 100%|██████████| 873/873 [00:00<00:00, 3904.12it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/stage1_yolo11n_k_fold_cv/yolo11n_fold_0/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0001, momentum=0.937) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0001), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/stage1_yolo11n_k_fold_cv/yolo11n_fold_0\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0001, momentum=0.937) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0001), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/stage1_yolo11n_k_fold_cv/yolo11n_fold_0\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100      4.35G      1.149      2.415      1.486        131        640:  99%|█████████▉| 108/109 [00:35<00:\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     19\u001b[39m data_yaml = os.path.join(fold_dir, \u001b[33m\"\u001b[39m\u001b[33mdata.yaml\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m os.path.exists(data_yaml):\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     result = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43myolo\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43myolo11n\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata_yaml\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_yaml\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfold_idx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfold_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstage1_yolo11n_k_fold_cv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m     28\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m     stage1_results.append(result)\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 104\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model_type, model_name, data_yaml, fold_idx, experiment_name, project_dir)\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    103\u001b[39m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m results = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# Extract metrics\u001b[39;00m\n\u001b[32m    107\u001b[39m fold_result = {\n\u001b[32m    108\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m'\u001b[39m: model_type,\n\u001b[32m    109\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmodel_name\u001b[39m\u001b[33m'\u001b[39m: model_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    117\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtraining_params\u001b[39m\u001b[33m'\u001b[39m: train_params\n\u001b[32m    118\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/AI-waste-detection/.venv/lib/python3.11/site-packages/ultralytics/engine/model.py:799\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, trainer, **kwargs)\u001b[39m\n\u001b[32m    796\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m.trainer.model\n\u001b[32m    798\u001b[39m \u001b[38;5;28mself\u001b[39m.trainer.hub_session = \u001b[38;5;28mself\u001b[39m.session  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m799\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[32m    801\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {-\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m}:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/AI-waste-detection/.venv/lib/python3.11/site-packages/ultralytics/engine/trainer.py:227\u001b[39m, in \u001b[36mBaseTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    224\u001b[39m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/AI-waste-detection/.venv/lib/python3.11/site-packages/ultralytics/engine/trainer.py:419\u001b[39m, in \u001b[36mBaseTrainer._do_train\u001b[39m\u001b[34m(self, world_size)\u001b[39m\n\u001b[32m    417\u001b[39m \u001b[38;5;66;03m# Optimize - https://pytorch.org/docs/master/notes/amp_examples.html\u001b[39;00m\n\u001b[32m    418\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ni - last_opt_step >= \u001b[38;5;28mself\u001b[39m.accumulate:\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    420\u001b[39m     last_opt_step = ni\n\u001b[32m    422\u001b[39m     \u001b[38;5;66;03m# Timed stopping\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/AI-waste-detection/.venv/lib/python3.11/site-packages/ultralytics/engine/trainer.py:642\u001b[39m, in \u001b[36mBaseTrainer.optimizer_step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    640\u001b[39m \u001b[38;5;28mself\u001b[39m.scaler.unscale_(\u001b[38;5;28mself\u001b[39m.optimizer)  \u001b[38;5;66;03m# unscale gradients\u001b[39;00m\n\u001b[32m    641\u001b[39m torch.nn.utils.clip_grad_norm_(\u001b[38;5;28mself\u001b[39m.model.parameters(), max_norm=\u001b[32m10.0\u001b[39m)  \u001b[38;5;66;03m# clip gradients\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m642\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    643\u001b[39m \u001b[38;5;28mself\u001b[39m.scaler.update()\n\u001b[32m    644\u001b[39m \u001b[38;5;28mself\u001b[39m.optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/AI-waste-detection/.venv/lib/python3.11/site-packages/torch/amp/grad_scaler.py:461\u001b[39m, in \u001b[36mGradScaler.step\u001b[39m\u001b[34m(self, optimizer, *args, **kwargs)\u001b[39m\n\u001b[32m    455\u001b[39m     \u001b[38;5;28mself\u001b[39m.unscale_(optimizer)\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m    458\u001b[39m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m]) > \u001b[32m0\u001b[39m\n\u001b[32m    459\u001b[39m ), \u001b[33m\"\u001b[39m\u001b[33mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m461\u001b[39m retval = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    463\u001b[39m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mstage\u001b[39m\u001b[33m\"\u001b[39m] = OptState.STEPPED\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/AI-waste-detection/.venv/lib/python3.11/site-packages/torch/amp/grad_scaler.py:355\u001b[39m, in \u001b[36mGradScaler._maybe_opt_step\u001b[39m\u001b[34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_maybe_opt_step\u001b[39m(\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    349\u001b[39m     optimizer: torch.optim.Optimizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    352\u001b[39m     **kwargs: Any,\n\u001b[32m    353\u001b[39m ) -> Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    354\u001b[39m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(v.item() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m].values()):\n\u001b[32m    356\u001b[39m         retval = optimizer.step(*args, **kwargs)\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/AI-waste-detection/.venv/lib/python3.11/site-packages/torch/amp/grad_scaler.py:355\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_maybe_opt_step\u001b[39m(\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    349\u001b[39m     optimizer: torch.optim.Optimizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    352\u001b[39m     **kwargs: Any,\n\u001b[32m    353\u001b[39m ) -> Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    354\u001b[39m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m].values()):\n\u001b[32m    356\u001b[39m         retval = optimizer.step(*args, **kwargs)\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Stage 1: Train YOLO11n on all folds of k_fold_cv\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"STAGE 1: Training YOLO11n on all folds of k_fold_cv\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "stage1_results = []\n",
    "k_fold_cv_path = TrainingConfig.K_FOLD_CV_PATH\n",
    "\n",
    "# Check if dataset exists\n",
    "if not os.path.exists(k_fold_cv_path):\n",
    "    print(f\"❌ Dataset path not found: {k_fold_cv_path}\")\n",
    "else:\n",
    "    print(f\"📁 Dataset path: {k_fold_cv_path}\")\n",
    "    \n",
    "    # Train on all 5 folds (0-4)\n",
    "    for fold_idx in range(5):\n",
    "        fold_dir = os.path.join(k_fold_cv_path, f\"fold_{fold_idx}\")\n",
    "        data_yaml = os.path.join(fold_dir, \"data.yaml\")\n",
    "        \n",
    "        if os.path.exists(data_yaml):\n",
    "            result = train_model(\n",
    "                model_type='yolo',\n",
    "                model_name='yolo11n',\n",
    "                data_yaml=data_yaml,\n",
    "                fold_idx=fold_idx,\n",
    "                experiment_name='stage1_yolo11n_k_fold_cv'\n",
    "            )\n",
    "            stage1_results.append(result)\n",
    "        else:\n",
    "            print(f\"❌ Data YAML not found: {data_yaml}\")\n",
    "            stage1_results.append({\n",
    "                'model_name': 'yolo11n',\n",
    "                'fold': fold_idx,\n",
    "                'status': 'failed',\n",
    "                'error': f'Data YAML not found: {data_yaml}'\n",
    "            })\n",
    "\n",
    "# Save Stage 1 results\n",
    "stage1_file = save_results(stage1_results, \"stage1\")\n",
    "\n",
    "# Summary\n",
    "successful_stage1 = [r for r in stage1_results if r['status'] == 'completed']\n",
    "print(f\"\\n📊 Stage 1 Summary: {len(successful_stage1)}/5 folds completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfeef21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "STAGE 2: Training YOLO11n, s, and m on all folds of k_fold_cv_augmented\n",
      "====================================================================================================\n",
      "📁 Dataset path: /home/andrea/work/AI-waste-detection/datasets/k_fold_cv_augmented\n",
      "\n",
      "🚀 Starting yolo11n training on all folds...\n",
      "\n",
      "================================================================================\n",
      "Training yolo11n on Fold 0\n",
      "Data: /home/andrea/work/AI-waste-detection/datasets/k_fold_cv_augmented/fold_0/data.yaml\n",
      "================================================================================\n",
      "Training parameters: {'epochs': 100, 'imgsz': 640, 'patience': 20, 'amp': True, 'optimizer': 'AdamW', 'save_period': 10, 'workers': 8, 'cache': True, 'half': True, 'pretrained': True, 'lr0': 0.0001, 'lrf': 0.01, 'momentum': 0.937, 'weight_decay': 0.0001, 'augment': False, 'batch': 32, 'data': '/home/andrea/work/AI-waste-detection/datasets/k_fold_cv_augmented/fold_0/data.yaml', 'name': 'yolo11n_fold_0', 'project': 'runs/stage2_yolo11n_k_fold_cv_augmented'}\n",
      "Ultralytics 8.3.167 🚀 Python-3.11.0rc1 torch-2.7.1+cu126 CUDA:0 (Tesla T4, 14914MiB)\n",
      "Training parameters: {'epochs': 100, 'imgsz': 640, 'patience': 20, 'amp': True, 'optimizer': 'AdamW', 'save_period': 10, 'workers': 8, 'cache': True, 'half': True, 'pretrained': True, 'lr0': 0.0001, 'lrf': 0.01, 'momentum': 0.937, 'weight_decay': 0.0001, 'augment': False, 'batch': 32, 'data': '/home/andrea/work/AI-waste-detection/datasets/k_fold_cv_augmented/fold_0/data.yaml', 'name': 'yolo11n_fold_0', 'project': 'runs/stage2_yolo11n_k_fold_cv_augmented'}\n",
      "Ultralytics 8.3.167 🚀 Python-3.11.0rc1 torch-2.7.1+cu126 CUDA:0 (Tesla T4, 14914MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/home/andrea/work/AI-waste-detection/datasets/k_fold_cv_augmented/fold_0/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=True, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo11n_fold_0, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/stage2_yolo11n_k_fold_cv_augmented, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/stage2_yolo11n_k_fold_cv_augmented/yolo11n_fold_0, save_frames=False, save_json=False, save_period=10, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/home/andrea/work/AI-waste-detection/datasets/k_fold_cv_augmented/fold_0/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=True, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo11n_fold_0, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/stage2_yolo11n_k_fold_cv_augmented, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/stage2_yolo11n_k_fold_cv_augmented/yolo11n_fold_0, save_frames=False, save_json=False, save_period=10, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    431647  ultralytics.nn.modules.head.Detect           [5, [64, 128, 256]]           \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    431647  ultralytics.nn.modules.head.Detect           [5, [64, 128, 256]]           \n",
      "YOLO11n summary: 181 layers, 2,590,815 parameters, 2,590,799 gradients, 6.4 GFLOPs\n",
      "\n",
      "YOLO11n summary: 181 layers, 2,590,815 parameters, 2,590,799 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 847.6±625.1 MB/s, size: 28.5 KB)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 847.6±625.1 MB/s, size: 28.5 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/andrea/work/AI-waste-detection/datasets/k_fold_cv_augmented/fold_0/train/labels... 12864 ima\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/andrea/work/AI-waste-detection/datasets/k_fold_cv_augmented/fold_0/train/labels.cache\n",
      "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
      "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (12.3GB RAM): 100%|██████████| 12864/12864 [00:03<00:00, 3473.85it/s]\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 653.1±407.5 MB/s, size: 24.8 KB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 653.1±407.5 MB/s, size: 24.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/andrea/work/AI-waste-detection/datasets/k_fold_cv_augmented/fold_0/val/labels... 3217 images, \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/andrea/work/AI-waste-detection/datasets/k_fold_cv_augmented/fold_0/val/labels.cache\n",
      "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
      "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (3.1GB RAM): 100%|██████████| 3217/3217 [00:00<00:00, 3634.05it/s]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (3.1GB RAM): 100%|██████████| 3217/3217 [00:00<00:00, 3634.05it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/stage2_yolo11n_k_fold_cv_augmented/yolo11n_fold_0/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0001, momentum=0.937) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0001), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/stage2_yolo11n_k_fold_cv_augmented/yolo11n_fold_0\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0001, momentum=0.937) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0001), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/stage2_yolo11n_k_fold_cv_augmented/yolo11n_fold_0\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100      4.42G      1.121      2.661       1.44        148        640:  19%|█▉        | 77/402 [00:26<01:5\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     23\u001b[39m data_yaml = os.path.join(fold_dir, \u001b[33m\"\u001b[39m\u001b[33mdata.yaml\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m os.path.exists(data_yaml):\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     result = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43myolo\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata_yaml\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_yaml\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfold_idx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfold_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstage2_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmodel_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m_k_fold_cv_augmented\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m     stage2_results.append(result)\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 104\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model_type, model_name, data_yaml, fold_idx, experiment_name, project_dir)\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTraining parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_params\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    103\u001b[39m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m results = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# Extract metrics\u001b[39;00m\n\u001b[32m    107\u001b[39m fold_result = {\n\u001b[32m    108\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmodel_type\u001b[39m\u001b[33m'\u001b[39m: model_type,\n\u001b[32m    109\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmodel_name\u001b[39m\u001b[33m'\u001b[39m: model_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    117\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtraining_params\u001b[39m\u001b[33m'\u001b[39m: train_params\n\u001b[32m    118\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/AI-waste-detection/.venv/lib/python3.11/site-packages/ultralytics/engine/model.py:799\u001b[39m, in \u001b[36mModel.train\u001b[39m\u001b[34m(self, trainer, **kwargs)\u001b[39m\n\u001b[32m    796\u001b[39m     \u001b[38;5;28mself\u001b[39m.model = \u001b[38;5;28mself\u001b[39m.trainer.model\n\u001b[32m    798\u001b[39m \u001b[38;5;28mself\u001b[39m.trainer.hub_session = \u001b[38;5;28mself\u001b[39m.session  \u001b[38;5;66;03m# attach optional HUB session\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m799\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[38;5;66;03m# Update model and cfg after training\u001b[39;00m\n\u001b[32m    801\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m RANK \u001b[38;5;129;01min\u001b[39;00m {-\u001b[32m1\u001b[39m, \u001b[32m0\u001b[39m}:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/AI-waste-detection/.venv/lib/python3.11/site-packages/ultralytics/engine/trainer.py:227\u001b[39m, in \u001b[36mBaseTrainer.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    224\u001b[39m         ddp_cleanup(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mstr\u001b[39m(file))\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_do_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworld_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/AI-waste-detection/.venv/lib/python3.11/site-packages/ultralytics/engine/trainer.py:419\u001b[39m, in \u001b[36mBaseTrainer._do_train\u001b[39m\u001b[34m(self, world_size)\u001b[39m\n\u001b[32m    417\u001b[39m \u001b[38;5;66;03m# Optimize - https://pytorch.org/docs/master/notes/amp_examples.html\u001b[39;00m\n\u001b[32m    418\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ni - last_opt_step >= \u001b[38;5;28mself\u001b[39m.accumulate:\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    420\u001b[39m     last_opt_step = ni\n\u001b[32m    422\u001b[39m     \u001b[38;5;66;03m# Timed stopping\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/AI-waste-detection/.venv/lib/python3.11/site-packages/ultralytics/engine/trainer.py:642\u001b[39m, in \u001b[36mBaseTrainer.optimizer_step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    640\u001b[39m \u001b[38;5;28mself\u001b[39m.scaler.unscale_(\u001b[38;5;28mself\u001b[39m.optimizer)  \u001b[38;5;66;03m# unscale gradients\u001b[39;00m\n\u001b[32m    641\u001b[39m torch.nn.utils.clip_grad_norm_(\u001b[38;5;28mself\u001b[39m.model.parameters(), max_norm=\u001b[32m10.0\u001b[39m)  \u001b[38;5;66;03m# clip gradients\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m642\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    643\u001b[39m \u001b[38;5;28mself\u001b[39m.scaler.update()\n\u001b[32m    644\u001b[39m \u001b[38;5;28mself\u001b[39m.optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/AI-waste-detection/.venv/lib/python3.11/site-packages/torch/amp/grad_scaler.py:461\u001b[39m, in \u001b[36mGradScaler.step\u001b[39m\u001b[34m(self, optimizer, *args, **kwargs)\u001b[39m\n\u001b[32m    455\u001b[39m     \u001b[38;5;28mself\u001b[39m.unscale_(optimizer)\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[32m    458\u001b[39m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m]) > \u001b[32m0\u001b[39m\n\u001b[32m    459\u001b[39m ), \u001b[33m\"\u001b[39m\u001b[33mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m461\u001b[39m retval = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    463\u001b[39m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mstage\u001b[39m\u001b[33m\"\u001b[39m] = OptState.STEPPED\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/AI-waste-detection/.venv/lib/python3.11/site-packages/torch/amp/grad_scaler.py:355\u001b[39m, in \u001b[36mGradScaler._maybe_opt_step\u001b[39m\u001b[34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_maybe_opt_step\u001b[39m(\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    349\u001b[39m     optimizer: torch.optim.Optimizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    352\u001b[39m     **kwargs: Any,\n\u001b[32m    353\u001b[39m ) -> Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    354\u001b[39m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(v.item() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m].values()):\n\u001b[32m    356\u001b[39m         retval = optimizer.step(*args, **kwargs)\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/AI-waste-detection/.venv/lib/python3.11/site-packages/torch/amp/grad_scaler.py:355\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_maybe_opt_step\u001b[39m(\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    349\u001b[39m     optimizer: torch.optim.Optimizer,\n\u001b[32m   (...)\u001b[39m\u001b[32m    352\u001b[39m     **kwargs: Any,\n\u001b[32m    353\u001b[39m ) -> Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[32m    354\u001b[39m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[33m\"\u001b[39m\u001b[33mfound_inf_per_device\u001b[39m\u001b[33m\"\u001b[39m].values()):\n\u001b[32m    356\u001b[39m         retval = optimizer.step(*args, **kwargs)\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Stage 2: Train YOLO11n, s, and m on all folds of k_fold_cv_augmented\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"STAGE 2: Training YOLO11n, s, and m on all folds of k_fold_cv_augmented\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "stage2_results = []\n",
    "k_fold_cv_augmented_path = TrainingConfig.K_FOLD_CV_AUGMENTED_PATH\n",
    "stage2_models = ['yolo11n', 'yolo11s', 'yolo11m']\n",
    "\n",
    "# Check if dataset exists\n",
    "if not os.path.exists(k_fold_cv_augmented_path):\n",
    "    print(f\"❌ Dataset path not found: {k_fold_cv_augmented_path}\")\n",
    "else:\n",
    "    print(f\"📁 Dataset path: {k_fold_cv_augmented_path}\")\n",
    "    \n",
    "    # Train each model on all 5 folds (0-4)\n",
    "    for model_name in stage2_models:\n",
    "        print(f\"\\n🚀 Starting {model_name} training on all folds...\")\n",
    "        \n",
    "        for fold_idx in range(5):\n",
    "            fold_dir = os.path.join(k_fold_cv_augmented_path, f\"fold_{fold_idx}\")\n",
    "            data_yaml = os.path.join(fold_dir, \"data.yaml\")\n",
    "            \n",
    "            if os.path.exists(data_yaml):\n",
    "                result = train_model(\n",
    "                    model_type='yolo',\n",
    "                    model_name=model_name,\n",
    "                    data_yaml=data_yaml,\n",
    "                    fold_idx=fold_idx,\n",
    "                    experiment_name=f'stage2_{model_name}_k_fold_cv_augmented'\n",
    "                )\n",
    "                stage2_results.append(result)\n",
    "            else:\n",
    "                print(f\"❌ Data YAML not found: {data_yaml}\")\n",
    "                stage2_results.append({\n",
    "                    'model_name': model_name,\n",
    "                    'fold': fold_idx,\n",
    "                    'status': 'failed',\n",
    "                    'error': f'Data YAML not found: {data_yaml}'\n",
    "                })\n",
    "\n",
    "# Save Stage 2 results\n",
    "stage2_file = save_results(stage2_results, \"stage2\")\n",
    "\n",
    "# Summary\n",
    "successful_stage2 = [r for r in stage2_results if r['status'] == 'completed']\n",
    "total_expected = len(stage2_models) * 5  # 3 models × 5 folds = 15\n",
    "print(f\"\\n📊 Stage 2 Summary: {len(successful_stage2)}/{total_expected} trainings completed successfully\")\n",
    "\n",
    "# Per-model summary\n",
    "for model_name in stage2_models:\n",
    "    model_results = [r for r in stage2_results if r['model_name'] == model_name and r['status'] == 'completed']\n",
    "    print(f\"  {model_name}: {len(model_results)}/5 folds completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbf1c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "STAGE 3: Training YOLO11l and x on first fold of k_fold_cv_augmented\n",
      "====================================================================================================\n",
      "📁 Using fold 0: /home/andrea/work/AI-waste-detection/datasets/k_fold_cv_augmented/fold_0/data.yaml\n",
      "\n",
      "🚀 Starting yolo11l training on fold 0...\n",
      "\n",
      "================================================================================\n",
      "Training yolo11l on Fold 0\n",
      "Data: /home/andrea/work/AI-waste-detection/datasets/k_fold_cv_augmented/fold_0/data.yaml\n",
      "================================================================================\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11l.pt to 'yolo11l.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 49.0M/49.0M [00:00<00:00, 63.5MB/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training parameters: {'epochs': 100, 'imgsz': 640, 'patience': 20, 'amp': True, 'optimizer': 'AdamW', 'save_period': 10, 'workers': 8, 'cache': True, 'half': True, 'pretrained': True, 'lr0': 0.0001, 'lrf': 0.01, 'momentum': 0.937, 'weight_decay': 0.0001, 'augment': False, 'batch': 8, 'data': '/home/andrea/work/AI-waste-detection/datasets/k_fold_cv_augmented/fold_0/data.yaml', 'name': 'yolo11l_fold_0', 'project': 'runs/stage3_yolo11l_fold0_augmented'}\n",
      "Ultralytics 8.3.167 🚀 Python-3.11.0rc1 torch-2.7.1+cu126 CUDA:0 (Tesla T4, 14914MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/home/andrea/work/AI-waste-detection/datasets/k_fold_cv_augmented/fold_0/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=True, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo11l_fold_0, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/stage3_yolo11l_fold0_augmented, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/stage3_yolo11l_fold0_augmented/yolo11l_fold_0, save_frames=False, save_json=False, save_period=10, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/home/andrea/work/AI-waste-detection/datasets/k_fold_cv_augmented/fold_0/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=True, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.0001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo11l_fold_0, nbs=64, nms=False, opset=None, optimize=False, optimizer=AdamW, overlap_mask=True, patience=20, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=runs/stage3_yolo11l_fold0_augmented, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs/stage3_yolo11l_fold0_augmented/yolo11l_fold_0, save_frames=False, save_json=False, save_period=10, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0001, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
      "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  2                  -1  2    173824  ultralytics.nn.modules.block.C3k2            [128, 256, 2, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  2                  -1  2    173824  ultralytics.nn.modules.block.C3k2            [128, 256, 2, True, 0.25]     \n",
      "  3                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  4                  -1  2    691712  ultralytics.nn.modules.block.C3k2            [256, 512, 2, True, 0.25]     \n",
      "  4                  -1  2    691712  ultralytics.nn.modules.block.C3k2            [256, 512, 2, True, 0.25]     \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  5                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  6                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
      "  6                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      "  8                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      "  8                  -1  2   2234368  ultralytics.nn.modules.block.C3k2            [512, 512, 2, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  2   1455616  ultralytics.nn.modules.block.C2PSA           [512, 512, 2]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 10                  -1  2   1455616  ultralytics.nn.modules.block.C2PSA           [512, 512, 2]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  2    756736  ultralytics.nn.modules.block.C3k2            [1024, 256, 2, True]          \n",
      " 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  2    756736  ultralytics.nn.modules.block.C3k2            [1024, 256, 2, True]          \n",
      " 17                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  2   2365440  ultralytics.nn.modules.block.C3k2            [768, 512, 2, True]           \n",
      " 19                  -1  2   2365440  ultralytics.nn.modules.block.C3k2            [768, 512, 2, True]           \n",
      " 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 22                  -1  2   2496512  ultralytics.nn.modules.block.C3k2            [1024, 512, 2, True]          \n",
      " 23        [16, 19, 22]  1   1414879  ultralytics.nn.modules.head.Detect           [5, [256, 512, 512]]          \n",
      " 23        [16, 19, 22]  1   1414879  ultralytics.nn.modules.head.Detect           [5, [256, 512, 512]]          \n",
      "YOLO11l summary: 357 layers, 25,314,335 parameters, 25,314,319 gradients, 87.3 GFLOPs\n",
      "\n",
      "YOLO11l summary: 357 layers, 25,314,335 parameters, 25,314,319 gradients, 87.3 GFLOPs\n",
      "\n",
      "Transferred 1009/1015 items from pretrained weights\n",
      "Transferred 1009/1015 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1068.1±768.7 MB/s, size: 28.5 KB)\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1068.1±768.7 MB/s, size: 28.5 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/andrea/work/AI-waste-detection/datasets/k_fold_cv_augmented/fold_0/train/labels.cache... 128\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (12.3GB RAM): 100%|██████████| 12864/12864 [00:03<00:00, 3600.74it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 340.8±113.4 MB/s, size: 24.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/andrea/work/AI-waste-detection/datasets/k_fold_cv_augmented/fold_0/val/labels.cache... 3217 im\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING ⚠️ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mCaching images (3.1GB RAM): 100%|██████████| 3217/3217 [00:01<00:00, 2873.36it/s]\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/stage3_yolo11l_fold0_augmented/yolo11l_fold_0/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0001, momentum=0.937) with parameter groups 167 weight(decay=0.0), 174 weight(decay=0.0001), 173 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/stage3_yolo11l_fold0_augmented/yolo11l_fold_0\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.0001, momentum=0.937) with parameter groups 167 weight(decay=0.0), 174 weight(decay=0.0001), 173 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns/stage3_yolo11l_fold0_augmented/yolo11l_fold_0\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100      5.68G      1.379      3.528      1.858         32        640:   1%|          | 14/1608 [00:08<10:"
     ]
    }
   ],
   "source": [
    "# Stage 3: Train YOLO11l and x on first fold of k_fold_cv_augmented\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"STAGE 3: Training YOLO11l and x on first fold of k_fold_cv_augmented\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "stage3_results = []\n",
    "stage3_models = ['yolo11l', 'yolo11x']\n",
    "fold_idx = 0  # First fold\n",
    "\n",
    "# Check if dataset exists\n",
    "if not os.path.exists(k_fold_cv_augmented_path):\n",
    "    print(f\"❌ Dataset path not found: {k_fold_cv_augmented_path}\")\n",
    "else:\n",
    "    fold_dir = os.path.join(k_fold_cv_augmented_path, f\"fold_{fold_idx}\")\n",
    "    data_yaml = os.path.join(fold_dir, \"data.yaml\")\n",
    "    \n",
    "    if os.path.exists(data_yaml):\n",
    "        print(f\"📁 Using fold {fold_idx}: {data_yaml}\")\n",
    "        \n",
    "        # Train each large model on fold 0\n",
    "        for model_name in stage3_models:\n",
    "            print(f\"\\n🚀 Starting {model_name} training on fold {fold_idx}...\")\n",
    "            \n",
    "            result = train_model(\n",
    "                model_type='yolo',\n",
    "                model_name=model_name,\n",
    "                data_yaml=data_yaml,\n",
    "                fold_idx=fold_idx,\n",
    "                experiment_name=f'stage3_{model_name}_fold0_augmented'\n",
    "            )\n",
    "            stage3_results.append(result)\n",
    "    else:\n",
    "        print(f\"❌ Data YAML not found: {data_yaml}\")\n",
    "        for model_name in stage3_models:\n",
    "            stage3_results.append({\n",
    "                'model_name': model_name,\n",
    "                'fold': fold_idx,\n",
    "                'status': 'failed',\n",
    "                'error': f'Data YAML not found: {data_yaml}'\n",
    "            })\n",
    "\n",
    "# Save Stage 3 results\n",
    "stage3_file = save_results(stage3_results, \"stage3\")\n",
    "\n",
    "# Summary\n",
    "successful_stage3 = [r for r in stage3_results if r['status'] == 'completed']\n",
    "print(f\"\\n📊 Stage 3 Summary: {len(successful_stage3)}/{len(stage3_models)} large YOLO models completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615019c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 4: Train RT-DETR-l and x on first fold of k_fold_cv_augmented\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"STAGE 4: Training RT-DETR-l and x on first fold of k_fold_cv_augmented\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "stage4_results = []\n",
    "stage4_models = ['rtdetr-l', 'rtdetr-x']\n",
    "fold_idx = 0  # First fold\n",
    "\n",
    "# Check if dataset exists\n",
    "if not os.path.exists(k_fold_cv_augmented_path):\n",
    "    print(f\"❌ Dataset path not found: {k_fold_cv_augmented_path}\")\n",
    "else:\n",
    "    fold_dir = os.path.join(k_fold_cv_augmented_path, f\"fold_{fold_idx}\")\n",
    "    data_yaml = os.path.join(fold_dir, \"data.yaml\")\n",
    "    \n",
    "    if os.path.exists(data_yaml):\n",
    "        print(f\"📁 Using fold {fold_idx}: {data_yaml}\")\n",
    "        \n",
    "        # Train each RT-DETR model on fold 0\n",
    "        for model_name in stage4_models:\n",
    "            print(f\"\\n🚀 Starting {model_name} training on fold {fold_idx}...\")\n",
    "            \n",
    "            result = train_model(\n",
    "                model_type='rtdetr',\n",
    "                model_name=model_name,\n",
    "                data_yaml=data_yaml,\n",
    "                fold_idx=fold_idx,\n",
    "                experiment_name=f'stage4_{model_name}_fold0_augmented'\n",
    "            )\n",
    "            stage4_results.append(result)\n",
    "    else:\n",
    "        print(f\"❌ Data YAML not found: {data_yaml}\")\n",
    "        for model_name in stage4_models:\n",
    "            stage4_results.append({\n",
    "                'model_name': model_name,\n",
    "                'fold': fold_idx,\n",
    "                'status': 'failed',\n",
    "                'error': f'Data YAML not found: {data_yaml}'\n",
    "            })\n",
    "\n",
    "# Save Stage 4 results\n",
    "stage4_file = save_results(stage4_results, \"stage4\")\n",
    "\n",
    "# Summary\n",
    "successful_stage4 = [r for r in stage4_results if r['status'] == 'completed']\n",
    "print(f\"\\n📊 Stage 4 Summary: {len(successful_stage4)}/{len(stage4_models)} RT-DETR models completed successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeeb339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Summary and Analysis\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"COMPREHENSIVE TRAINING PIPELINE - FINAL SUMMARY\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Combine all results\n",
    "all_results = stage1_results + stage2_results + stage3_results + stage4_results\n",
    "\n",
    "# Overall statistics\n",
    "total_trainings = len(all_results)\n",
    "successful_trainings = len([r for r in all_results if r['status'] == 'completed'])\n",
    "failed_trainings = total_trainings - successful_trainings\n",
    "\n",
    "print(f\"\\n📊 OVERALL STATISTICS:\")\n",
    "print(f\"Total trainings attempted: {total_trainings}\")\n",
    "print(f\"Successful trainings: {successful_trainings}\")\n",
    "print(f\"Failed trainings: {failed_trainings}\")\n",
    "print(f\"Success rate: {(successful_trainings/total_trainings)*100:.1f}%\")\n",
    "\n",
    "# Stage-by-stage breakdown\n",
    "print(f\"\\n📋 STAGE BREAKDOWN:\")\n",
    "stages = [\n",
    "    (\"Stage 1 (YOLO11n on k_fold_cv)\", stage1_results, 5),\n",
    "    (\"Stage 2 (YOLO11n,s,m on k_fold_cv_augmented)\", stage2_results, 15),\n",
    "    (\"Stage 3 (YOLO11l,x on fold 0)\", stage3_results, 2),\n",
    "    (\"Stage 4 (RT-DETR-l,x on fold 0)\", stage4_results, 2)\n",
    "]\n",
    "\n",
    "for stage_name, stage_results, expected_count in stages:\n",
    "    successful = len([r for r in stage_results if r['status'] == 'completed'])\n",
    "    print(f\"  {stage_name}: {successful}/{expected_count} completed\")\n",
    "\n",
    "# Model performance summary (for successful trainings)\n",
    "print(f\"\\n🏆 MODEL PERFORMANCE SUMMARY:\")\n",
    "successful_results = [r for r in all_results if r['status'] == 'completed' and r.get('best_fitness')]\n",
    "\n",
    "if successful_results:\n",
    "    # Group by model\n",
    "    model_performance = {}\n",
    "    for result in successful_results:\n",
    "        model_name = result['model_name']\n",
    "        if model_name not in model_performance:\n",
    "            model_performance[model_name] = []\n",
    "        model_performance[model_name].append(result['best_fitness'])\n",
    "    \n",
    "    # Calculate averages\n",
    "    for model_name, fitness_values in model_performance.items():\n",
    "        avg_fitness = sum(fitness_values) / len(fitness_values)\n",
    "        max_fitness = max(fitness_values)\n",
    "        min_fitness = min(fitness_values)\n",
    "        count = len(fitness_values)\n",
    "        \n",
    "        print(f\"  {model_name}: Avg={avg_fitness:.4f}, Max={max_fitness:.4f}, Min={min_fitness:.4f} ({count} runs)\")\n",
    "\n",
    "# Best performing models\n",
    "if successful_results:\n",
    "    best_model = max(successful_results, key=lambda x: x['best_fitness'])\n",
    "    print(f\"\\n🥇 BEST PERFORMING MODEL:\")\n",
    "    print(f\"  Model: {best_model['model_name']}\")\n",
    "    print(f\"  Fold: {best_model['fold']}\")\n",
    "    print(f\"  Fitness: {best_model['best_fitness']:.4f}\")\n",
    "    print(f\"  Path: {best_model.get('model_path', 'N/A')}\")\n",
    "\n",
    "# Failed trainings summary\n",
    "failed_results = [r for r in all_results if r['status'] == 'failed']\n",
    "if failed_results:\n",
    "    print(f\"\\n❌ FAILED TRAININGS:\")\n",
    "    for result in failed_results:\n",
    "        print(f\"  {result['model_name']} (Fold {result['fold']}): {result.get('error', 'Unknown error')}\")\n",
    "\n",
    "# Save comprehensive results\n",
    "comprehensive_results = {\n",
    "    'timestamp': datetime.datetime.now().isoformat(),\n",
    "    'summary': {\n",
    "        'total_trainings': total_trainings,\n",
    "        'successful_trainings': successful_trainings,\n",
    "        'failed_trainings': failed_trainings,\n",
    "        'success_rate': (successful_trainings/total_trainings)*100\n",
    "    },\n",
    "    'stages': {\n",
    "        'stage1': stage1_results,\n",
    "        'stage2': stage2_results,\n",
    "        'stage3': stage3_results,\n",
    "        'stage4': stage4_results\n",
    "    },\n",
    "    'all_results': all_results\n",
    "}\n",
    "\n",
    "comprehensive_file = save_results(comprehensive_results, \"comprehensive_pipeline\")\n",
    "\n",
    "print(f\"\\n✅ Comprehensive training pipeline completed!\")\n",
    "print(f\"📁 All results saved to: {comprehensive_file}\")\n",
    "print(f\"\\n🔍 Check the 'runs/' directory for individual training outputs and models.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853a14cb",
   "metadata": {},
   "source": [
    "## Training Pipeline Summary\n",
    "\n",
    "This comprehensive training pipeline will train **24 models total**:\n",
    "\n",
    "### Stage 1: YOLO11n Cross-Validation (5 models)\n",
    "- YOLO11n on all 5 folds of `k_fold_cv`\n",
    "- Provides baseline performance on original dataset\n",
    "\n",
    "### Stage 2: Multi-Model Cross-Validation (15 models)\n",
    "- YOLO11n, YOLO11s, YOLO11m on all 5 folds of `k_fold_cv_augmented`\n",
    "- Tests effect of model size on augmented dataset\n",
    "\n",
    "### Stage 3: Large YOLO Models (2 models)\n",
    "- YOLO11l, YOLO11x on fold 0 of `k_fold_cv_augmented`\n",
    "- Tests largest YOLO models for maximum performance\n",
    "\n",
    "### Stage 4: RT-DETR Models (2 models)\n",
    "- RT-DETR-l, RT-DETR-x on fold 0 of `k_fold_cv_augmented`\n",
    "- Tests transformer-based detection architecture\n",
    "\n",
    "### Training Configuration\n",
    "- **Epochs**: 100 (with early stopping patience=20)\n",
    "- **Image Size**: 640x640\n",
    "- **Optimizer**: AdamW\n",
    "- **Batch Sizes**: Automatically adjusted based on model size\n",
    "  - Small models (n, s): batch=32\n",
    "  - Medium models (m, rtdetr-l): batch=16  \n",
    "  - Large models (l, x, rtdetr-x): batch=8\n",
    "\n",
    "### Output Structure\n",
    "All trained models will be saved in organized directories under `runs/`:\n",
    "- `runs/stage1_yolo11n_k_fold_cv/`\n",
    "- `runs/stage2_yolo11n_k_fold_cv_augmented/`\n",
    "- `runs/stage2_yolo11s_k_fold_cv_augmented/`\n",
    "- `runs/stage2_yolo11m_k_fold_cv_augmented/`\n",
    "- `runs/stage3_yolo11l_fold0_augmented/`\n",
    "- `runs/stage3_yolo11x_fold0_augmented/`\n",
    "- `runs/stage4_rtdetr-l_fold0_augmented/`\n",
    "- `runs/stage4_rtdetr-x_fold0_augmented/`\n",
    "\n",
    "Results will be automatically saved to timestamped JSON files for analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
