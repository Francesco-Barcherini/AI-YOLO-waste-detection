{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efd2d86c",
   "metadata": {},
   "source": [
    "# Model Evaluation and mAP@50 Testing\n",
    "\n",
    "This notebook evaluates all trained models on the test dataset and computes mAP@50 scores for each class.\n",
    "The results are averaged across folds where multiple folds exist for the same model variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48aaa24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base directory: ../..\n",
      "Runs directory: ../../runs\n",
      "Test dataset: ../../datasets/roboflow/test\n",
      "Data YAML: ../../datasets/roboflow/data.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import YOLO and RT-DETR\n",
    "from ultralytics import YOLO\n",
    "try:\n",
    "    from ultralytics import RTDETR\n",
    "except ImportError:\n",
    "    print(\"RT-DETR not available, will handle separately\")\n",
    "    RTDETR = None\n",
    "\n",
    "# Set up paths\n",
    "BASE_DIR = Path(\"../../\")\n",
    "RUNS_DIR = BASE_DIR / \"runs\"\n",
    "TEST_DATASET = BASE_DIR / \"datasets\" / \"roboflow\" / \"test\"\n",
    "DATA_YAML = BASE_DIR / \"datasets\" / \"roboflow\" / \"data.yaml\"\n",
    "\n",
    "print(f\"Base directory: {BASE_DIR}\")\n",
    "print(f\"Runs directory: {RUNS_DIR}\")\n",
    "print(f\"Test dataset: {TEST_DATASET}\")\n",
    "print(f\"Data YAML: {DATA_YAML}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6afeaba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scanning stage2_yolo11m_k_fold_cv_augmented:\n",
      "  Found: yolo11m_fold_0 -> ../../runs/stage2_yolo11m_k_fold_cv_augmented/yolo11m_fold_0/weights/best.pt\n",
      "  Found: yolo11m_fold_1 -> ../../runs/stage2_yolo11m_k_fold_cv_augmented/yolo11m_fold_1/weights/best.pt\n",
      "  Skipping yolo11m_fold_1 - using only fold_0 for yolo11m (other folds still training)\n",
      "  Found: yolo11m_fold_2 -> ../../runs/stage2_yolo11m_k_fold_cv_augmented/yolo11m_fold_2/weights/best.pt\n",
      "  Skipping yolo11m_fold_2 - using only fold_0 for yolo11m (other folds still training)\n",
      "\n",
      "Scanning stage3_yolo11l_fold0_subsampled:\n",
      "  Found: yolo11l_fold_0 -> ../../runs/stage3_yolo11l_fold0_subsampled/yolo11l_fold_0/weights/best.pt\n",
      "\n",
      "Scanning stage1_yolo11n_k_fold_cv:\n",
      "  Found: yolo11n_fold_3 -> ../../runs/stage1_yolo11n_k_fold_cv/yolo11n_fold_3/weights/best.pt\n",
      "  Found: yolo11n_fold_2 -> ../../runs/stage1_yolo11n_k_fold_cv/yolo11n_fold_2/weights/best.pt\n",
      "  Found: yolo11n_fold_1 -> ../../runs/stage1_yolo11n_k_fold_cv/yolo11n_fold_1/weights/best.pt\n",
      "  Found: yolo11n_fold_0 -> ../../runs/stage1_yolo11n_k_fold_cv/yolo11n_fold_0/weights/best.pt\n",
      "  Found: yolo11n_fold_4 -> ../../runs/stage1_yolo11n_k_fold_cv/yolo11n_fold_4/weights/best.pt\n",
      "\n",
      "Scanning stage2_yolo11n_k_fold_cv_augmented:\n",
      "  Found: yolo11n_fold_3 -> ../../runs/stage2_yolo11n_k_fold_cv_augmented/yolo11n_fold_3/weights/best.pt\n",
      "  Found: yolo11n_fold_2 -> ../../runs/stage2_yolo11n_k_fold_cv_augmented/yolo11n_fold_2/weights/best.pt\n",
      "  Found: yolo11n_fold_1 -> ../../runs/stage2_yolo11n_k_fold_cv_augmented/yolo11n_fold_1/weights/best.pt\n",
      "  Found: yolo11n_fold_0 -> ../../runs/stage2_yolo11n_k_fold_cv_augmented/yolo11n_fold_0/weights/best.pt\n",
      "  Found: yolo11n_fold_4 -> ../../runs/stage2_yolo11n_k_fold_cv_augmented/yolo11n_fold_4/weights/best.pt\n",
      "\n",
      "Scanning stage4_rtdetr-l_fold0_augmented:\n",
      "  Found: rtdetr-l_fold_0 -> ../../runs/stage4_rtdetr-l_fold0_augmented/rtdetr-l_fold_0/weights/best.pt\n",
      "\n",
      "Scanning stage4_rtdetr-x_fold0_augmented:\n",
      "  Found: rtdetr-x_fold_0 -> ../../runs/stage4_rtdetr-x_fold0_augmented/rtdetr-x_fold_0/weights/best.pt\n",
      "\n",
      "Scanning stage2_yolo11s_k_fold_cv_augmented:\n",
      "  Found: yolo11s_fold_4 -> ../../runs/stage2_yolo11s_k_fold_cv_augmented/yolo11s_fold_4/weights/best.pt\n",
      "  Found: yolo11s_fold_3 -> ../../runs/stage2_yolo11s_k_fold_cv_augmented/yolo11s_fold_3/weights/best.pt\n",
      "  Found: yolo11s_fold_2 -> ../../runs/stage2_yolo11s_k_fold_cv_augmented/yolo11s_fold_2/weights/best.pt\n",
      "  Found: yolo11s_fold_1 -> ../../runs/stage2_yolo11s_k_fold_cv_augmented/yolo11s_fold_1/weights/best.pt\n",
      "  Found: yolo11s_fold_0 -> ../../runs/stage2_yolo11s_k_fold_cv_augmented/yolo11s_fold_0/weights/best.pt\n",
      "\n",
      "Scanning stage3_yolo11x_fold0_subsampled:\n",
      "  Found: yolo11x_fold_0 -> ../../runs/stage3_yolo11x_fold0_subsampled/yolo11x_fold_0/weights/best.pt\n",
      "\n",
      "Found 7 unique models:\n",
      "  yolo11m: 1 folds (YOLOv11-M)\n",
      "  yolo11l: 1 folds (YOLOv11-L)\n",
      "  yolo11n: 5 folds (YOLOv11-N)\n",
      "  rtdetr-l: 1 folds (RT-DETRv2-L)\n",
      "  rtdetr-x: 1 folds (RT-DETRv2-X)\n",
      "  yolo11s: 5 folds (YOLOv11-S)\n",
      "  yolo11x: 1 folds (YOLOv11-X)\n"
     ]
    }
   ],
   "source": [
    "def discover_model_weights():\n",
    "    \"\"\"\n",
    "    Discover all trained model weights in the runs directory\n",
    "    Returns a dictionary with model information\n",
    "    \"\"\"\n",
    "    models_info = {}\n",
    "    \n",
    "    # Define class names\n",
    "    class_names = ['glass', 'metal', 'organic', 'paper', 'plastic']\n",
    "    \n",
    "    # Scan all stage directories\n",
    "    for stage_dir in RUNS_DIR.glob(\"stage*\"):\n",
    "        print(f\"\\nScanning {stage_dir.name}:\")\n",
    "        \n",
    "        # Extract stage info\n",
    "        stage_name = stage_dir.name\n",
    "        \n",
    "        # Find all fold directories in this stage\n",
    "        fold_dirs = list(stage_dir.glob(\"*fold*\"))\n",
    "        \n",
    "        for fold_dir in fold_dirs:\n",
    "            weights_dir = fold_dir / \"weights\"\n",
    "            if weights_dir.exists():\n",
    "                # Find best.pt file\n",
    "                best_weights = weights_dir / \"best.pt\"\n",
    "                if best_weights.exists():\n",
    "                    print(f\"  Found: {fold_dir.name} -> {best_weights}\")\n",
    "                    \n",
    "                    # Extract model info\n",
    "                    model_name = fold_dir.name.split('_fold_')[0]\n",
    "                    fold_num = fold_dir.name.split('_fold_')[-1]\n",
    "\n",
    "                    # todo: togliere queste righe quando yolo11m finisce di allenarsi\n",
    "                    # Special handling for yolo11m: only use fold_0 (other folds still training)\n",
    "                    if 'yolo11m' in model_name.lower() and fold_num != '0':\n",
    "                        print(f\"  Skipping {fold_dir.name} - using only fold_0 for yolo11m (other folds still training)\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Determine model family and type\n",
    "                    if 'rtdetr' in model_name.lower():\n",
    "                        family = 'RT-DETRv2'\n",
    "                        size = model_name.split('-')[-1].upper()\n",
    "                    else:\n",
    "                        family = 'YOLOv11'\n",
    "                        size = model_name[-1].upper()  # Extract last character (n, s, m, l, x)\n",
    "                    \n",
    "                    # Store model info\n",
    "                    if model_name not in models_info:\n",
    "                        models_info[model_name] = {\n",
    "                            'family': family,\n",
    "                            'size': size,\n",
    "                            'folds': {},\n",
    "                            'stage': stage_name\n",
    "                        }\n",
    "                    \n",
    "                    models_info[model_name]['folds'][fold_num] = {\n",
    "                        'weights_path': str(best_weights),\n",
    "                        'fold_dir': str(fold_dir)\n",
    "                    }\n",
    "                else:\n",
    "                    print(f\"  Missing best.pt: {fold_dir.name}\")\n",
    "    \n",
    "    return models_info, class_names\n",
    "\n",
    "# Discover all models\n",
    "models_info, class_names = discover_model_weights()\n",
    "print(f\"\\nFound {len(models_info)} unique models:\")\n",
    "for model_name, info in models_info.items():\n",
    "    print(f\"  {model_name}: {len(info['folds'])} folds ({info['family']}-{info['size']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77faa745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2\n",
    "\n",
    "def evaluate_model(weights_path, model_type='yolo'):\n",
    "    \"\"\"\n",
    "    Evaluate a single model on the test dataset and return per-class mAP@50 and FPS\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if model_type == 'yolo':\n",
    "            # Load YOLO model\n",
    "            model = YOLO(weights_path)\n",
    "        elif model_type == 'rtdetr':\n",
    "            # Load RT-DETR model\n",
    "            if RTDETR is None:\n",
    "                print(f\"RT-DETR not available, skipping {weights_path}\")\n",
    "                return None\n",
    "            model = RTDETR(weights_path)\n",
    "        else:\n",
    "            print(f\"Unknown model type: {model_type}\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"Evaluating {weights_path}...\")\n",
    "        \n",
    "        # Run validation on test dataset\n",
    "        results = model.val(data=str(DATA_YAML), split='test', verbose=False)\n",
    "        \n",
    "        # Extract per-class mAP@50, P and R\n",
    "        if hasattr(results, 'box') and hasattr(results.box, 'map50') and hasattr(results.box, 'p') and hasattr(results.box, 'r'):\n",
    "            # Overall mAP@50\n",
    "            overall_map50 = results.box.map50\n",
    "            overall_P = results.box.p\n",
    "            overall_R = results.box.r\n",
    "            \n",
    "            # Per-class mAP@50\n",
    "            if hasattr(results.box, 'ap50') and results.box.ap50 is not None:\n",
    "                per_class_map50 = results.box.ap50.tolist()\n",
    "            else:\n",
    "                print(f\"Warning: No per-class mAP@50 available for {weights_path}\")\n",
    "                per_class_map50 = [0.0] * 5  # Default to zeros\n",
    "            \n",
    "            print(f\"  Overall mAP@50: {overall_map50:.4f}\")\n",
    "            print(f\"  Per-class mAP@50: {per_class_map50}\")\n",
    "            print(f\"  Overall P: {overall_P:.4f}, Overall R: {overall_R:.4f}\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"Error: Could not extract mAP@50 from results for {weights_path}\")\n",
    "            return None\n",
    "        \n",
    "        # Measure FPS on test images\n",
    "        print(f\"  Measuring FPS...\")\n",
    "        test_images_dir = TEST_DATASET / \"images\"\n",
    "        test_images = list(test_images_dir.glob(\"*.jpg\")) + list(test_images_dir.glob(\"*.png\"))\n",
    "        \n",
    "        # Use a subset of test images for FPS measurement (to save time)\n",
    "        fps_test_images = test_images[:min(50, len(test_images))]  # Use max 50 images\n",
    "        \n",
    "        if len(fps_test_images) == 0:\n",
    "            print(f\"  Warning: No test images found for FPS measurement\")\n",
    "            mean_fps = 0.0\n",
    "        else:\n",
    "            # Warm up the model (first few predictions are usually slower)\n",
    "            if len(fps_test_images) >= 3:\n",
    "                for warmup_img in fps_test_images[:3]:\n",
    "                    _ = model.predict(str(warmup_img), verbose=False)\n",
    "            \n",
    "            # Measure inference time\n",
    "            inference_times = []\n",
    "            \n",
    "            for img_path in fps_test_images:\n",
    "                start_time = time.time()\n",
    "                _ = model.predict(str(img_path), verbose=False)\n",
    "                end_time = time.time()\n",
    "                inference_times.append(end_time - start_time)\n",
    "            \n",
    "            # Calculate mean FPS\n",
    "            mean_inference_time = np.mean(inference_times)\n",
    "            mean_fps = 1.0 / mean_inference_time if mean_inference_time > 0 else 0.0\n",
    "            \n",
    "            print(f\"  Mean FPS: {mean_fps:.2f} ({len(fps_test_images)} images)\")\n",
    "        \n",
    "        return {\n",
    "            'overall_P': overall_P,\n",
    "            'overall_R': overall_R,\n",
    "            'overall_map50': overall_map50,\n",
    "            'per_class_map50': per_class_map50,\n",
    "            'class_names': class_names,\n",
    "            'mean_fps': mean_fps,\n",
    "            'num_fps_images': len(fps_test_images) if 'fps_test_images' in locals() else 0\n",
    "        }\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating {weights_path}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8be58cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Evaluating yolo11m (YOLOv11-M)\n",
      "============================================================\n",
      "Evaluating ../../runs/stage2_yolo11m_k_fold_cv_augmented/yolo11m_fold_0/weights/best.pt...\n",
      "Ultralytics 8.3.167 ðŸš€ Python-3.11.0rc1 torch-2.7.1+cu126 CUDA:0 (Tesla T4, 14914MiB)\n",
      "YOLO11m summary (fused): 125 layers, 20,033,887 parameters, 0 gradients, 67.7 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 997.8Â±910.4 MB/s, size: 22.9 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/andrea/work/AI-waste-detection/datasets/roboflow/test/labels.cache... 1099 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1099/1099 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [01:14<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1099       1622      0.839      0.773      0.825       0.62\n",
      "Speed: 0.6ms preprocess, 37.6ms inference, 0.0ms loss, 6.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val84\u001b[0m\n",
      "  Overall mAP@50: 0.8249\n",
      "  Per-class mAP@50: [0.8936417429808664, 0.9120692754764765, 0.7414633482770655, 0.9349313183815487, 0.6423306064263941]\n",
      "  Measuring FPS...\n",
      "  Mean FPS: 15.75 (50 images)\n",
      "Completed yolo11m: 1 successful evaluations\n",
      "\n",
      "============================================================\n",
      "Evaluating yolo11l (YOLOv11-L)\n",
      "============================================================\n",
      "Evaluating ../../runs/stage3_yolo11l_fold0_subsampled/yolo11l_fold_0/weights/best.pt...\n",
      "Ultralytics 8.3.167 ðŸš€ Python-3.11.0rc1 torch-2.7.1+cu126 CUDA:0 (Tesla T4, 14914MiB)\n",
      "YOLO11l summary (fused): 190 layers, 25,283,167 parameters, 0 gradients, 86.6 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 432.2Â±180.8 MB/s, size: 6.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/andrea/work/AI-waste-detection/datasets/roboflow/test/labels.cache... 1099 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1099/1099 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [01:20<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1099       1622      0.831      0.758      0.809      0.609\n",
      "Speed: 0.6ms preprocess, 45.2ms inference, 0.0ms loss, 6.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val85\u001b[0m\n",
      "  Overall mAP@50: 0.8086\n",
      "  Per-class mAP@50: [0.841748902912257, 0.9206058394155782, 0.7249234944608487, 0.9426800391274945, 0.6128786899947374]\n",
      "  Measuring FPS...\n",
      "  Mean FPS: 24.23 (50 images)\n",
      "Completed yolo11l: 1 successful evaluations\n",
      "\n",
      "============================================================\n",
      "Evaluating yolo11n (YOLOv11-N)\n",
      "============================================================\n",
      "Evaluating ../../runs/stage2_yolo11n_k_fold_cv_augmented/yolo11n_fold_3/weights/best.pt...\n",
      "Ultralytics 8.3.167 ðŸš€ Python-3.11.0rc1 torch-2.7.1+cu126 CUDA:0 (Tesla T4, 14914MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,583,127 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1198.6Â±978.3 MB/s, size: 35.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/andrea/work/AI-waste-detection/datasets/roboflow/test/labels.cache... 1099 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1099/1099 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:21<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1099       1622      0.849      0.752      0.807      0.587\n",
      "Speed: 0.5ms preprocess, 4.7ms inference, 0.0ms loss, 3.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val86\u001b[0m\n",
      "  Overall mAP@50: 0.8072\n",
      "  Per-class mAP@50: [0.8732610430756309, 0.912945488365606, 0.6916097160320844, 0.9440998554135069, 0.6138801161620073]\n",
      "  Measuring FPS...\n",
      "  Mean FPS: 31.89 (50 images)\n",
      "Evaluating ../../runs/stage2_yolo11n_k_fold_cv_augmented/yolo11n_fold_2/weights/best.pt...\n",
      "Ultralytics 8.3.167 ðŸš€ Python-3.11.0rc1 torch-2.7.1+cu126 CUDA:0 (Tesla T4, 14914MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,583,127 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 682.7Â±177.8 MB/s, size: 10.0 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/andrea/work/AI-waste-detection/datasets/roboflow/test/labels.cache... 1099 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1099/1099 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:21<00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1099       1622      0.836      0.754      0.811      0.596\n",
      "Speed: 0.4ms preprocess, 4.8ms inference, 0.0ms loss, 5.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val87\u001b[0m\n",
      "  Overall mAP@50: 0.8109\n",
      "  Per-class mAP@50: [0.9114827121874811, 0.9150705882819365, 0.720994443953203, 0.9165631041429649, 0.5903758005719946]\n",
      "  Measuring FPS...\n",
      "  Mean FPS: 32.02 (50 images)\n",
      "Evaluating ../../runs/stage2_yolo11n_k_fold_cv_augmented/yolo11n_fold_1/weights/best.pt...\n",
      "Ultralytics 8.3.167 ðŸš€ Python-3.11.0rc1 torch-2.7.1+cu126 CUDA:0 (Tesla T4, 14914MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,583,127 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 586.7Â±342.5 MB/s, size: 7.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/andrea/work/AI-waste-detection/datasets/roboflow/test/labels.cache... 1099 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1099/1099 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:41<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1099       1622      0.832      0.753      0.798      0.582\n",
      "Speed: 0.6ms preprocess, 6.3ms inference, 0.0ms loss, 8.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val88\u001b[0m\n",
      "  Overall mAP@50: 0.7977\n",
      "  Per-class mAP@50: [0.8654187509980696, 0.9009492954346198, 0.6852179156701024, 0.9359716378917637, 0.6011506361910643]\n",
      "  Measuring FPS...\n",
      "  Mean FPS: 32.87 (50 images)\n",
      "Evaluating ../../runs/stage2_yolo11n_k_fold_cv_augmented/yolo11n_fold_0/weights/best.pt...\n",
      "Ultralytics 8.3.167 ðŸš€ Python-3.11.0rc1 torch-2.7.1+cu126 CUDA:0 (Tesla T4, 14914MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,583,127 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 966.9Â±599.0 MB/s, size: 24.9 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/andrea/work/AI-waste-detection/datasets/roboflow/test/labels.cache... 1099 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1099/1099 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:39<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1099       1622      0.815      0.774      0.794      0.578\n",
      "Speed: 0.6ms preprocess, 6.6ms inference, 0.0ms loss, 8.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val89\u001b[0m\n",
      "  Overall mAP@50: 0.7939\n",
      "  Per-class mAP@50: [0.8343910946579143, 0.8717068531703214, 0.7104386395151036, 0.9404710635676123, 0.6127285948747878]\n",
      "  Measuring FPS...\n",
      "  Mean FPS: 32.73 (50 images)\n",
      "Evaluating ../../runs/stage2_yolo11n_k_fold_cv_augmented/yolo11n_fold_4/weights/best.pt...\n",
      "Ultralytics 8.3.167 ðŸš€ Python-3.11.0rc1 torch-2.7.1+cu126 CUDA:0 (Tesla T4, 14914MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,583,127 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1132.2Â±1039.9 MB/s, size: 29.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/andrea/work/AI-waste-detection/datasets/roboflow/test/labels.cache... 1099 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1099/1099 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:39<00:00,  1.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1099       1622      0.815      0.772      0.812      0.594\n",
      "Speed: 0.6ms preprocess, 6.8ms inference, 0.0ms loss, 8.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val90\u001b[0m\n",
      "  Overall mAP@50: 0.8118\n",
      "  Per-class mAP@50: [0.8576248476834922, 0.9105992750155206, 0.7122822609866117, 0.9323209463256196, 0.645978012365353]\n",
      "  Measuring FPS...\n",
      "  Mean FPS: 33.00 (50 images)\n",
      "Completed yolo11n: 5 successful evaluations\n",
      "\n",
      "============================================================\n",
      "Evaluating rtdetr-l (RT-DETRv2-L)\n",
      "============================================================\n",
      "Evaluating ../../runs/stage4_rtdetr-l_fold0_augmented/rtdetr-l_fold_0/weights/best.pt...\n",
      "Ultralytics 8.3.167 ðŸš€ Python-3.11.0rc1 torch-2.7.1+cu126 CUDA:0 (Tesla T4, 14914MiB)\n",
      "rt-detr-l summary: 302 layers, 31,994,015 parameters, 0 gradients, 103.5 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1041.5Â±717.4 MB/s, size: 24.8 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/andrea/work/AI-waste-detection/datasets/roboflow/test/labels.cache... 1099 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1099/1099 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [01:51<00:00,  1.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1099       1622      0.829      0.699      0.754      0.549\n",
      "Speed: 0.8ms preprocess, 67.4ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val91\u001b[0m\n",
      "  Overall mAP@50: 0.7537\n",
      "  Per-class mAP@50: [0.8306480484253883, 0.8587076079492546, 0.650119978828882, 0.9142512612524027, 0.5149256486878995]\n",
      "  Measuring FPS...\n",
      "  Mean FPS: 9.51 (50 images)\n",
      "Completed rtdetr-l: 1 successful evaluations\n",
      "\n",
      "============================================================\n",
      "Evaluating rtdetr-x (RT-DETRv2-X)\n",
      "============================================================\n",
      "Evaluating ../../runs/stage4_rtdetr-x_fold0_augmented/rtdetr-x_fold_0/weights/best.pt...\n",
      "Ultralytics 8.3.167 ðŸš€ Python-3.11.0rc1 torch-2.7.1+cu126 CUDA:0 (Tesla T4, 14914MiB)\n",
      "rt-detr-x summary: 373 layers, 65,477,711 parameters, 0 gradients, 222.5 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 705.6Â±491.2 MB/s, size: 9.9 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/andrea/work/AI-waste-detection/datasets/roboflow/test/labels.cache... 1099 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1099/1099 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [02:39<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1099       1622      0.799      0.711       0.74       0.53\n",
      "Speed: 0.8ms preprocess, 112.1ms inference, 0.0ms loss, 1.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val92\u001b[0m\n",
      "  Overall mAP@50: 0.7399\n",
      "  Per-class mAP@50: [0.8469243364084952, 0.8463501917738496, 0.6534918123387711, 0.868694725134842, 0.4842382013152916]\n",
      "  Measuring FPS...\n",
      "  Mean FPS: 6.26 (50 images)\n",
      "Completed rtdetr-x: 1 successful evaluations\n",
      "\n",
      "============================================================\n",
      "Evaluating yolo11s (YOLOv11-S)\n",
      "============================================================\n",
      "Evaluating ../../runs/stage2_yolo11s_k_fold_cv_augmented/yolo11s_fold_4/weights/best.pt...\n",
      "Ultralytics 8.3.167 ðŸš€ Python-3.11.0rc1 torch-2.7.1+cu126 CUDA:0 (Tesla T4, 14914MiB)\n",
      "YOLO11s summary (fused): 100 layers, 9,414,735 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 491.9Â±84.8 MB/s, size: 7.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/andrea/work/AI-waste-detection/datasets/roboflow/test/labels.cache... 1099 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1099/1099 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:48<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1099       1622      0.865      0.748      0.814      0.609\n",
      "Speed: 0.7ms preprocess, 15.6ms inference, 0.0ms loss, 8.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val93\u001b[0m\n",
      "  Overall mAP@50: 0.8136\n",
      "  Per-class mAP@50: [0.8798861780450407, 0.9243683408414906, 0.717796044823451, 0.9322669995606471, 0.6136884808705939]\n",
      "  Measuring FPS...\n",
      "  Mean FPS: 23.86 (50 images)\n",
      "Evaluating ../../runs/stage2_yolo11s_k_fold_cv_augmented/yolo11s_fold_3/weights/best.pt...\n",
      "Ultralytics 8.3.167 ðŸš€ Python-3.11.0rc1 torch-2.7.1+cu126 CUDA:0 (Tesla T4, 14914MiB)\n",
      "YOLO11s summary (fused): 100 layers, 9,414,735 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 788.7Â±254.9 MB/s, size: 10.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/andrea/work/AI-waste-detection/datasets/roboflow/test/labels.cache... 1099 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1099/1099 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:47<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1099       1622      0.825      0.771      0.819      0.615\n",
      "Speed: 0.6ms preprocess, 15.8ms inference, 0.0ms loss, 8.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val94\u001b[0m\n",
      "  Overall mAP@50: 0.8186\n",
      "  Per-class mAP@50: [0.8954202688019743, 0.9006918101993759, 0.7415182032031533, 0.9239055729922252, 0.6314879766523191]\n",
      "  Measuring FPS...\n",
      "  Mean FPS: 25.53 (50 images)\n",
      "Evaluating ../../runs/stage2_yolo11s_k_fold_cv_augmented/yolo11s_fold_2/weights/best.pt...\n",
      "Ultralytics 8.3.167 ðŸš€ Python-3.11.0rc1 torch-2.7.1+cu126 CUDA:0 (Tesla T4, 14914MiB)\n",
      "YOLO11s summary (fused): 100 layers, 9,414,735 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 692.3Â±225.2 MB/s, size: 11.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/andrea/work/AI-waste-detection/datasets/roboflow/test/labels.cache... 1099 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1099/1099 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:50<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1099       1622      0.813      0.781       0.82      0.615\n",
      "Speed: 0.7ms preprocess, 15.6ms inference, 0.0ms loss, 7.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val95\u001b[0m\n",
      "  Overall mAP@50: 0.8203\n",
      "  Per-class mAP@50: [0.9062221311876116, 0.9022015544422646, 0.7267870715335883, 0.9322952006956019, 0.6339653270545093]\n",
      "  Measuring FPS...\n",
      "  Mean FPS: 26.07 (50 images)\n",
      "Evaluating ../../runs/stage2_yolo11s_k_fold_cv_augmented/yolo11s_fold_1/weights/best.pt...\n",
      "Ultralytics 8.3.167 ðŸš€ Python-3.11.0rc1 torch-2.7.1+cu126 CUDA:0 (Tesla T4, 14914MiB)\n",
      "YOLO11s summary (fused): 100 layers, 9,414,735 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1919.2Â±1863.2 MB/s, size: 60.5 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/andrea/work/AI-waste-detection/datasets/roboflow/test/labels.cache... 1099 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1099/1099 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:49<00:00,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1099       1622      0.839      0.774      0.818      0.615\n",
      "Speed: 0.7ms preprocess, 15.6ms inference, 0.0ms loss, 7.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val96\u001b[0m\n",
      "  Overall mAP@50: 0.8181\n",
      "  Per-class mAP@50: [0.8773070016038595, 0.9167832625275951, 0.7433782994646206, 0.9467486812539049, 0.6062292122120075]\n",
      "  Measuring FPS...\n",
      "  Mean FPS: 26.88 (50 images)\n",
      "Evaluating ../../runs/stage2_yolo11s_k_fold_cv_augmented/yolo11s_fold_0/weights/best.pt...\n",
      "Ultralytics 8.3.167 ðŸš€ Python-3.11.0rc1 torch-2.7.1+cu126 CUDA:0 (Tesla T4, 14914MiB)\n",
      "YOLO11s summary (fused): 100 layers, 9,414,735 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1068.0Â±932.0 MB/s, size: 32.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/andrea/work/AI-waste-detection/datasets/roboflow/test/labels.cache... 1099 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1099/1099 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:25<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1099       1622      0.854      0.754       0.82      0.611\n",
      "Speed: 0.4ms preprocess, 10.0ms inference, 0.0ms loss, 3.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val97\u001b[0m\n",
      "  Overall mAP@50: 0.8197\n",
      "  Per-class mAP@50: [0.9022776775784258, 0.8944060805643207, 0.7323139333758623, 0.9514663915678255, 0.6179617212106178]\n",
      "  Measuring FPS...\n",
      "  Mean FPS: 40.46 (50 images)\n",
      "Completed yolo11s: 5 successful evaluations\n",
      "\n",
      "============================================================\n",
      "Evaluating yolo11x (YOLOv11-X)\n",
      "============================================================\n",
      "Evaluating ../../runs/stage3_yolo11x_fold0_subsampled/yolo11x_fold_0/weights/best.pt...\n",
      "Ultralytics 8.3.167 ðŸš€ Python-3.11.0rc1 torch-2.7.1+cu126 CUDA:0 (Tesla T4, 14914MiB)\n",
      "YOLO11x summary (fused): 190 layers, 56,832,799 parameters, 0 gradients, 194.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 809.0Â±337.1 MB/s, size: 10.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/andrea/work/AI-waste-detection/datasets/roboflow/test/labels.cache... 1099 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1099/1099 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [01:33<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       1099       1622       0.84      0.749      0.811       0.61\n",
      "Speed: 0.4ms preprocess, 70.0ms inference, 0.0ms loss, 3.5ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/val98\u001b[0m\n",
      "  Overall mAP@50: 0.8110\n",
      "  Per-class mAP@50: [0.8551476679619787, 0.9066016957685561, 0.7284465573052452, 0.9187055050620077, 0.6463144575577993]\n",
      "  Measuring FPS...\n",
      "  Mean FPS: 8.34 (50 images)\n",
      "Completed yolo11x: 1 successful evaluations\n",
      "\n",
      "============================================================\n",
      "EVALUATION COMPLETE\n",
      "============================================================\n",
      "Total models evaluated: 7\n",
      "  yolo11m: 1 folds\n",
      "  yolo11l: 1 folds\n",
      "  yolo11n: 5 folds\n",
      "  rtdetr-l: 1 folds\n",
      "  rtdetr-x: 1 folds\n",
      "  yolo11s: 5 folds\n",
      "  yolo11x: 1 folds\n"
     ]
    }
   ],
   "source": [
    "# Evaluate all models and collect results\n",
    "evaluation_results = {}\n",
    "\n",
    "for model_name, model_info in models_info.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Evaluating {model_name} ({model_info['family']}-{model_info['size']})\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Determine model type\n",
    "    model_type = 'rtdetr' if 'rtdetr' in model_name.lower() else 'yolo'\n",
    "    \n",
    "    fold_results = {}\n",
    "    \n",
    "    # Evaluate each fold\n",
    "    for fold_num, fold_info in model_info['folds'].items():\n",
    "        weights_path = fold_info['weights_path']\n",
    "        \n",
    "        # Evaluate this fold\n",
    "        result = evaluate_model(weights_path, model_type)\n",
    "        \n",
    "        if result is not None:\n",
    "            fold_results[fold_num] = result\n",
    "        else:\n",
    "            print(f\"  Failed to evaluate fold {fold_num}\")\n",
    "    \n",
    "    # Store results for this model\n",
    "    evaluation_results[model_name] = {\n",
    "        'family': model_info['family'],\n",
    "        'size': model_info['size'],\n",
    "        'fold_results': fold_results,\n",
    "        'stage': model_info['stage']\n",
    "    }\n",
    "    \n",
    "    print(f\"Completed {model_name}: {len(fold_results)} successful evaluations\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"EVALUATION COMPLETE\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total models evaluated: {len(evaluation_results)}\")\n",
    "for model_name, results in evaluation_results.items():\n",
    "    print(f\"  {model_name}: {len(results['fold_results'])} folds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86342470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yolo11m (YOLOv11-M):\n",
      "  Overall mAP@50: 0.8249 Â± 0.0000 (1 folds)\n",
      "  Mean FPS: 15.75 Â± 0.00\n",
      "  Per-class mAP@50: ['0.8936Â±0.0000', '0.9121Â±0.0000', '0.7415Â±0.0000', '0.9349Â±0.0000', '0.6423Â±0.0000']\n",
      "  Overall P: 0.8387 Â± 0.0000\n",
      "  Overall R: 0.7730 Â± 0.0000\n",
      "yolo11l (YOLOv11-L):\n",
      "  Overall mAP@50: 0.8086 Â± 0.0000 (1 folds)\n",
      "  Mean FPS: 24.23 Â± 0.00\n",
      "  Per-class mAP@50: ['0.8417Â±0.0000', '0.9206Â±0.0000', '0.7249Â±0.0000', '0.9427Â±0.0000', '0.6129Â±0.0000']\n",
      "  Overall P: 0.8313 Â± 0.0000\n",
      "  Overall R: 0.7577 Â± 0.0000\n",
      "yolo11n (YOLOv11-N):\n",
      "  Overall mAP@50: 0.8043 Â± 0.0072 (5 folds)\n",
      "  Mean FPS: 32.50 Â± 0.46\n",
      "  Per-class mAP@50: ['0.8684Â±0.0251', '0.9023Â±0.0160', '0.7041Â±0.0135', '0.9339Â±0.0095', '0.6128Â±0.0187']\n",
      "  Overall P: 0.8294 Â± 0.0753\n",
      "  Overall R: 0.7608 Â± 0.1396\n",
      "rtdetr-l (RT-DETRv2-L):\n",
      "  Overall mAP@50: 0.7537 Â± 0.0000 (1 folds)\n",
      "  Mean FPS: 9.51 Â± 0.00\n",
      "  Per-class mAP@50: ['0.8306Â±0.0000', '0.8587Â±0.0000', '0.6501Â±0.0000', '0.9143Â±0.0000', '0.5149Â±0.0000']\n",
      "  Overall P: 0.8289 Â± 0.0000\n",
      "  Overall R: 0.6988 Â± 0.0000\n",
      "rtdetr-x (RT-DETRv2-X):\n",
      "  Overall mAP@50: 0.7399 Â± 0.0000 (1 folds)\n",
      "  Mean FPS: 6.26 Â± 0.00\n",
      "  Per-class mAP@50: ['0.8469Â±0.0000', '0.8464Â±0.0000', '0.6535Â±0.0000', '0.8687Â±0.0000', '0.4842Â±0.0000']\n",
      "  Overall P: 0.7987 Â± 0.0000\n",
      "  Overall R: 0.7114 Â± 0.0000\n",
      "yolo11s (YOLOv11-S):\n",
      "  Overall mAP@50: 0.8181 Â± 0.0024 (5 folds)\n",
      "  Mean FPS: 28.56 Â± 6.03\n",
      "  Per-class mAP@50: ['0.8922Â±0.0117', '0.9077Â±0.0111', '0.7324Â±0.0095', '0.9373Â±0.0102', '0.6207Â±0.0106']\n",
      "  Overall P: 0.8392 Â± 0.0770\n",
      "  Overall R: 0.7655 Â± 0.1404\n",
      "yolo11x (YOLOv11-X):\n",
      "  Overall mAP@50: 0.8110 Â± 0.0000 (1 folds)\n",
      "  Mean FPS: 8.34 Â± 0.00\n",
      "  Per-class mAP@50: ['0.8551Â±0.0000', '0.9066Â±0.0000', '0.7284Â±0.0000', '0.9187Â±0.0000', '0.6463Â±0.0000']\n",
      "  Overall P: 0.8402 Â± 0.0000\n",
      "  Overall R: 0.7493 Â± 0.0000\n",
      "\n",
      "Summary complete for 7 models\n"
     ]
    }
   ],
   "source": [
    "# Calculate average and standard deviation across folds\n",
    "summary_results = []\n",
    "\n",
    "for model_name, results in evaluation_results.items():\n",
    "    if len(results['fold_results']) == 0:\n",
    "        print(f\"No results for {model_name}, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    # Collect per-class mAP@50 values across all folds\n",
    "    all_per_class_maps = []\n",
    "    all_overall_maps = []\n",
    "    all_fps = []\n",
    "    all_Ps = []\n",
    "    all_Rs = []\n",
    "    \n",
    "    for fold_num, fold_result in results['fold_results'].items():\n",
    "        all_per_class_maps.append(fold_result['per_class_map50'])\n",
    "        all_overall_maps.append(fold_result['overall_map50'])\n",
    "        all_fps.append(fold_result.get('mean_fps', 0.0))\n",
    "        all_Ps.append(fold_result.get('overall_P', 0.0))\n",
    "        all_Rs.append(fold_result.get('overall_R', 0.0))\n",
    "    \n",
    "    # Convert to numpy array for easier calculation\n",
    "    per_class_array = np.array(all_per_class_maps)  # Shape: (n_fooverall_P = lds, n_classes)\n",
    "    overall_array = np.array(all_overall_maps)\n",
    "    fps_array = np.array(all_fps)\n",
    "    overall_P_array = np.array(all_Ps)\n",
    "    overall_R_array = np.array(all_Rs)\n",
    "    \n",
    "    # Calculate mean and std for each class\n",
    "    mean_per_class = np.mean(per_class_array, axis=0)\n",
    "    std_per_class = np.std(per_class_array, axis=0) if len(all_per_class_maps) > 1 else np.zeros_like(mean_per_class)\n",
    "    \n",
    "    # Calculate mean and std for overall mAP@50\n",
    "    mean_overall = np.mean(overall_array)\n",
    "    std_overall = np.std(overall_array) if len(all_overall_maps) > 1 else 0.0\n",
    "    \n",
    "    # Calculate mean and std for FPS\n",
    "    mean_fps = np.mean(fps_array)\n",
    "    std_fps = np.std(fps_array) if len(all_fps) > 1 else 0.0\n",
    "\n",
    "    # Calculate mean and std for overall P and R\n",
    "    mean_P = np.mean(overall_P_array)\n",
    "    std_P = np.std(overall_P_array) if len(all_Ps) > 1 else 0.0\n",
    "    mean_R = np.mean(overall_R_array)\n",
    "    std_R = np.std(overall_R_array) if len(all_Rs) > 1 else 0.0\n",
    "    \n",
    "    # Create summary entry\n",
    "    summary_entry = {\n",
    "        'model_name': model_name,\n",
    "        'family': results['family'],\n",
    "        'size': results['size'],\n",
    "        'n_folds': len(results['fold_results']),\n",
    "        'mean_P': mean_P,\n",
    "        'std_P': std_P,\n",
    "        'mean_R': mean_R,\n",
    "        'std_R': std_R,\n",
    "        'mean_overall_map50': mean_overall,\n",
    "        'std_overall_map50': std_overall,\n",
    "        'mean_per_class_map50': mean_per_class.tolist(),\n",
    "        'std_per_class_map50': std_per_class.tolist(),\n",
    "        'mean_fps': mean_fps,\n",
    "        'std_fps': std_fps,\n",
    "        'stage': results['stage']\n",
    "    }\n",
    "    \n",
    "    summary_results.append(summary_entry)\n",
    "    \n",
    "    print(f\"{model_name} ({results['family']}-{results['size']}):\")\n",
    "    print(f\"  Overall mAP@50: {mean_overall:.4f} Â± {std_overall:.4f} ({len(results['fold_results'])} folds)\")\n",
    "    print(f\"  Mean FPS: {mean_fps:.2f} Â± {std_fps:.2f}\")\n",
    "    print(f\"  Per-class mAP@50: {[f'{m:.4f}Â±{s:.4f}' for m, s in zip(mean_per_class, std_per_class)]}\")\n",
    "    print(f\"  Overall P: {mean_P:.4f} Â± {std_P:.4f}\")\n",
    "    print(f\"  Overall R: {mean_R:.4f} Â± {std_R:.4f}\")\n",
    "\n",
    "print(f\"\\nSummary complete for {len(summary_results)} models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "833f951f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL PERFORMANCE SUMMARY\n",
      "================================================================================\n",
      "Model                Family       Size   mAP@50       P            R            FPS          Folds \n",
      "--------------------------------------------------------------------------------\n",
      "rtdetr-l             RT-DETRv2    L      0.754        0.829        0.699        9.5          1*    \n",
      "rtdetr-x             RT-DETRv2    X      0.740        0.799        0.711        6.3          1*    \n",
      "yolo11n              YOLOv11      N      0.804Â±0.007  0.829Â±0.075  0.761Â±0.140  32.5Â±0.5     5     \n",
      "yolo11s              YOLOv11      S      0.818Â±0.002  0.839Â±0.077  0.766Â±0.140  28.6Â±6.0     5     \n",
      "yolo11m              YOLOv11      M      0.825        0.839        0.773        15.8         1*    \n",
      "yolo11l              YOLOv11      L      0.809        0.831        0.758        24.2         1*    \n",
      "yolo11x              YOLOv11      X      0.811        0.840        0.749        8.3          1*    \n",
      "--------------------------------------------------------------------------------\n",
      "* Models evaluated on single fold only\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Display performance summary table (mAP@50 and FPS)\n",
    "def display_performance_summary(summary_results):\n",
    "    \"\"\"Display a summary table with overall mAP@50 and FPS for each model\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"MODEL PERFORMANCE SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"{'Model':<20} {'Family':<12} {'Size':<6} {'mAP@50':<12} {'P':<12} {'R':<12} {'FPS':<12} {'Folds':<6}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    # Sort results by family and size\n",
    "    def sort_key(result):\n",
    "        family = result['family']\n",
    "        size = result['size']\n",
    "        size_order = {'N': 0, 'S': 1, 'M': 2, 'L': 3, 'X': 4}\n",
    "        return (family, size_order.get(size, 999))\n",
    "    \n",
    "    sorted_results = sorted(summary_results, key=sort_key)\n",
    "    \n",
    "    for result in sorted_results:\n",
    "        model_name = result['model_name']\n",
    "        family = result['family']\n",
    "        size = result['size']\n",
    "        n_folds = result['n_folds']\n",
    "        \n",
    "        # Format mAP@50\n",
    "        if result['n_folds'] > 1 and result['std_overall_map50'] > 0.001:\n",
    "            map50_str = f\"{result['mean_overall_map50']:.3f}Â±{result['std_overall_map50']:.3f}\"\n",
    "        else:\n",
    "            map50_str = f\"{result['mean_overall_map50']:.3f}\"\n",
    "\n",
    "        # Format P and R\n",
    "        if result['n_folds'] > 1 and result['std_P'] > 0.001:\n",
    "            p_str = f\"{result['mean_P']:.3f}Â±{result['std_P']:.3f}\"\n",
    "        else:\n",
    "            p_str = f\"{result['mean_P']:.3f}\"\n",
    "\n",
    "        if result['n_folds'] > 1 and result['std_R'] > 0.001:\n",
    "            r_str = f\"{result['mean_R']:.3f}Â±{result['std_R']:.3f}\"\n",
    "        else:\n",
    "            r_str = f\"{result['mean_R']:.3f}\"\n",
    "        \n",
    "        # Format FPS\n",
    "        if result['n_folds'] > 1 and result['std_fps'] > 0.1:\n",
    "            fps_str = f\"{result['mean_fps']:.1f}Â±{result['std_fps']:.1f}\"\n",
    "        else:\n",
    "            fps_str = f\"{result['mean_fps']:.1f}\"\n",
    "        \n",
    "        fold_str = f\"{n_folds}\"\n",
    "        if n_folds == 1:\n",
    "            fold_str += \"*\"\n",
    "        \n",
    "        print(f\"{model_name:<20} {family:<12} {size:<6} {map50_str:<12} {p_str:<12} {r_str:<12} {fps_str:<12} {fold_str:<6}\")\n",
    "    \n",
    "    print(\"-\"*80)\n",
    "    print(\"* Models evaluated on single fold only\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "# Display the summary\n",
    "display_performance_summary(summary_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5eca7d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating LaTeX table...\n",
      "================================================================================\n",
      "\\begin{table*}[t]\n",
      "\\centering\n",
      "\\caption{Per-class AP@50 for each model variant. Results are averaged over multiple folds. \\\\\n",
      "Models marked with * were evaluated only on one fold.}\n",
      "\\label{tab:map50_per_class}\n",
      "\\begin{tabular}{lll|ccccc|c}\n",
      "\\toprule\n",
      "\\textbf{Model} & \\textbf{Family} & \\textbf{Size} & \\textbf{Glass} & \\textbf{Metal} & \\textbf{Organic} & \\textbf{Paper} & \\textbf{Plastic} & \\textbf{mAP@50} & \\textbf{P} \\ & \\textbf{R} && \\textbf{F1} \\\\\n",
      "\\midrule\n",
      "\\midrule\n",
      "RT-DETRv2-l* & RT-DETRv2 & l & 0.83 & 0.86 & 0.65 & 0.91 & 0.51 & \\textbf{0.754} & 0.829 & 0.699 & 0.758 \\\\\n",
      "RT-DETRv2-x* & RT-DETRv2 & x & 0.85 & 0.85 & 0.65 & 0.87 & 0.48 & \\textbf{0.740} & 0.799 & 0.711 & 0.753 \\\\\n",
      "YOLOv11-n & YOLOv11 & n & 0.87$\\pm$0.03 & 0.90$\\pm$0.02 & 0.70$\\pm$0.01 & 0.93$\\pm$0.01 & 0.61$\\pm$0.02 & \\textbf{0.804} & 0.829$\\pm$0.075 & 0.761$\\pm$0.140 & 0.794 \\\\\n",
      "YOLOv11-s & YOLOv11 & s & 0.89$\\pm$0.01 & 0.91$\\pm$0.01 & 0.73$\\pm$0.01 & 0.94$\\pm$0.01 & 0.62$\\pm$0.01 & \\textbf{0.818} & 0.839$\\pm$0.077 & 0.766$\\pm$0.140 & 0.801 \\\\\n",
      "YOLOv11-m* & YOLOv11 & m & 0.89 & 0.91 & 0.74 & 0.93 & 0.64 & \\textbf{0.825} & 0.839 & 0.773 & 0.804 \\\\\n",
      "YOLOv11-l* & YOLOv11 & l & 0.84 & 0.92 & 0.72 & 0.94 & 0.61 & \\textbf{0.809} & 0.831 & 0.758 & 0.793 \\\\\n",
      "YOLOv11-x* & YOLOv11 & x & 0.86 & 0.91 & 0.73 & 0.92 & 0.65 & \\textbf{0.811} & 0.840 & 0.749 & 0.792 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}%\n",
      "\\end{table*}\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Generate LaTeX table\n",
    "def generate_latex_table(summary_results, class_names):\n",
    "    \"\"\"Generate LaTeX table with per-class mAP@50 results including mean column\"\"\"\n",
    "\n",
    "    # Sort results by family and size\n",
    "    def sort_key(result):\n",
    "        family = result['family']\n",
    "        size = result['size'].upper()\n",
    "        size_order = {'N': 0, 'S': 1, 'M': 2, 'L': 3, 'X': 4}\n",
    "        return (family, size_order.get(size, 999))\n",
    "\n",
    "    sorted_results = sorted(summary_results, key=sort_key)\n",
    "\n",
    "    # Start LaTeX table\n",
    "    latex_table = []\n",
    "    latex_table.append(\"\\\\begin{table*}[t]\")\n",
    "    latex_table.append(\"\\\\centering\")\n",
    "    latex_table.append(\"\\\\caption{Per-class AP@50 for each model variant. Results are averaged over multiple folds. \\\\\\\\\")\n",
    "    latex_table.append(\"Models marked with * were evaluated only on one fold.}\")\n",
    "    latex_table.append(\"\\\\label{tab:map50_per_class}\")\n",
    "    latex_table.append(\"\\\\begin{tabular}{lll|\" + \"c\" * len(class_names) + \"|c}\")\n",
    "    latex_table.append(\"\\\\toprule\")\n",
    "\n",
    "    # Header\n",
    "    header = \"\\\\textbf{Model} & \\\\textbf{Family} & \\\\textbf{Size}\"\n",
    "    for class_name in class_names:\n",
    "        header += f\" & \\\\textbf{{{class_name.capitalize()}}}\"\n",
    "    header += \" & \\\\textbf{mAP@50}\"\n",
    "    header += \" & \\\\textbf{P} \\\\ & \\\\textbf{R} && \\\\textbf{F1} \\\\\\\\\"\n",
    "    latex_table.append(header)\n",
    "    latex_table.append(\"\\\\midrule\")\n",
    "\n",
    "    # Add rows\n",
    "    for result in sorted_results:\n",
    "        model_display = f\"{result['family']}-{result['size'].lower()}\"\n",
    "        if result['n_folds'] == 1:\n",
    "            model_display += \"*\"\n",
    "\n",
    "        family = result['family']\n",
    "        size = result['size'].lower()\n",
    "\n",
    "        row = f\"{model_display} & {family} & {size}\"\n",
    "\n",
    "        per_class_values = []\n",
    "        for mean_map, std_map in zip(result['mean_per_class_map50'], result['std_per_class_map50']):\n",
    "            per_class_values.append(mean_map)\n",
    "            if result['n_folds'] > 1 and std_map > 0.001:\n",
    "                row += f\" & {mean_map:.2f}$\\\\pm${std_map:.2f}\"\n",
    "            else:\n",
    "                row += f\" & {mean_map:.2f}\"\n",
    "\n",
    "        mean_map = sum(per_class_values) / len(per_class_values)\n",
    "        row += f\" & \\\\textbf{{{mean_map:.3f}}}\"\n",
    "\n",
    "        # add P, R and F1\n",
    "        row += f\" & {result['mean_P']:.3f}\"\n",
    "        if result['n_folds'] > 1 and result['std_P'] > 0.001:\n",
    "            row += f\"$\\\\pm${result['std_P']:.3f}\"\n",
    "        \n",
    "        row += f\" & {result['mean_R']:.3f}\"\n",
    "        if result['n_folds'] > 1 and result['std_R'] > 0.001:\n",
    "            row += f\"$\\\\pm${result['std_R']:.3f}\"\n",
    "        \n",
    "        f1_score = 2 * (result['mean_P'] * result['mean_R']) / (result['mean_P'] + result['mean_R']) if (result['mean_P'] + result['mean_R']) > 0 else 0.0\n",
    "        row += f\" & {f1_score:.3f} \\\\\\\\\"\n",
    "        latex_table.append(row)\n",
    "\n",
    "    # Add midrule between families if needed\n",
    "    yolo_count = sum(1 for r in sorted_results if r['family'] == 'YOLOv11')\n",
    "    rtdetr_count = sum(1 for r in sorted_results if r['family'] == 'RT-DETRv2')\n",
    "\n",
    "    if yolo_count > 0 and rtdetr_count > 0:\n",
    "        # Find the index where RT-DETR models start\n",
    "        rtdetr_start_idx = None\n",
    "        for i, line in enumerate(latex_table):\n",
    "            if \"RT-DETRv2\" in line:\n",
    "                rtdetr_start_idx = i\n",
    "                break\n",
    "\n",
    "        if rtdetr_start_idx is not None:\n",
    "            latex_table.insert(rtdetr_start_idx, \"\\\\midrule\")\n",
    "\n",
    "    latex_table.append(\"\\\\bottomrule\")\n",
    "    latex_table.append(\"\\\\end{tabular}%\")\n",
    "    latex_table.append(\"\\\\end{table*}\")\n",
    "\n",
    "    return \"\\n\".join(latex_table)\n",
    "\n",
    "print(\"\\nGenerating LaTeX table...\")\n",
    "latex_table = generate_latex_table(summary_results, class_names)\n",
    "print(\"=\" * 80)\n",
    "print(latex_table)\n",
    "print(\"=\" * 80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
