{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efd2d86c",
   "metadata": {},
   "source": [
    "# Model Evaluation and mAP@50 Testing\n",
    "\n",
    "This notebook evaluates all trained models on the test dataset and computes mAP@50 scores for each class.\n",
    "The results are averaged across folds where multiple folds exist for the same model variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48aaa24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import YOLO and RT-DETR\n",
    "from ultralytics import YOLO\n",
    "try:\n",
    "    from ultralytics import RTDETR\n",
    "except ImportError:\n",
    "    print(\"RT-DETR not available, will handle separately\")\n",
    "    RTDETR = None\n",
    "\n",
    "# Set up paths\n",
    "BASE_DIR = Path(\"../../\")\n",
    "RUNS_DIR = BASE_DIR / \"runs\"\n",
    "TEST_DATASET = BASE_DIR / \"datasets\" / \"roboflow\" / \"test\"\n",
    "DATA_YAML = BASE_DIR / \"datasets\" / \"roboflow\" / \"data.yaml\"\n",
    "\n",
    "print(f\"Base directory: {BASE_DIR}\")\n",
    "print(f\"Runs directory: {RUNS_DIR}\")\n",
    "print(f\"Test dataset: {TEST_DATASET}\")\n",
    "print(f\"Data YAML: {DATA_YAML}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afeaba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discover_model_weights():\n",
    "    \"\"\"\n",
    "    Discover all trained model weights in the runs directory\n",
    "    Returns a dictionary with model information\n",
    "    \"\"\"\n",
    "    models_info = {}\n",
    "    \n",
    "    # Define class names\n",
    "    class_names = ['glass', 'metal', 'organic', 'paper', 'plastic']\n",
    "    \n",
    "    # Scan all stage directories\n",
    "    for stage_dir in RUNS_DIR.glob(\"stage*\"):\n",
    "        print(f\"\\nScanning {stage_dir.name}:\")\n",
    "        \n",
    "        # Extract stage info\n",
    "        stage_name = stage_dir.name\n",
    "        \n",
    "        # Find all fold directories in this stage\n",
    "        fold_dirs = list(stage_dir.glob(\"*fold*\"))\n",
    "        \n",
    "        for fold_dir in fold_dirs:\n",
    "            weights_dir = fold_dir / \"weights\"\n",
    "            if weights_dir.exists():\n",
    "                # Find best.pt file\n",
    "                best_weights = weights_dir / \"best.pt\"\n",
    "                if best_weights.exists():\n",
    "                    print(f\"  Found: {fold_dir.name} -> {best_weights}\")\n",
    "                    \n",
    "                    # Extract model info\n",
    "                    model_name = fold_dir.name.split('_fold_')[0]\n",
    "                    fold_num = fold_dir.name.split('_fold_')[-1]\n",
    "                    \n",
    "                    # Special handling for yolo11m: only use fold_0 (other folds still training)\n",
    "                    if 'yolo11m' in model_name.lower() and fold_num != '0':\n",
    "                        print(f\"  Skipping {fold_dir.name} - using only fold_0 for yolo11m (other folds still training)\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Determine model family and type\n",
    "                    if 'rtdetr' in model_name.lower():\n",
    "                        family = 'RT-DETRv2'\n",
    "                        size = model_name.split('-')[-1].upper()\n",
    "                    else:\n",
    "                        family = 'YOLOv11'\n",
    "                        size = model_name[-1].upper()  # Extract last character (n, s, m, l, x)\n",
    "                    \n",
    "                    # Store model info\n",
    "                    if model_name not in models_info:\n",
    "                        models_info[model_name] = {\n",
    "                            'family': family,\n",
    "                            'size': size,\n",
    "                            'folds': {},\n",
    "                            'stage': stage_name\n",
    "                        }\n",
    "                    \n",
    "                    models_info[model_name]['folds'][fold_num] = {\n",
    "                        'weights_path': str(best_weights),\n",
    "                        'fold_dir': str(fold_dir)\n",
    "                    }\n",
    "                else:\n",
    "                    print(f\"  Missing best.pt: {fold_dir.name}\")\n",
    "    \n",
    "    return models_info, class_names\n",
    "\n",
    "# Discover all models\n",
    "models_info, class_names = discover_model_weights()\n",
    "print(f\"\\nFound {len(models_info)} unique models:\")\n",
    "for model_name, info in models_info.items():\n",
    "    print(f\"  {model_name}: {len(info['folds'])} folds ({info['family']}-{info['size']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77faa745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import cv2\n",
    "\n",
    "def evaluate_model(weights_path, model_type='yolo'):\n",
    "    \"\"\"\n",
    "    Evaluate a single model on the test dataset and return per-class mAP@50 and FPS\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if model_type == 'yolo':\n",
    "            # Load YOLO model\n",
    "            model = YOLO(weights_path)\n",
    "        elif model_type == 'rtdetr':\n",
    "            # Load RT-DETR model\n",
    "            if RTDETR is None:\n",
    "                print(f\"RT-DETR not available, skipping {weights_path}\")\n",
    "                return None\n",
    "            model = RTDETR(weights_path)\n",
    "        else:\n",
    "            print(f\"Unknown model type: {model_type}\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"Evaluating {weights_path}...\")\n",
    "        \n",
    "        # Run validation on test dataset\n",
    "        results = model.val(data=str(DATA_YAML), split='test', verbose=False)\n",
    "        \n",
    "        # Extract per-class mAP@50\n",
    "        if hasattr(results, 'box') and hasattr(results.box, 'map50'):\n",
    "            # Overall mAP@50\n",
    "            overall_map50 = results.box.map50\n",
    "            \n",
    "            # Per-class mAP@50\n",
    "            if hasattr(results.box, 'ap50') and results.box.ap50 is not None:\n",
    "                per_class_map50 = results.box.ap50.tolist()\n",
    "            else:\n",
    "                print(f\"Warning: No per-class mAP@50 available for {weights_path}\")\n",
    "                per_class_map50 = [0.0] * 5  # Default to zeros\n",
    "            \n",
    "            print(f\"  Overall mAP@50: {overall_map50:.4f}\")\n",
    "            print(f\"  Per-class mAP@50: {per_class_map50}\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"Error: Could not extract mAP@50 from results for {weights_path}\")\n",
    "            return None\n",
    "        \n",
    "        # Measure FPS on test images\n",
    "        print(f\"  Measuring FPS...\")\n",
    "        test_images_dir = TEST_DATASET / \"images\"\n",
    "        test_images = list(test_images_dir.glob(\"*.jpg\")) + list(test_images_dir.glob(\"*.png\"))\n",
    "        \n",
    "        # Use a subset of test images for FPS measurement (to save time)\n",
    "        fps_test_images = test_images[:min(50, len(test_images))]  # Use max 50 images\n",
    "        \n",
    "        if len(fps_test_images) == 0:\n",
    "            print(f\"  Warning: No test images found for FPS measurement\")\n",
    "            mean_fps = 0.0\n",
    "        else:\n",
    "            # Warm up the model (first few predictions are usually slower)\n",
    "            if len(fps_test_images) >= 3:\n",
    "                for warmup_img in fps_test_images[:3]:\n",
    "                    _ = model.predict(str(warmup_img), verbose=False)\n",
    "            \n",
    "            # Measure inference time\n",
    "            inference_times = []\n",
    "            \n",
    "            for img_path in fps_test_images:\n",
    "                start_time = time.time()\n",
    "                _ = model.predict(str(img_path), verbose=False)\n",
    "                end_time = time.time()\n",
    "                inference_times.append(end_time - start_time)\n",
    "            \n",
    "            # Calculate mean FPS\n",
    "            mean_inference_time = np.mean(inference_times)\n",
    "            mean_fps = 1.0 / mean_inference_time if mean_inference_time > 0 else 0.0\n",
    "            \n",
    "            print(f\"  Mean FPS: {mean_fps:.2f} ({len(fps_test_images)} images)\")\n",
    "        \n",
    "        return {\n",
    "            'overall_map50': overall_map50,\n",
    "            'per_class_map50': per_class_map50,\n",
    "            'class_names': class_names,\n",
    "            'mean_fps': mean_fps,\n",
    "            'num_fps_images': len(fps_test_images) if 'fps_test_images' in locals() else 0\n",
    "        }\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating {weights_path}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8be58cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all models and collect results\n",
    "evaluation_results = {}\n",
    "\n",
    "for model_name, model_info in models_info.items():\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Evaluating {model_name} ({model_info['family']}-{model_info['size']})\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Determine model type\n",
    "    model_type = 'rtdetr' if 'rtdetr' in model_name.lower() else 'yolo'\n",
    "    \n",
    "    fold_results = {}\n",
    "    \n",
    "    # Evaluate each fold\n",
    "    for fold_num, fold_info in model_info['folds'].items():\n",
    "        weights_path = fold_info['weights_path']\n",
    "        \n",
    "        # Evaluate this fold\n",
    "        result = evaluate_model(weights_path, model_type)\n",
    "        \n",
    "        if result is not None:\n",
    "            fold_results[fold_num] = result\n",
    "        else:\n",
    "            print(f\"  Failed to evaluate fold {fold_num}\")\n",
    "    \n",
    "    # Store results for this model\n",
    "    evaluation_results[model_name] = {\n",
    "        'family': model_info['family'],\n",
    "        'size': model_info['size'],\n",
    "        'fold_results': fold_results,\n",
    "        'stage': model_info['stage']\n",
    "    }\n",
    "    \n",
    "    print(f\"Completed {model_name}: {len(fold_results)} successful evaluations\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"EVALUATION COMPLETE\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Total models evaluated: {len(evaluation_results)}\")\n",
    "for model_name, results in evaluation_results.items():\n",
    "    print(f\"  {model_name}: {len(results['fold_results'])} folds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86342470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average and standard deviation across folds\n",
    "summary_results = []\n",
    "\n",
    "for model_name, results in evaluation_results.items():\n",
    "    if len(results['fold_results']) == 0:\n",
    "        print(f\"No results for {model_name}, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    # Collect per-class mAP@50 values across all folds\n",
    "    all_per_class_maps = []\n",
    "    all_overall_maps = []\n",
    "    all_fps = []\n",
    "    \n",
    "    for fold_num, fold_result in results['fold_results'].items():\n",
    "        all_per_class_maps.append(fold_result['per_class_map50'])\n",
    "        all_overall_maps.append(fold_result['overall_map50'])\n",
    "        all_fps.append(fold_result.get('mean_fps', 0.0))\n",
    "    \n",
    "    # Convert to numpy array for easier calculation\n",
    "    per_class_array = np.array(all_per_class_maps)  # Shape: (n_folds, n_classes)\n",
    "    overall_array = np.array(all_overall_maps)\n",
    "    fps_array = np.array(all_fps)\n",
    "    \n",
    "    # Calculate mean and std for each class\n",
    "    mean_per_class = np.mean(per_class_array, axis=0)\n",
    "    std_per_class = np.std(per_class_array, axis=0) if len(all_per_class_maps) > 1 else np.zeros_like(mean_per_class)\n",
    "    \n",
    "    # Calculate mean and std for overall mAP@50\n",
    "    mean_overall = np.mean(overall_array)\n",
    "    std_overall = np.std(overall_array) if len(all_overall_maps) > 1 else 0.0\n",
    "    \n",
    "    # Calculate mean and std for FPS\n",
    "    mean_fps = np.mean(fps_array)\n",
    "    std_fps = np.std(fps_array) if len(all_fps) > 1 else 0.0\n",
    "    \n",
    "    # Create summary entry\n",
    "    summary_entry = {\n",
    "        'model_name': model_name,\n",
    "        'family': results['family'],\n",
    "        'size': results['size'],\n",
    "        'n_folds': len(results['fold_results']),\n",
    "        'mean_overall_map50': mean_overall,\n",
    "        'std_overall_map50': std_overall,\n",
    "        'mean_per_class_map50': mean_per_class.tolist(),\n",
    "        'std_per_class_map50': std_per_class.tolist(),\n",
    "        'mean_fps': mean_fps,\n",
    "        'std_fps': std_fps,\n",
    "        'stage': results['stage']\n",
    "    }\n",
    "    \n",
    "    summary_results.append(summary_entry)\n",
    "    \n",
    "    print(f\"{model_name} ({results['family']}-{results['size']}):\")\n",
    "    print(f\"  Overall mAP@50: {mean_overall:.4f} ± {std_overall:.4f} ({len(results['fold_results'])} folds)\")\n",
    "    print(f\"  Mean FPS: {mean_fps:.2f} ± {std_fps:.2f}\")\n",
    "    print(f\"  Per-class mAP@50: {[f'{m:.4f}±{s:.4f}' for m, s in zip(mean_per_class, std_per_class)]}\")\n",
    "\n",
    "print(f\"\\nSummary complete for {len(summary_results)} models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833f951f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display performance summary table (mAP@50 and FPS)\n",
    "def display_performance_summary(summary_results):\n",
    "    \"\"\"Display a summary table with overall mAP@50 and FPS for each model\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"MODEL PERFORMANCE SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"{'Model':<20} {'Family':<12} {'Size':<6} {'mAP@50':<12} {'FPS':<12} {'Folds':<6}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    # Sort results by family and size\n",
    "    def sort_key(result):\n",
    "        family = result['family']\n",
    "        size = result['size']\n",
    "        size_order = {'N': 0, 'S': 1, 'M': 2, 'L': 3, 'X': 4}\n",
    "        return (family, size_order.get(size, 999))\n",
    "    \n",
    "    sorted_results = sorted(summary_results, key=sort_key)\n",
    "    \n",
    "    for result in sorted_results:\n",
    "        model_name = result['model_name']\n",
    "        family = result['family']\n",
    "        size = result['size']\n",
    "        n_folds = result['n_folds']\n",
    "        \n",
    "        # Format mAP@50\n",
    "        if result['n_folds'] > 1 and result['std_overall_map50'] > 0.001:\n",
    "            map50_str = f\"{result['mean_overall_map50']:.3f}±{result['std_overall_map50']:.3f}\"\n",
    "        else:\n",
    "            map50_str = f\"{result['mean_overall_map50']:.3f}\"\n",
    "        \n",
    "        # Format FPS\n",
    "        if result['n_folds'] > 1 and result['std_fps'] > 0.1:\n",
    "            fps_str = f\"{result['mean_fps']:.1f}±{result['std_fps']:.1f}\"\n",
    "        else:\n",
    "            fps_str = f\"{result['mean_fps']:.1f}\"\n",
    "        \n",
    "        fold_str = f\"{n_folds}\"\n",
    "        if n_folds == 1:\n",
    "            fold_str += \"*\"\n",
    "        \n",
    "        print(f\"{model_name:<20} {family:<12} {size:<6} {map50_str:<12} {fps_str:<12} {fold_str:<6}\")\n",
    "    \n",
    "    print(\"-\"*80)\n",
    "    print(\"* Models evaluated on single fold only\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "# Display the summary\n",
    "display_performance_summary(summary_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eca7d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate LaTeX table\n",
    "def generate_latex_table(summary_results, class_names):\n",
    "    \"\"\"Generate LaTeX table with per-class mAP@50 results including mean column\"\"\"\n",
    "\n",
    "    # Sort results by family and size\n",
    "    def sort_key(result):\n",
    "        family = result['family']\n",
    "        size = result['size'].upper()\n",
    "        size_order = {'N': 0, 'S': 1, 'M': 2, 'L': 3, 'X': 4}\n",
    "        return (family, size_order.get(size, 999))\n",
    "\n",
    "    sorted_results = sorted(summary_results, key=sort_key)\n",
    "\n",
    "    # Start LaTeX table\n",
    "    latex_table = []\n",
    "    latex_table.append(\"\\\\begin{table*}[t]\")\n",
    "    latex_table.append(\"\\\\centering\")\n",
    "    latex_table.append(\"\\\\caption{Per-class AP@50 for each model variant. Results are averaged over multiple folds. \\\\\\\\\")\n",
    "    latex_table.append(\"Models marked with * were evaluated only on one fold.}\")\n",
    "    latex_table.append(\"\\\\label{tab:map50_per_class}\")\n",
    "    latex_table.append(\"\\\\begin{tabular}{lll\" + \"c\" * len(class_names) + \"c}\")\n",
    "    latex_table.append(\"\\\\toprule\")\n",
    "\n",
    "    # Header\n",
    "    header = \"\\\\textbf{Model} & \\\\textbf{Family} & \\\\textbf{Size}\"\n",
    "    for class_name in class_names:\n",
    "        header += f\" & \\\\textbf{{{class_name.capitalize()}}}\"\n",
    "    header += \" & \\\\textbf{mAP@50} \\\\\\\\\"\n",
    "    latex_table.append(header)\n",
    "    latex_table.append(\"\\\\midrule\")\n",
    "\n",
    "    # Add rows\n",
    "    for result in sorted_results:\n",
    "        model_display = f\"{result['family']}-{result['size'].lower()}\"\n",
    "        if result['n_folds'] == 1:\n",
    "            model_display += \"*\"\n",
    "\n",
    "        family = result['family']\n",
    "        size = result['size'].lower()\n",
    "\n",
    "        row = f\"{model_display} & {family} & {size}\"\n",
    "\n",
    "        per_class_values = []\n",
    "        for mean_map, std_map in zip(result['mean_per_class_map50'], result['std_per_class_map50']):\n",
    "            per_class_values.append(mean_map)\n",
    "            if result['n_folds'] > 1 and std_map > 0.001:\n",
    "                row += f\" & {mean_map:.2f}$\\\\pm${std_map:.2f}\"\n",
    "            else:\n",
    "                row += f\" & {mean_map:.2f}\"\n",
    "\n",
    "        mean_map = sum(per_class_values) / len(per_class_values)\n",
    "        row += f\" & \\\\textbf{{{mean_map:.3f}}} \\\\\\\\\"\n",
    "        latex_table.append(row)\n",
    "\n",
    "    # Add midrule between families if needed\n",
    "    yolo_count = sum(1 for r in sorted_results if r['family'] == 'YOLOv11')\n",
    "    rtdetr_count = sum(1 for r in sorted_results if r['family'] == 'RT-DETRv2')\n",
    "\n",
    "    if yolo_count > 0 and rtdetr_count > 0:\n",
    "        # Find the index where RT-DETR models start\n",
    "        rtdetr_start_idx = None\n",
    "        for i, line in enumerate(latex_table):\n",
    "            if \"RT-DETRv2\" in line:\n",
    "                rtdetr_start_idx = i\n",
    "                break\n",
    "\n",
    "        if rtdetr_start_idx is not None:\n",
    "            latex_table.insert(rtdetr_start_idx, \"\\\\midrule\")\n",
    "\n",
    "    latex_table.append(\"\\\\bottomrule\")\n",
    "    latex_table.append(\"\\\\end{tabular}%\")\n",
    "    latex_table.append(\"\\\\end{table*}\")\n",
    "\n",
    "    return \"\\n\".join(latex_table)\n",
    "\n",
    "print(\"\\nGenerating LaTeX table...\")\n",
    "latex_table = generate_latex_table(summary_results, class_names)\n",
    "print(\"=\" * 80)\n",
    "print(latex_table)\n",
    "print(\"=\" * 80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
