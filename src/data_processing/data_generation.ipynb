{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d62bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, random, pathlib, uuid\n",
    "import cv2, numpy as np\n",
    "from pycocotools.coco import COCO\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaeab67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Cut an object from an image and paste onto a background\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pycocotools.coco import COCO\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Load COCO annotations\n",
    "annotation_file = '../../datasets/taco_official/annotations.json'\n",
    "coco = COCO(annotation_file)\n",
    "\n",
    "# Load an example image\n",
    "image_dir = '../../datasets/taco_official/'\n",
    "image_info = coco.loadImgs(coco.getImgIds()[0])[0]\n",
    "image_path = os.path.join(image_dir, image_info['file_name'])\n",
    "print(f\"Loading image: {image_path}\")\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Check if image was loaded successfully\n",
    "if image is None:\n",
    "    print(f\"Error: Could not load image at {image_path}\")\n",
    "    print(f\"File exists: {os.path.exists(image_path)}\")\n",
    "    # Try to find the image in subdirectories\n",
    "    for batch_dir in os.listdir(image_dir):\n",
    "        if batch_dir.startswith('batch_'):\n",
    "            test_path = os.path.join(image_dir, batch_dir, image_info['file_name'])\n",
    "            if os.path.exists(test_path):\n",
    "                image_path = test_path\n",
    "                image = cv2.imread(image_path)\n",
    "                print(f\"Found image at: {image_path}\")\n",
    "                break\n",
    "\n",
    "# Get annotations for the image\n",
    "annotation_ids = coco.getAnnIds(imgIds=image_info['id'])\n",
    "annotations = coco.loadAnns(annotation_ids)\n",
    "\n",
    "if len(annotations) == 0:\n",
    "    print(\"No annotations found for this image\")\n",
    "else:\n",
    "    # Extract the first object using its segmentation mask\n",
    "    mask = coco.annToMask(annotations[0])\n",
    "    \n",
    "    # Ensure mask has the same dimensions as the image\n",
    "    if image is not None and mask.shape[:2] == image.shape[:2]:\n",
    "        # Create a 3-channel mask for bitwise operations\n",
    "        mask_3d = np.stack([mask] * 3, axis=-1)\n",
    "        object_img = image * mask_3d\n",
    "        \n",
    "        # Create a random background\n",
    "        background = np.random.randint(0, 256, image.shape, dtype=np.uint8)\n",
    "        \n",
    "        # Create a simple composite by placing the object on the background\n",
    "        result = np.where(mask_3d > 0, object_img, background)\n",
    "        \n",
    "        # Display the result\n",
    "        import matplotlib.pyplot as plt\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.title('Original Image')\n",
    "        plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.title('Mask')\n",
    "        plt.imshow(mask, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.title('Synthetic Image')\n",
    "        plt.imshow(cv2.cvtColor(result, cv2.COLOR_BGR2RGB))\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Error: Image shape {image.shape if image is not None else 'None'} doesn't match mask shape {mask.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f519e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Examples: Cut multiple objects and create various synthetic scenarios\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pycocotools.coco import COCO\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load COCO annotations\n",
    "annotation_file = '../../datasets/taco_official/annotations.json'\n",
    "coco = COCO(annotation_file)\n",
    "\n",
    "def find_image_path(image_dir, filename):\n",
    "    \"\"\"Helper function to find the correct image path\"\"\"\n",
    "    # Try direct path first\n",
    "    direct_path = os.path.join(image_dir, filename)\n",
    "    if os.path.exists(direct_path):\n",
    "        return direct_path\n",
    "    \n",
    "    # Search in batch directories\n",
    "    for item in os.listdir(image_dir):\n",
    "        if item.startswith('batch_'):\n",
    "            test_path = os.path.join(image_dir, item, filename)\n",
    "            if os.path.exists(test_path):\n",
    "                return test_path\n",
    "    return None\n",
    "\n",
    "def extract_object(image, mask):\n",
    "    \"\"\"Extract an object from an image using a mask\"\"\"\n",
    "    if image is None or mask is None:\n",
    "        return None\n",
    "    \n",
    "    # Ensure mask dimensions match image\n",
    "    if mask.shape[:2] != image.shape[:2]:\n",
    "        return None\n",
    "    \n",
    "    # Create 3-channel mask\n",
    "    mask_3d = np.stack([mask] * 3, axis=-1)\n",
    "    return image * mask_3d\n",
    "\n",
    "def get_bounding_box_from_mask(mask):\n",
    "    \"\"\"Extract bounding box coordinates from a binary mask\"\"\"\n",
    "    coords = np.where(mask > 0)\n",
    "    if len(coords[0]) == 0:\n",
    "        return None\n",
    "    \n",
    "    y_min, y_max = coords[0].min(), coords[0].max()\n",
    "    x_min, x_max = coords[1].min(), coords[1].max()\n",
    "    \n",
    "    return [int(x_min), int(y_min), int(x_max - x_min), int(y_max - y_min)]  # [x, y, width, height]\n",
    "\n",
    "def draw_bounding_box(image, bbox, color=(0, 255, 0), thickness=2):\n",
    "    \"\"\"Draw a bounding box on an image\"\"\"\n",
    "    if bbox is None:\n",
    "        return image\n",
    "    \n",
    "    img_with_box = image.copy()\n",
    "    x, y, w, h = bbox\n",
    "    \n",
    "    # Convert to integers to ensure OpenCV compatibility\n",
    "    x, y, w, h = int(x), int(y), int(w), int(h)\n",
    "    \n",
    "    cv2.rectangle(img_with_box, (x, y), (x + w, y + h), color, thickness)\n",
    "    \n",
    "    # Add area text\n",
    "    area = w * h\n",
    "    cv2.putText(img_with_box, f'Area: {area}px', (x, y - 10), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "    \n",
    "    return img_with_box\n",
    "\n",
    "def create_background(shape, bg_type='random'):\n",
    "    \"\"\"Create different types of backgrounds\"\"\"\n",
    "    if bg_type == 'random':\n",
    "        return np.random.randint(0, 256, shape, dtype=np.uint8)\n",
    "    elif bg_type == 'gradient':\n",
    "        h, w = shape[:2]\n",
    "        gradient = np.linspace(0, 255, w, dtype=np.uint8)\n",
    "        background = np.tile(gradient, (h, 1))\n",
    "        return np.stack([background] * 3, axis=-1)\n",
    "    elif bg_type == 'solid':\n",
    "        color = [random.randint(50, 200) for _ in range(3)]\n",
    "        return np.full(shape, color, dtype=np.uint8)\n",
    "    else:\n",
    "        return np.zeros(shape, dtype=np.uint8)\n",
    "\n",
    "# Get category names for better labeling\n",
    "categories = coco.loadCats(coco.getCatIds())\n",
    "category_names = {cat['id']: cat['name'] for cat in categories}\n",
    "\n",
    "# Get multiple images with annotations\n",
    "image_dir = '../../datasets/taco_official/'\n",
    "image_ids = coco.getImgIds()[:5]  # Get first 5 images\n",
    "\n",
    "examples = []\n",
    "for img_id in image_ids:\n",
    "    image_info = coco.loadImgs(img_id)[0]\n",
    "    image_path = find_image_path(image_dir, image_info['file_name'])\n",
    "    \n",
    "    if image_path:\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is not None:\n",
    "            # Get annotations for this image\n",
    "            annotation_ids = coco.getAnnIds(imgIds=img_id)\n",
    "            annotations = coco.loadAnns(annotation_ids)\n",
    "            \n",
    "            if len(annotations) > 0:\n",
    "                examples.append({\n",
    "                    'image': image,\n",
    "                    'annotations': annotations,\n",
    "                    'filename': image_info['file_name']\n",
    "                })\n",
    "    \n",
    "    if len(examples) >= 3:  # Limit to 3 examples for display\n",
    "        break\n",
    "\n",
    "# Create synthetic examples with bounding boxes\n",
    "fig, axes = plt.subplots(3, 5, figsize=(20, 12))\n",
    "fig.suptitle('Object Cutting and Synthetic Generation with Bounding Boxes', fontsize=16)\n",
    "\n",
    "for i, example in enumerate(examples):\n",
    "    if i >= 3:\n",
    "        break\n",
    "        \n",
    "    image = example['image']\n",
    "    annotations = example['annotations']\n",
    "    filename = example['filename']\n",
    "    \n",
    "    # Original image with bounding box\n",
    "    original_with_bbox = image.copy()\n",
    "    first_annotation = annotations[0]\n",
    "    \n",
    "    # Draw original bounding box from annotation\n",
    "    if 'bbox' in first_annotation:\n",
    "        original_bbox = first_annotation['bbox']  # COCO format: [x, y, width, height]\n",
    "        original_with_bbox = draw_bounding_box(original_with_bbox, original_bbox, (255, 0, 0), 3)\n",
    "        \n",
    "        # Add category label\n",
    "        category_name = category_names.get(first_annotation['category_id'], f\"Cat {first_annotation['category_id']}\")\n",
    "        cv2.putText(original_with_bbox, category_name, \n",
    "                   (int(original_bbox[0]), int(original_bbox[1] - 30)), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "    \n",
    "    axes[i, 0].imshow(cv2.cvtColor(original_with_bbox, cv2.COLOR_BGR2RGB))\n",
    "    axes[i, 0].set_title(f'Original: {filename}')\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    # Extract first object\n",
    "    mask = coco.annToMask(annotations[0])\n",
    "    object_img = extract_object(image, mask)\n",
    "    \n",
    "    if object_img is not None:\n",
    "        # Show mask\n",
    "        axes[i, 1].imshow(mask, cmap='gray')\n",
    "        axes[i, 1].set_title('Segmentation Mask')\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # Get bounding box from mask\n",
    "        mask_bbox = get_bounding_box_from_mask(mask)\n",
    "        \n",
    "        # Create synthetic image with random background\n",
    "        bg_random = create_background(image.shape, 'random')\n",
    "        mask_3d = np.stack([mask] * 3, axis=-1)\n",
    "        synthetic_random = np.where(mask_3d > 0, object_img, bg_random)\n",
    "        \n",
    "        # Draw bounding box on synthetic image\n",
    "        synthetic_random_with_bbox = draw_bounding_box(synthetic_random, mask_bbox, (0, 255, 0), 2)\n",
    "        \n",
    "        axes[i, 2].imshow(cv2.cvtColor(synthetic_random_with_bbox, cv2.COLOR_BGR2RGB))\n",
    "        axes[i, 2].set_title('Random Background + BBox')\n",
    "        axes[i, 2].axis('off')\n",
    "        \n",
    "        # Create synthetic image with gradient background\n",
    "        bg_gradient = create_background(image.shape, 'gradient')\n",
    "        synthetic_gradient = np.where(mask_3d > 0, object_img, bg_gradient)\n",
    "        \n",
    "        # Draw bounding box on gradient synthetic image\n",
    "        synthetic_gradient_with_bbox = draw_bounding_box(synthetic_gradient, mask_bbox, (0, 255, 0), 2)\n",
    "        \n",
    "        axes[i, 3].imshow(cv2.cvtColor(synthetic_gradient_with_bbox, cv2.COLOR_BGR2RGB))\n",
    "        axes[i, 3].set_title('Gradient Background + BBox')\n",
    "        axes[i, 3].axis('off')\n",
    "        \n",
    "        # Create synthetic image with solid background\n",
    "        bg_solid = create_background(image.shape, 'solid')\n",
    "        synthetic_solid = np.where(mask_3d > 0, object_img, bg_solid)\n",
    "        \n",
    "        # Draw bounding box on solid synthetic image\n",
    "        synthetic_solid_with_bbox = draw_bounding_box(synthetic_solid, mask_bbox, (0, 255, 0), 2)\n",
    "        \n",
    "        axes[i, 4].imshow(cv2.cvtColor(synthetic_solid_with_bbox, cv2.COLOR_BGR2RGB))\n",
    "        axes[i, 4].set_title('Solid Background + BBox')\n",
    "        axes[i, 4].axis('off')\n",
    "        \n",
    "        # Print bounding box information\n",
    "        print(f\"\\nImage {i+1}: {filename}\")\n",
    "        print(f\"  Category: {category_names.get(first_annotation['category_id'], 'Unknown')}\")\n",
    "        if 'bbox' in first_annotation:\n",
    "            orig_bbox = first_annotation['bbox']\n",
    "            print(f\"  Original BBox: [{orig_bbox[0]:.0f}, {orig_bbox[1]:.0f}, {orig_bbox[2]:.0f}, {orig_bbox[3]:.0f}]\")\n",
    "        if mask_bbox:\n",
    "            print(f\"  Mask BBox:     [{mask_bbox[0]}, {mask_bbox[1]}, {mask_bbox[2]}, {mask_bbox[3]}]\")\n",
    "            print(f\"  Object Area:   {mask_bbox[2] * mask_bbox[3]} pixels\")\n",
    "        \n",
    "    else:\n",
    "        # If extraction failed, show empty plots\n",
    "        for j in range(1, 5):\n",
    "            axes[i, j].text(0.5, 0.5, 'Processing\\nFailed', \n",
    "                          ha='center', va='center', transform=axes[i, j].transAxes)\n",
    "            axes[i, j].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nProcessed {len(examples)} examples successfully!\")\n",
    "print(\"Red boxes: Original annotations from dataset\")\n",
    "print(\"Green boxes: Computed from segmentation masks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078bd21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Synthetic Generation: Object Bank + Real Backgrounds\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pycocotools.coco import COCO\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "def extract_object(image, mask):\n",
    "    \"\"\"Extract a tightly cropped object from an image using a mask.\"\"\"\n",
    "    if image is None or mask is None or mask.shape[:2] != image.shape[:2]:\n",
    "        return None, None\n",
    "\n",
    "    # Find the bounding box of the object from the mask\n",
    "    coords = np.where(mask > 0)\n",
    "    if len(coords[0]) == 0:\n",
    "        return None, None\n",
    "    \n",
    "    y_min, y_max = coords[0].min(), coords[0].max()\n",
    "    x_min, x_max = coords[1].min(), coords[1].max()\n",
    "\n",
    "    # Crop the mask and the image to the bounding box\n",
    "    cropped_mask = mask[y_min:y_max+1, x_min:x_max+1]\n",
    "    cropped_image = image[y_min:y_max+1, x_min:x_max+1]\n",
    "\n",
    "    # Apply the mask to the cropped image\n",
    "    mask_3d = np.stack([cropped_mask] * 3, axis=-1)\n",
    "    extracted_obj = np.where(mask_3d > 0, cropped_image, 0)\n",
    "    \n",
    "    return extracted_obj, cropped_mask\n",
    "\n",
    "def resize_object_and_mask(obj_img, mask, scale_factor):\n",
    "    \"\"\"Resize an object and its mask\"\"\"\n",
    "    h, w = mask.shape\n",
    "    new_h, new_w = int(h * scale_factor), int(w * scale_factor)\n",
    "    \n",
    "    if new_h <= 0 or new_w <= 0:\n",
    "        return None, None\n",
    "    \n",
    "    resized_obj = cv2.resize(obj_img, (new_w, new_h))\n",
    "    resized_mask = cv2.resize(mask.astype(np.uint8), (new_w, new_h))\n",
    "    \n",
    "    return resized_obj, resized_mask\n",
    "\n",
    "def create_object_mask_regions(image, annotations, coco):\n",
    "    \"\"\"Create a mask of all annotated objects in an image to find clean background areas\"\"\"\n",
    "    mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "    \n",
    "    for ann in annotations:\n",
    "        obj_mask = coco.annToMask(ann)\n",
    "        if obj_mask.shape[:2] == image.shape[:2]:\n",
    "            mask = np.logical_or(mask, obj_mask).astype(np.uint8)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def get_clean_background_region(image, object_mask, region_size=(400, 400)):\n",
    "    \"\"\"Extract a clean background region without objects\"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    region_h, region_w = region_size\n",
    "    \n",
    "    # Try multiple random positions to find a clean area\n",
    "    for _ in range(50):\n",
    "        start_y = random.randint(0, max(0, h - region_h))\n",
    "        start_x = random.randint(0, max(0, w - region_w))\n",
    "        \n",
    "        end_y = min(start_y + region_h, h)\n",
    "        end_x = min(start_x + region_w, w)\n",
    "        \n",
    "        # Check if this region has minimal objects\n",
    "        region_mask = object_mask[start_y:end_y, start_x:end_x]\n",
    "        object_ratio = np.sum(region_mask) / (region_mask.shape[0] * region_mask.shape[1])\n",
    "        \n",
    "        if object_ratio < 0.1:  # Less than 10% objects\n",
    "            return image[start_y:end_y, start_x:end_x]\n",
    "    \n",
    "    # If no clean region found, return a random region\n",
    "    start_y = random.randint(0, max(0, h - region_h))\n",
    "    start_x = random.randint(0, max(0, w - region_w))\n",
    "    end_y = min(start_y + region_h, h)\n",
    "    end_x = min(start_x + region_w, w)\n",
    "    return image[start_y:end_y, start_x:end_x]\n",
    "\n",
    "def place_object_on_background_with_annotation(background, obj_img, mask, x_pos, y_pos, category_id, object_id):\n",
    "    \"\"\"Place an object on background and return annotation info\"\"\"\n",
    "    obj_h, obj_w = obj_img.shape[:2]\n",
    "    bg_h, bg_w = background.shape[:2]\n",
    "    \n",
    "    # Ensure the object fits within the background\n",
    "    end_y = min(y_pos + obj_h, bg_h)\n",
    "    end_x = min(x_pos + obj_w, bg_w)\n",
    "    actual_h = end_y - y_pos\n",
    "    actual_w = end_x - x_pos\n",
    "    \n",
    "    if actual_h <= 0 or actual_w <= 0:\n",
    "        return background, None\n",
    "    \n",
    "    # Crop object and mask if necessary\n",
    "    obj_crop = obj_img[:actual_h, :actual_w]\n",
    "    mask_crop = mask[:actual_h, :actual_w]\n",
    "    \n",
    "    # Create 3D mask for blending\n",
    "    mask_3d = np.stack([mask_crop] * 3, axis=-1)\n",
    "    \n",
    "    # Blend the object onto the background\n",
    "    background_region = background[y_pos:end_y, x_pos:end_x]\n",
    "    blended_region = np.where(mask_3d > 0, obj_crop, background_region)\n",
    "    background[y_pos:end_y, x_pos:end_x] = blended_region\n",
    "    \n",
    "    # Create annotation info\n",
    "    bbox = [x_pos, y_pos, actual_w, actual_h]\n",
    "    area = int(np.sum(mask_crop > 0))\n",
    "    \n",
    "    annotation = {\n",
    "        \"id\": object_id,\n",
    "        \"category_id\": category_id,\n",
    "        \"bbox\": bbox,\n",
    "        \"area\": area,\n",
    "        \"iscrowd\": 0\n",
    "    }\n",
    "    \n",
    "    return background, annotation\n",
    "\n",
    "def draw_all_bboxes(image, annotations, category_names, original_color=(255, 0, 0), synthetic_color=(0, 255, 0)):\n",
    "    \"\"\"Draw bounding boxes for both original and synthetic objects\"\"\"\n",
    "    img_with_boxes = image.copy()\n",
    "    \n",
    "    for ann in annotations:\n",
    "        if ann is None:\n",
    "            continue\n",
    "            \n",
    "        x, y, w, h = ann['bbox']\n",
    "        x, y, w, h = int(x), int(y), int(w), int(h)\n",
    "        category_id = ann['category_id']\n",
    "        \n",
    "        # Use different colors for original vs synthetic\n",
    "        color = original_color if ann.get('is_original', False) else synthetic_color\n",
    "        \n",
    "        # Draw rectangle\n",
    "        cv2.rectangle(img_with_boxes, (x, y), (x + w, y + h), color, 2)\n",
    "        \n",
    "        # Add label\n",
    "        cat_name = category_names.get(category_id, f\"Cat {category_id}\")\n",
    "        label = f\"{cat_name}\"\n",
    "        \n",
    "        # Add text background\n",
    "        (text_width, text_height), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)\n",
    "        cv2.rectangle(img_with_boxes, (x, y - text_height - 5), (x + text_width, y), color, -1)\n",
    "        cv2.putText(img_with_boxes, label, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "    \n",
    "    return img_with_boxes\n",
    "\n",
    "# Load COCO annotations\n",
    "annotation_file = '../../datasets/taco_official/annotations.json'\n",
    "coco = COCO(annotation_file)\n",
    "\n",
    "# Get category names\n",
    "categories = coco.loadCats(coco.getCatIds())\n",
    "category_names = {cat['id']: cat['name'] for cat in categories}\n",
    "\n",
    "print(\"Building object bank...\")\n",
    "# Build object bank\n",
    "object_bank = defaultdict(list)\n",
    "background_images = []\n",
    "\n",
    "image_dir = '../../datasets/taco_official/'\n",
    "image_ids = coco.getImgIds()[:20]  # Process more images for better variety\n",
    "\n",
    "for img_id in image_ids:\n",
    "    image_info = coco.loadImgs(img_id)[0]\n",
    "    image_path = find_image_path(image_dir, image_info['file_name'])\n",
    "    \n",
    "    if image_path:\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is not None:\n",
    "            annotation_ids = coco.getAnnIds(imgIds=img_id)\n",
    "            annotations = coco.loadAnns(annotation_ids)\n",
    "            \n",
    "            if len(annotations) > 0:\n",
    "                # Extract objects for the bank\n",
    "                for ann in annotations:\n",
    "                    mask = coco.annToMask(ann)\n",
    "                    if mask.shape[:2] == image.shape[:2] and np.sum(mask) > 500:  # Filter small objects\n",
    "                        obj_img, cropped_mask = extract_object(image, mask)\n",
    "                        if obj_img is not None:\n",
    "                            object_bank[ann['category_id']].append({\n",
    "                                'object': obj_img,\n",
    "                                'mask': cropped_mask,\n",
    "                                'category_id': ann['category_id'],\n",
    "                                'source_image': image_info['file_name']\n",
    "                            })\n",
    "                \n",
    "                # Store background images\n",
    "                object_mask = create_object_mask_regions(image, annotations, coco)\n",
    "                background_images.append({\n",
    "                    'image': image,\n",
    "                    'object_mask': object_mask,\n",
    "                    'annotations': annotations,\n",
    "                    'filename': image_info['file_name']\n",
    "                })\n",
    "\n",
    "print(f\"Object bank built with {sum(len(objects) for objects in object_bank.values())} objects\")\n",
    "print(f\"Categories in bank: {list(object_bank.keys())}\")\n",
    "print(f\"Available background images: {len(background_images)}\")\n",
    "\n",
    "# Create synthetic scenes using real backgrounds + object bank\n",
    "print(\"\\nGenerating synthetic scenes...\")\n",
    "\n",
    "# Select 3 background images for synthetic generation\n",
    "selected_backgrounds = random.sample(background_images, min(3, len(background_images)))\n",
    "\n",
    "fig, axes = plt.subplots(len(selected_backgrounds), 2, figsize=(15, 7 * len(selected_backgrounds)))\n",
    "if len(selected_backgrounds) == 1:\n",
    "    axes = [axes] # Make it iterable\n",
    "fig.suptitle('Synthetic Generation: Adding Objects Directly to Images', fontsize=16)\n",
    "\n",
    "synthetic_data = []\n",
    "\n",
    "for i, bg_data in enumerate(selected_backgrounds):\n",
    "    background_img = bg_data['image']\n",
    "    original_annotations = bg_data['annotations']\n",
    "    filename = bg_data['filename']\n",
    "    object_mask = bg_data['object_mask']\n",
    "    \n",
    "    # Create a copy of the original image to add objects to\n",
    "    synthetic_scene = background_img.copy()\n",
    "    \n",
    "    # Prepare original annotations with a flag\n",
    "    original_anns_with_flag = []\n",
    "    for ann in original_annotations:\n",
    "        if 'bbox' in ann:\n",
    "            ann_copy = ann.copy()\n",
    "            ann_copy['is_original'] = True\n",
    "            original_anns_with_flag.append(ann_copy)\n",
    "    \n",
    "    # Display the original image with its bounding boxes\n",
    "    original_with_all_bboxes = draw_all_bboxes(background_img, original_anns_with_flag, category_names)\n",
    "    axes[i, 0].imshow(cv2.cvtColor(original_with_all_bboxes, cv2.COLOR_BGR2RGB))\n",
    "    axes[i, 0].set_title(f'Original: {filename}\\n({len(original_annotations)} objects)')\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    # --- Create synthetic scene by adding objects to the original image ---\n",
    "    synthetic_annotations = []\n",
    "    \n",
    "    # Add 2-4 random objects from the bank\n",
    "    num_objects = random.randint(2, 4)\n",
    "    available_categories = [cat for cat in object_bank.keys() if len(object_bank[cat]) > 0]\n",
    "    \n",
    "    if len(available_categories) > 0:\n",
    "        object_id_counter = max([ann['id'] for ann in original_annotations], default=0) + 1\n",
    "        \n",
    "        for _ in range(num_objects):\n",
    "            cat_id = random.choice(available_categories)\n",
    "            obj_data = random.choice(object_bank[cat_id])\n",
    "            obj_img, mask = obj_data['object'], obj_data['mask']\n",
    "            \n",
    "            scale = random.uniform(0.7, 1.4)\n",
    "            resized_obj, resized_mask = resize_object_and_mask(obj_img, mask, scale)\n",
    "            \n",
    "            if resized_obj is None:\n",
    "                continue\n",
    "\n",
    "            # Try to place the object in a relatively empty area\n",
    "            best_pos = None\n",
    "            min_overlap = float('inf')\n",
    "            \n",
    "            for _ in range(20): # Try 20 random positions\n",
    "                margin = 10\n",
    "                max_x = max(margin, synthetic_scene.shape[1] - resized_obj.shape[1] - margin)\n",
    "                max_y = max(margin, synthetic_scene.shape[0] - resized_obj.shape[0] - margin)\n",
    "                \n",
    "                if max_x <= margin or max_y <= margin: continue\n",
    "\n",
    "                x_pos = random.randint(margin, max_x)\n",
    "                y_pos = random.randint(margin, max_y)\n",
    "\n",
    "                # Check overlap with existing objects\n",
    "                h, w = resized_obj.shape[:2]\n",
    "                overlap_region = object_mask[y_pos:y_pos+h, x_pos:x_pos+w]\n",
    "                overlap_ratio = np.sum(overlap_region) / (h * w) if h > 0 and w > 0 else 1\n",
    "\n",
    "                if overlap_ratio < min_overlap:\n",
    "                    min_overlap = overlap_ratio\n",
    "                    best_pos = (x_pos, y_pos)\n",
    "\n",
    "                if overlap_ratio < 0.2: # Found a good spot\n",
    "                    break\n",
    "            \n",
    "            if best_pos:\n",
    "                x_pos, y_pos = best_pos\n",
    "                synthetic_scene, annotation = place_object_on_background_with_annotation(\n",
    "                    synthetic_scene, resized_obj, resized_mask, x_pos, y_pos, cat_id, object_id_counter\n",
    "                )\n",
    "                if annotation:\n",
    "                    annotation['is_original'] = False\n",
    "                    synthetic_annotations.append(annotation)\n",
    "                    object_id_counter += 1\n",
    "\n",
    "    # Combine original and new annotations for final visualization\n",
    "    all_annotations = original_anns_with_flag + synthetic_annotations\n",
    "    \n",
    "    # Draw all bounding boxes on the augmented scene\n",
    "    synthetic_with_all_boxes = draw_all_bboxes(synthetic_scene, all_annotations, category_names)\n",
    "    \n",
    "    axes[i, 1].imshow(cv2.cvtColor(synthetic_with_all_boxes, cv2.COLOR_BGR2RGB))\n",
    "    axes[i, 1].set_title(f'Augmented Scene\\n({len(synthetic_annotations)} added objects)')\n",
    "    axes[i, 1].axis('off')\n",
    "    \n",
    "    # Store synthetic data\n",
    "    synthetic_data.append({\n",
    "        'original_image': background_img,\n",
    "        'original_annotations': original_anns_with_flag,\n",
    "        'synthetic_scene': synthetic_scene,\n",
    "        'synthetic_annotations': synthetic_annotations,\n",
    "        'filename': filename\n",
    "    })\n",
    "    \n",
    "    # Print details\n",
    "    print(f\"\\nSynthetic Scene {i+1} ({filename}):\")\n",
    "    print(f\"  Original objects: {len(original_annotations)}\")\n",
    "    print(f\"  Added objects: {len(synthetic_annotations)}\")\n",
    "    for ann in synthetic_annotations:\n",
    "        cat_name = category_names.get(ann['category_id'], f\"Category {ann['category_id']}\")\n",
    "        bbox = ann['bbox']\n",
    "        print(f\"    - {cat_name}: bbox=[{int(bbox[0])}, {int(bbox[1])}, {int(bbox[2])}, {int(bbox[3])}], area={ann['area']}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display object bank statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"OBJECT BANK STATISTICS:\")\n",
    "print(\"=\"*60)\n",
    "for cat_id, objects in object_bank.items():\n",
    "    cat_name = category_names.get(cat_id, f\"Category {cat_id}\")\n",
    "    print(f\"{cat_name}: {len(objects)} objects\")\n",
    "\n",
    "print(f\"\\nTotal synthetic scenes generated: {len(synthetic_data)}\")\n",
    "print(\"Green boxes: Synthetic objects added to scenes\")\n",
    "print(\"Red boxes: Original objects from dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24273ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic Generation with Fake Backgrounds, Rotation, and No Overlap\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pycocotools.coco import COCO\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "def create_background(shape, bg_type='random'):\n",
    "    \"\"\"Create different types of backgrounds\"\"\"\n",
    "    if bg_type == 'random':\n",
    "        return np.random.randint(0, 256, shape, dtype=np.uint8)\n",
    "    elif bg_type == 'gradient':\n",
    "        h, w = shape[:2]\n",
    "        gradient = np.linspace(0, 255, w, dtype=np.uint8)\n",
    "        background = np.tile(gradient, (h, 1))\n",
    "        return np.stack([background] * 3, axis=-1)\n",
    "    elif bg_type == 'solid':\n",
    "        color = [random.randint(50, 200) for _ in range(3)]\n",
    "        return np.full(shape, color, dtype=np.uint8)\n",
    "    else:\n",
    "        return np.zeros(shape, dtype=np.uint8)\n",
    "\n",
    "def rotate_object_and_mask(image, mask, angle):\n",
    "    \"\"\"Rotates an object and its mask, returning the new images and bounding box.\"\"\"\n",
    "    h, w = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "\n",
    "    # Get the rotation matrix\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "\n",
    "    # Calculate the new bounding box size\n",
    "    cos = np.abs(M[0, 0])\n",
    "    sin = np.abs(M[0, 1])\n",
    "    new_w = int((h * sin) + (w * cos))\n",
    "    new_h = int((h * cos) + (w * sin))\n",
    "\n",
    "    # Adjust the rotation matrix to account for translation\n",
    "    M[0, 2] += (new_w / 2) - center[0]\n",
    "    M[1, 2] += (new_h / 2) - center[1]\n",
    "\n",
    "    # Perform the rotation\n",
    "    rotated_image = cv2.warpAffine(image, M, (new_w, new_h))\n",
    "    rotated_mask = cv2.warpAffine(mask, M, (new_w, new_h))\n",
    "\n",
    "    # The new bounding box is simply the size of the new image\n",
    "    new_bbox = (0, 0, new_w, new_h)\n",
    "    \n",
    "    return rotated_image, rotated_mask, new_bbox\n",
    "\n",
    "# We can reuse the object bank from the previous cell if it has been run.\n",
    "# If not, we should build it again.\n",
    "if 'object_bank' not in locals() or not object_bank:\n",
    "    print(\"Object bank not found. Building it now...\")\n",
    "    # Load COCO annotations\n",
    "    annotation_file = '../../datasets/taco_official/annotations.json'\n",
    "    coco = COCO(annotation_file)\n",
    "\n",
    "    # Get category names\n",
    "    categories = coco.loadCats(coco.getCatIds())\n",
    "    category_names = {cat['id']: cat['name'] for cat in categories}\n",
    "\n",
    "    object_bank = defaultdict(list)\n",
    "    image_dir = '../../datasets/taco_official/'\n",
    "    image_ids = coco.getImgIds()[:50]  # Process images to build a decent bank\n",
    "\n",
    "    for img_id in image_ids:\n",
    "        image_info = coco.loadImgs(img_id)[0]\n",
    "        image_path = find_image_path(image_dir, image_info['file_name'])\n",
    "        \n",
    "        if image_path:\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is not None:\n",
    "                annotation_ids = coco.getAnnIds(imgIds=img_id)\n",
    "                annotations = coco.loadAnns(annotation_ids)\n",
    "                \n",
    "                for ann in annotations:\n",
    "                    mask = coco.annToMask(ann)\n",
    "                    if mask.shape[:2] == image.shape[:2] and np.sum(mask) > 500:\n",
    "                        obj_img, cropped_mask = extract_object(image, mask)\n",
    "                        if obj_img is not None:\n",
    "                            object_bank[ann['category_id']].append({\n",
    "                                'object': obj_img,\n",
    "                                'mask': cropped_mask,\n",
    "                                'category_id': ann['category_id']\n",
    "                            })\n",
    "    print(f\"Object bank built with {sum(len(objects) for objects in object_bank.values())} objects.\")\n",
    "\n",
    "\n",
    "# --- Generate synthetic scenes with fake backgrounds ---\n",
    "print(\"\\nGenerating synthetic scenes with fake backgrounds...\")\n",
    "\n",
    "num_synthetic_images = 4\n",
    "fig, axes = plt.subplots(1, num_synthetic_images, figsize=(20, 5))\n",
    "fig.suptitle('Synthetic Scenes with Fake Backgrounds, Rotation & No Overlap', fontsize=16)\n",
    "\n",
    "synthetic_scenes_data = []\n",
    "\n",
    "for i in range(num_synthetic_images):\n",
    "    bg_shape = (random.randint(600, 800), random.randint(800, 1200), 3)\n",
    "    bg_type = random.choice(['random', 'gradient', 'solid'])\n",
    "    background = create_background(bg_shape, bg_type)\n",
    "    placement_mask = np.zeros(bg_shape[:2], dtype=np.uint8)\n",
    "    \n",
    "    synthetic_annotations = []\n",
    "    num_objects = random.randint(3, 7)\n",
    "    available_categories = [cat for cat in object_bank.keys() if len(object_bank[cat]) > 0]\n",
    "    object_id_counter = 1\n",
    "\n",
    "    if len(available_categories) > 0:\n",
    "        for _ in range(num_objects):\n",
    "            cat_id = random.choice(available_categories)\n",
    "            obj_data = random.choice(object_bank[cat_id])\n",
    "            obj_img, mask = obj_data['object'], obj_data['mask']\n",
    "            \n",
    "            # --- Rotation ---\n",
    "            angle = random.uniform(0, 360)\n",
    "            rotated_obj, rotated_mask, _ = rotate_object_and_mask(obj_img, mask, angle)\n",
    "\n",
    "            # --- Scaling ---\n",
    "            bg_h, bg_w = background.shape[:2]\n",
    "            obj_h, obj_w = rotated_obj.shape[:2]\n",
    "            max_scale = min(bg_h / obj_h if obj_h > 0 else 1, bg_w / obj_w if obj_w > 0 else 1, 1.0) # Cap scale at 1.0\n",
    "            min_scale = 0.4 # Increased from 0.2\n",
    "            if max_scale <= min_scale:\n",
    "                scale = max_scale\n",
    "            else:\n",
    "                scale = random.uniform(min_scale, max_scale)\n",
    "            \n",
    "            resized_obj, resized_mask = resize_object_and_mask(rotated_obj, rotated_mask, scale)\n",
    "            if resized_obj is None:\n",
    "                continue\n",
    "\n",
    "            # --- Placement (avoid overlap) ---\n",
    "            best_pos = None\n",
    "            min_overlap = float('inf')\n",
    "            for _ in range(20):\n",
    "                max_x = max(1, background.shape[1] - resized_obj.shape[1])\n",
    "                max_y = max(1, background.shape[0] - resized_obj.shape[0])\n",
    "                x_pos, y_pos = random.randint(0, max_x), random.randint(0, max_y)\n",
    "                \n",
    "                h, w = resized_obj.shape[:2]\n",
    "                overlap_region = placement_mask[y_pos:y_pos+h, x_pos:x_pos+w]\n",
    "                overlap = np.sum(overlap_region > 0)\n",
    "                \n",
    "                if overlap < min_overlap:\n",
    "                    min_overlap = overlap\n",
    "                    best_pos = (x_pos, y_pos)\n",
    "                if overlap == 0:\n",
    "                    break # Found a perfect spot\n",
    "\n",
    "            if best_pos:\n",
    "                x_pos, y_pos = best_pos\n",
    "                background, annotation = place_object_on_background_with_annotation(\n",
    "                    background, resized_obj, resized_mask, x_pos, y_pos, cat_id, object_id_counter\n",
    "                )\n",
    "                if annotation:\n",
    "                    synthetic_annotations.append(annotation)\n",
    "                    object_id_counter += 1\n",
    "                    # Update placement mask\n",
    "                    h, w = resized_obj.shape[:2]\n",
    "                    placement_mask[y_pos:y_pos+h, x_pos:x_pos+w] = 255\n",
    "\n",
    "    # Draw bounding boxes on the final scene\n",
    "    scene_with_boxes = draw_all_bboxes(background, synthetic_annotations, category_names, synthetic_color=(0, 255, 0))\n",
    "    \n",
    "    axes[i].imshow(cv2.cvtColor(scene_with_boxes, cv2.COLOR_BGR2RGB))\n",
    "    axes[i].set_title(f'Scene {i+1} ({bg_type} bg)\\n{len(synthetic_annotations)} objects')\n",
    "    axes[i].axis('off')\n",
    "    \n",
    "    synthetic_scenes_data.append({\n",
    "        'scene': scene_with_boxes,\n",
    "        'annotations': synthetic_annotations\n",
    "    })\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "plt.show()\n",
    "\n",
    "# Print details for the first generated scene\n",
    "if synthetic_scenes_data:\n",
    "    print(\"\\nDetails for the first generated scene:\")\n",
    "    first_scene_data = synthetic_scenes_data[0]\n",
    "    print(f\"  - Total objects: {len(first_scene_data['annotations'])}\")\n",
    "    for ann in first_scene_data['annotations']:\n",
    "        cat_name = category_names.get(ann['category_id'], f\"Category {ann['category_id']}\")\n",
    "        bbox = ann['bbox']\n",
    "        print(f\"    - {cat_name}: bbox=[{int(bbox[0])}, {int(bbox[1])}, {int(bbox[2])}, {int(bbox[3])}], area={ann['area']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1063406a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6a0c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Exploration: Analisi del bilanciamento del dataset TACO\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter, defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "# Carica le annotazioni TACO\n",
    "annotation_file = '../../datasets/taco_official/annotations.json'\n",
    "with open(annotation_file, 'r') as f:\n",
    "    taco_data = json.load(f)\n",
    "\n",
    "# Estrai informazioni sui dati\n",
    "images = taco_data['images']\n",
    "annotations = taco_data['annotations']\n",
    "categories = taco_data['categories']\n",
    "\n",
    "print(\"=== STATISTICHE GENERALI DEL DATASET TACO ===\")\n",
    "print(f\"Numero totale di immagini: {len(images)}\")\n",
    "print(f\"Numero totale di annotazioni: {len(annotations)}\")\n",
    "print(f\"Numero di categorie: {len(categories)}\")\n",
    "\n",
    "# Crea mapping categoria_id -> nome categoria\n",
    "id_to_category = {cat['id']: cat['name'] for cat in categories}\n",
    "print(\"\\nCategorie disponibili:\")\n",
    "for cat_id, cat_name in id_to_category.items():\n",
    "    print(f\"  {cat_id}: {cat_name}\")\n",
    "\n",
    "# Analizza la distribuzione delle categorie\n",
    "category_counts = Counter()\n",
    "annotations_per_image = defaultdict(int)\n",
    "category_per_image = defaultdict(set)\n",
    "\n",
    "for ann in annotations:\n",
    "    category_counts[ann['category_id']] += 1\n",
    "    annotations_per_image[ann['image_id']] += 1\n",
    "    category_per_image[ann['image_id']].add(ann['category_id'])\n",
    "\n",
    "print(f\"\\n=== BILANCIAMENTO DELLE CLASSI ===\")\n",
    "print(\"Distribuzione degli oggetti per categoria:\")\n",
    "\n",
    "# Crea DataFrame per analisi più dettagliata\n",
    "category_stats = []\n",
    "for cat_id, count in category_counts.most_common():\n",
    "    cat_name = id_to_category[cat_id]\n",
    "    percentage = (count / len(annotations)) * 100\n",
    "    category_stats.append({\n",
    "        'category_id': cat_id,\n",
    "        'category_name': cat_name,\n",
    "        'count': count,\n",
    "        'percentage': percentage\n",
    "    })\n",
    "    print(f\"  {cat_name}: {count} oggetti ({percentage:.1f}%)\")\n",
    "\n",
    "df_categories = pd.DataFrame(category_stats)\n",
    "\n",
    "# Calcola statistiche di bilanciamento\n",
    "max_count = df_categories['count'].max()\n",
    "min_count = df_categories['count'].min()\n",
    "imbalance_ratio = max_count / min_count if min_count > 0 else float('inf')\n",
    "\n",
    "print(f\"\\nStatistiche di bilanciamento:\")\n",
    "print(f\"  Categoria più rappresentata: {df_categories.iloc[0]['category_name']} ({max_count} oggetti)\")\n",
    "print(f\"  Categoria meno rappresentata: {df_categories.iloc[-1]['category_name']} ({min_count} oggetti)\")\n",
    "print(f\"  Rapporto di sbilanciamento: {imbalance_ratio:.1f}:1\")\n",
    "\n",
    "# Analizza annotazioni per immagine\n",
    "ann_per_img_stats = list(annotations_per_image.values())\n",
    "print(f\"\\n=== STATISTICHE ANNOTAZIONI PER IMMAGINE ===\")\n",
    "print(f\"Media annotazioni per immagine: {np.mean(ann_per_img_stats):.1f}\")\n",
    "print(f\"Mediana annotazioni per immagine: {np.median(ann_per_img_stats):.1f}\")\n",
    "print(f\"Min annotazioni per immagine: {min(ann_per_img_stats)}\")\n",
    "print(f\"Max annotazioni per immagine: {max(ann_per_img_stats)}\")\n",
    "\n",
    "# Immagini senza annotazioni\n",
    "images_without_annotations = len(images) - len(annotations_per_image)\n",
    "print(f\"Immagini senza annotazioni: {images_without_annotations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f12621e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizzazioni per l'analisi del bilanciamento\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Analisi del Bilanciamento del Dataset TACO', fontsize=16)\n",
    "\n",
    "# 1. Distribuzione delle categorie (bar plot)\n",
    "ax1 = axes[0, 0]\n",
    "bars = ax1.bar(range(len(df_categories)), df_categories['count'], \n",
    "               color=plt.cm.viridis(np.linspace(0, 1, len(df_categories))))\n",
    "ax1.set_xlabel('Categorie')\n",
    "ax1.set_ylabel('Numero di Oggetti')\n",
    "ax1.set_title('Distribuzione degli Oggetti per Categoria')\n",
    "ax1.set_xticks(range(len(df_categories)))\n",
    "ax1.set_xticklabels([cat[:15] + '...' if len(cat) > 15 else cat \n",
    "                     for cat in df_categories['category_name']], rotation=45, ha='right')\n",
    "\n",
    "# Aggiungi valori sopra le barre\n",
    "for i, bar in enumerate(bars):\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f'{int(height)}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# 2. Distribuzione percentuale (pie chart per le top 10)\n",
    "ax2 = axes[0, 1]\n",
    "top_10 = df_categories.head(10)\n",
    "others_count = df_categories.tail(len(df_categories) - 10)['count'].sum()\n",
    "if others_count > 0:\n",
    "    pie_data = list(top_10['count']) + [others_count]\n",
    "    pie_labels = list(top_10['category_name']) + ['Altri']\n",
    "else:\n",
    "    pie_data = list(top_10['count'])\n",
    "    pie_labels = list(top_10['category_name'])\n",
    "\n",
    "wedges, texts, autotexts = ax2.pie(pie_data, labels=pie_labels, autopct='%1.1f%%', startangle=90)\n",
    "ax2.set_title('Distribuzione Percentuale (Top 10 + Altri)')\n",
    "for text in texts:\n",
    "    text.set_fontsize(8)\n",
    "for autotext in autotexts:\n",
    "    autotext.set_fontsize(8)\n",
    "    autotext.set_color('white')\n",
    "\n",
    "# 3. Annotazioni per immagine\n",
    "ax3 = axes[1, 0]\n",
    "ax3.hist(ann_per_img_stats, bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "ax3.set_xlabel('Numero di Annotazioni per Immagine')\n",
    "ax3.set_ylabel('Frequenza')\n",
    "ax3.set_title('Distribuzione delle Annotazioni per Immagine')\n",
    "ax3.axvline(np.mean(ann_per_img_stats), color='red', linestyle='--', \n",
    "           label=f'Media: {np.mean(ann_per_img_stats):.1f}')\n",
    "ax3.axvline(np.median(ann_per_img_stats), color='orange', linestyle='--',\n",
    "           label=f'Mediana: {np.median(ann_per_img_stats):.1f}')\n",
    "ax3.legend()\n",
    "\n",
    "# 4. Heatmap del bilanciamento\n",
    "ax4 = axes[1, 1]\n",
    "# Calcola il target count (media o mediana)\n",
    "target_count = int(np.mean(df_categories['count']))\n",
    "balance_scores = df_categories['count'] / target_count\n",
    "colors = ['red' if score < 0.5 else 'orange' if score < 0.8 else 'green' for score in balance_scores]\n",
    "\n",
    "bars = ax4.barh(range(len(df_categories)), balance_scores, color=colors)\n",
    "ax4.set_yticks(range(len(df_categories)))\n",
    "ax4.set_yticklabels([cat[:20] + '...' if len(cat) > 20 else cat \n",
    "                     for cat in df_categories['category_name']], fontsize=8)\n",
    "ax4.set_xlabel('Score di Bilanciamento (relativo alla media)')\n",
    "ax4.set_title('Score di Bilanciamento per Categoria')\n",
    "ax4.axvline(1.0, color='black', linestyle='--', alpha=0.5, label='Target (media)')\n",
    "ax4.legend()\n",
    "\n",
    "# Aggiungi valori accanto alle barre\n",
    "for i, bar in enumerate(bars):\n",
    "    width = bar.get_width()\n",
    "    ax4.text(width + 0.05, bar.get_y() + bar.get_height()/2.,\n",
    "             f'{width:.2f}', ha='left', va='center', fontsize=7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Stampa raccomandazioni per il bilanciamento\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RACCOMANDAZIONI PER IL BILANCIAMENTO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "target_per_category = int(np.median(df_categories['count']))  # Usiamo la mediana come target\n",
    "print(f\"Target oggetti per categoria: {target_per_category}\")\n",
    "\n",
    "print(\"\\nCategorie che necessitano di augmentazione:\")\n",
    "for _, row in df_categories.iterrows():\n",
    "    if row['count'] < target_per_category:\n",
    "        needed = target_per_category - row['count']\n",
    "        print(f\"  {row['category_name']}: +{needed} oggetti ({row['count']} -> {target_per_category})\")\n",
    "\n",
    "print(\"\\nCategorie sovra-rappresentate:\")\n",
    "for _, row in df_categories.iterrows():\n",
    "    if row['count'] > target_per_category * 1.5:\n",
    "        excess = row['count'] - target_per_category\n",
    "        print(f\"  {row['category_name']}: -{excess} oggetti ({row['count']} -> {target_per_category})\")\n",
    "\n",
    "# Salva le statistiche in un file per uso futuro\n",
    "df_categories.to_csv('../../datasets/taco_category_statistics.csv', index=False)\n",
    "print(f\"\\nStatistiche salvate in: ../../datasets/taco_category_statistics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b36ac10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sistema di Generazione Dataset Bilanciato - Versione Corretta\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def simple_extract_object(image, mask):\n",
    "    \"\"\"Versione semplificata di extract_object\"\"\"\n",
    "    if image is None or mask is None:\n",
    "        return None, None\n",
    "    \n",
    "    # Assicurati che le dimensioni corrispondano\n",
    "    if mask.shape[:2] != image.shape[:2]:\n",
    "        return None, None\n",
    "    \n",
    "    # Trova il bounding box dell'oggetto dalla maschera\n",
    "    coords = np.where(mask > 0)\n",
    "    if len(coords[0]) == 0:\n",
    "        return None, None\n",
    "    \n",
    "    y_min, y_max = coords[0].min(), coords[0].max()\n",
    "    x_min, x_max = coords[1].min(), coords[1].max()\n",
    "\n",
    "    # Ritaglia la maschera e l'immagine al bounding box\n",
    "    cropped_mask = mask[y_min:y_max+1, x_min:x_max+1]\n",
    "    cropped_image = image[y_min:y_max+1, x_min:x_max+1]\n",
    "\n",
    "    # Applica la maschera all'immagine ritagliata\n",
    "    mask_3d = np.stack([cropped_mask] * 3, axis=-1)\n",
    "    extracted_obj = np.where(mask_3d > 0, cropped_image, 0)\n",
    "    \n",
    "    return extracted_obj, cropped_mask\n",
    "\n",
    "class BalancedDatasetGenerator:\n",
    "    def __init__(self, original_annotation_file, original_image_dir, target_count_per_category=None):\n",
    "        self.original_annotation_file = original_annotation_file\n",
    "        self.original_image_dir = original_image_dir\n",
    "        \n",
    "        # Carica dati originali\n",
    "        with open(original_annotation_file, 'r') as f:\n",
    "            self.original_data = json.load(f)\n",
    "        \n",
    "        self.categories = self.original_data['categories']\n",
    "        self.id_to_category = {cat['id']: cat['name'] for cat in self.categories}\n",
    "        \n",
    "        # Calcola statistiche attuali\n",
    "        self.category_counts = Counter()\n",
    "        for ann in self.original_data['annotations']:\n",
    "            self.category_counts[ann['category_id']] += 1\n",
    "        \n",
    "        # Imposta target\n",
    "        if target_count_per_category is None:\n",
    "            self.target_count = int(np.median(list(self.category_counts.values())))\n",
    "        else:\n",
    "            self.target_count = target_count_per_category\n",
    "        \n",
    "        print(f\"Target oggetti per categoria: {self.target_count}\")\n",
    "        \n",
    "        # Inizializza contatori per il nuovo dataset\n",
    "        self.new_annotations = []\n",
    "        self.new_images = []\n",
    "        self.new_category_counts = Counter()\n",
    "        self.annotation_id_counter = 1\n",
    "        self.image_id_counter = 1\n",
    "        \n",
    "        # Costruisci object bank\n",
    "        self.object_bank = self._build_object_bank()\n",
    "        \n",
    "    def _build_object_bank(self):\n",
    "        \"\"\"Costruisce una banca di oggetti estratti dalle immagini originali\"\"\"\n",
    "        print(\"Costruendo object bank per la generazione sintetica...\")\n",
    "        \n",
    "        object_bank = defaultdict(list)\n",
    "        coco = COCO(self.original_annotation_file)\n",
    "        \n",
    "        # Processa le prime 50 immagini per costruire l'object bank\n",
    "        image_ids = coco.getImgIds()[:50]\n",
    "        \n",
    "        total_extracted = 0\n",
    "        \n",
    "        for img_id in tqdm(image_ids, desc=\"Estraendo oggetti\"):\n",
    "            image_info = coco.loadImgs(img_id)[0]\n",
    "            image_path = find_image_path(self.original_image_dir, image_info['file_name'])\n",
    "            \n",
    "            if image_path:\n",
    "                image = cv2.imread(image_path)\n",
    "                if image is not None:\n",
    "                    annotation_ids = coco.getAnnIds(imgIds=img_id)\n",
    "                    annotations = coco.loadAnns(annotation_ids)\n",
    "                    \n",
    "                    for ann in annotations:\n",
    "                        mask = coco.annToMask(ann)\n",
    "                        if mask.shape[:2] == image.shape[:2] and np.sum(mask) > 200:\n",
    "                            obj_img, cropped_mask = simple_extract_object(image, mask)\n",
    "                            if obj_img is not None and cropped_mask is not None:\n",
    "                                if obj_img.shape[0] > 10 and obj_img.shape[1] > 10:\n",
    "                                    object_bank[ann['category_id']].append({\n",
    "                                        'object': obj_img,\n",
    "                                        'mask': cropped_mask,\n",
    "                                        'category_id': ann['category_id'],\n",
    "                                        'source_image': image_info['file_name']\n",
    "                                    })\n",
    "                                    total_extracted += 1\n",
    "        \n",
    "        print(f\"Object bank costruito con {total_extracted} oggetti\")\n",
    "        for cat_id, objects in object_bank.items():\n",
    "            cat_name = self.id_to_category.get(cat_id, f\"Category {cat_id}\")\n",
    "            print(f\"  {cat_name}: {len(objects)} oggetti\")\n",
    "        \n",
    "        return object_bank\n",
    "    \n",
    "    def add_original_images(self, max_images_per_category=None):\n",
    "        \"\"\"Aggiunge immagini originali al dataset bilanciato\"\"\"\n",
    "        print(\"\\nAggiungendo immagini originali...\")\n",
    "        \n",
    "        # Raggruppa immagini per categoria\n",
    "        images_by_category = defaultdict(list)\n",
    "        \n",
    "        for ann in self.original_data['annotations']:\n",
    "            img_id = ann['image_id']\n",
    "            cat_id = ann['category_id']\n",
    "            \n",
    "            # Trova l'immagine corrispondente\n",
    "            image_info = next((img for img in self.original_data['images'] if img['id'] == img_id), None)\n",
    "            if image_info:\n",
    "                images_by_category[cat_id].append({\n",
    "                    'image_info': image_info,\n",
    "                    'annotations': [a for a in self.original_data['annotations'] if a['image_id'] == img_id]\n",
    "                })\n",
    "        \n",
    "        # Rimuovi duplicati\n",
    "        for cat_id in images_by_category:\n",
    "            seen_ids = set()\n",
    "            unique_images = []\n",
    "            for item in images_by_category[cat_id]:\n",
    "                img_id = item['image_info']['id']\n",
    "                if img_id not in seen_ids:\n",
    "                    seen_ids.add(img_id)\n",
    "                    unique_images.append(item)\n",
    "            images_by_category[cat_id] = unique_images\n",
    "        \n",
    "        # Aggiungi immagini per ogni categoria\n",
    "        for cat_id, images in images_by_category.items():\n",
    "            cat_name = self.id_to_category[cat_id]\n",
    "            current_count = self.new_category_counts[cat_id]\n",
    "            needed = max(0, self.target_count - current_count)\n",
    "            \n",
    "            if max_images_per_category:\n",
    "                max_to_add = min(needed, max_images_per_category, len(images))\n",
    "            else:\n",
    "                max_to_add = min(needed, len(images))\n",
    "            \n",
    "            # Seleziona immagini casuali\n",
    "            selected_images = random.sample(images, max_to_add) if len(images) > max_to_add else images\n",
    "            \n",
    "            for item in selected_images:\n",
    "                image_info = item['image_info'].copy()\n",
    "                annotations = item['annotations']\n",
    "                \n",
    "                # Aggiorna ID immagine\n",
    "                old_img_id = image_info['id']\n",
    "                image_info['id'] = self.image_id_counter\n",
    "                self.new_images.append(image_info)\n",
    "                \n",
    "                # Aggiorna annotazioni\n",
    "                for ann in annotations:\n",
    "                    new_ann = ann.copy()\n",
    "                    new_ann['id'] = self.annotation_id_counter\n",
    "                    new_ann['image_id'] = self.image_id_counter\n",
    "                    self.new_annotations.append(new_ann)\n",
    "                    self.new_category_counts[ann['category_id']] += 1\n",
    "                    self.annotation_id_counter += 1\n",
    "                \n",
    "                self.image_id_counter += 1\n",
    "            \n",
    "            print(f\"  {cat_name}: aggiunte {len(selected_images)} immagini originali\")\n",
    "    \n",
    "    def generate_synthetic_images(self, output_dir):\n",
    "        \"\"\"Genera immagini sintetiche per bilanciare il dataset\"\"\"\n",
    "        print(\"\\nGenerando immagini sintetiche...\")\n",
    "        \n",
    "        output_path = Path(output_dir)\n",
    "        output_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        for cat_id, current_count in self.new_category_counts.items():\n",
    "            cat_name = self.id_to_category[cat_id]\n",
    "            needed = max(0, self.target_count - current_count)\n",
    "            \n",
    "            if needed > 0 and cat_id in self.object_bank and len(self.object_bank[cat_id]) > 0:\n",
    "                print(f\"  Generando {needed} immagini sintetiche per {cat_name}...\")\n",
    "                \n",
    "                for i in tqdm(range(needed), desc=f\"Generando {cat_name}\"):\n",
    "                    synthetic_image, synthetic_annotations = self._create_synthetic_image(cat_id)\n",
    "                    \n",
    "                    if synthetic_image is not None and synthetic_annotations:\n",
    "                        # Salva immagine\n",
    "                        filename = f\"synthetic_{cat_id}_{i:04d}.jpg\"\n",
    "                        image_path = output_path / filename\n",
    "                        cv2.imwrite(str(image_path), synthetic_image)\n",
    "                        \n",
    "                        # Crea info immagine\n",
    "                        image_info = {\n",
    "                            'id': self.image_id_counter,\n",
    "                            'width': synthetic_image.shape[1],\n",
    "                            'height': synthetic_image.shape[0],\n",
    "                            'file_name': filename,\n",
    "                            'license': 1,\n",
    "                            'date_captured': datetime.now().isoformat()\n",
    "                        }\n",
    "                        self.new_images.append(image_info)\n",
    "                        \n",
    "                        # Aggiorna annotazioni\n",
    "                        for ann in synthetic_annotations:\n",
    "                            ann['id'] = self.annotation_id_counter\n",
    "                            ann['image_id'] = self.image_id_counter\n",
    "                            self.new_annotations.append(ann)\n",
    "                            self.new_category_counts[ann['category_id']] += 1\n",
    "                            self.annotation_id_counter += 1\n",
    "                        \n",
    "                        self.image_id_counter += 1\n",
    "            else:\n",
    "                if needed > 0:\n",
    "                    print(f\"  ATTENZIONE: Impossibile generare immagini per {cat_name} (oggetti non disponibili)\")\n",
    "    \n",
    "    def _create_synthetic_image(self, target_category_id):\n",
    "        \"\"\"Crea una singola immagine sintetica focalizzata su una categoria target\"\"\"\n",
    "        # Dimensioni dell'immagine\n",
    "        img_height = random.randint(400, 800)\n",
    "        img_width = random.randint(600, 1000)\n",
    "        \n",
    "        # Crea sfondo usando la funzione corretta dalla terza cella\n",
    "        bg_type = random.choice(['random', 'gradient', 'solid'])\n",
    "        background = create_background((img_height, img_width, 3), bg_type)\n",
    "        \n",
    "        # Maschera di posizionamento per evitare sovrapposizioni\n",
    "        placement_mask = np.zeros((img_height, img_width), dtype=np.uint8)\n",
    "        \n",
    "        annotations = []\n",
    "        object_id_counter = 1\n",
    "        \n",
    "        # Aggiungi 1-2 oggetti della categoria target\n",
    "        target_objects_count = random.randint(1, 2)\n",
    "        \n",
    "        if target_category_id in self.object_bank and len(self.object_bank[target_category_id]) > 0:\n",
    "            for _ in range(target_objects_count):\n",
    "                obj_data = random.choice(self.object_bank[target_category_id])\n",
    "                annotation = self._place_object_on_background(\n",
    "                    background, placement_mask, obj_data, target_category_id, object_id_counter\n",
    "                )\n",
    "                if annotation:\n",
    "                    annotations.append(annotation)\n",
    "                    object_id_counter += 1\n",
    "        \n",
    "        # Aggiungi 1-3 oggetti di altre categorie per rendere la scena più realistica\n",
    "        other_objects_count = random.randint(1, 3)\n",
    "        available_categories = [cat_id for cat_id in self.object_bank.keys() \n",
    "                              if cat_id != target_category_id and len(self.object_bank[cat_id]) > 0]\n",
    "        \n",
    "        for _ in range(min(other_objects_count, len(available_categories))):\n",
    "            other_cat_id = random.choice(available_categories)\n",
    "            obj_data = random.choice(self.object_bank[other_cat_id])\n",
    "            annotation = self._place_object_on_background(\n",
    "                background, placement_mask, obj_data, other_cat_id, object_id_counter\n",
    "            )\n",
    "            if annotation:\n",
    "                annotations.append(annotation)\n",
    "                object_id_counter += 1\n",
    "        \n",
    "        return background if annotations else None, annotations\n",
    "    \n",
    "    def _place_object_on_background(self, background, placement_mask, obj_data, category_id, object_id):\n",
    "        \"\"\"Posiziona un oggetto sullo sfondo e restituisce l'annotazione\"\"\"\n",
    "        obj_img, mask = obj_data['object'], obj_data['mask']\n",
    "        \n",
    "        # Rotazione casuale usando la funzione corretta dalla terza cella\n",
    "        angle = random.uniform(0, 360)\n",
    "        rotated_obj, rotated_mask, _ = rotate_object_and_mask(obj_img, mask, angle)\n",
    "        \n",
    "        # Scaling usando la funzione corretta dalla terza cella\n",
    "        scale = random.uniform(0.5, 1.5)\n",
    "        resized_obj, resized_mask = resize_object_and_mask(rotated_obj, rotated_mask, scale)\n",
    "        \n",
    "        if resized_obj is None:\n",
    "            return None\n",
    "        \n",
    "        # Trova posizione senza sovrapposizioni\n",
    "        best_pos = None\n",
    "        min_overlap = float('inf')\n",
    "        \n",
    "        for _ in range(30):  # Più tentativi per trovare una buona posizione\n",
    "            max_x = max(0, background.shape[1] - resized_obj.shape[1])\n",
    "            max_y = max(0, background.shape[0] - resized_obj.shape[0])\n",
    "            \n",
    "            if max_x <= 0 or max_y <= 0:\n",
    "                continue\n",
    "                \n",
    "            x_pos = random.randint(0, max_x)\n",
    "            y_pos = random.randint(0, max_y)\n",
    "            \n",
    "            h, w = resized_obj.shape[:2]\n",
    "            overlap_region = placement_mask[y_pos:y_pos+h, x_pos:x_pos+w]\n",
    "            overlap = np.sum(overlap_region > 0)\n",
    "            \n",
    "            if overlap < min_overlap:\n",
    "                min_overlap = overlap\n",
    "                best_pos = (x_pos, y_pos)\n",
    "            \n",
    "            if overlap == 0:  # Posizione perfetta trovata\n",
    "                break\n",
    "        \n",
    "        if best_pos:\n",
    "            x_pos, y_pos = best_pos\n",
    "            # Usa la funzione corretta dalla terza cella\n",
    "            result_background, annotation = place_object_on_background_with_annotation(\n",
    "                background, resized_obj, resized_mask, x_pos, y_pos, category_id, object_id\n",
    "            )\n",
    "            \n",
    "            if annotation:\n",
    "                # Aggiorna maschera di posizionamento\n",
    "                h, w = resized_obj.shape[:2]\n",
    "                placement_mask[y_pos:y_pos+h, x_pos:x_pos+w] = 255\n",
    "                return annotation\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def save_balanced_dataset(self, output_annotation_file):\n",
    "        \"\"\"Salva il dataset bilanciato in formato COCO\"\"\"\n",
    "        balanced_data = {\n",
    "            'info': {\n",
    "                'description': 'TACO Balanced Dataset',\n",
    "                'version': '1.0',\n",
    "                'year': 2025,\n",
    "                'date_created': datetime.now().isoformat()\n",
    "            },\n",
    "            'licenses': self.original_data.get('licenses', []),\n",
    "            'categories': self.categories,\n",
    "            'images': self.new_images,\n",
    "            'annotations': self.new_annotations\n",
    "        }\n",
    "        \n",
    "        with open(output_annotation_file, 'w') as f:\n",
    "            json.dump(balanced_data, f, indent=2)\n",
    "        \n",
    "        print(f\"\\nDataset bilanciato salvato in: {output_annotation_file}\")\n",
    "        print(f\"Totale immagini: {len(self.new_images)}\")\n",
    "        print(f\"Totale annotazioni: {len(self.new_annotations)}\")\n",
    "        \n",
    "        print(\"\\nDistribuzione finale per categoria:\")\n",
    "        for cat_id, count in self.new_category_counts.items():\n",
    "            cat_name = self.id_to_category[cat_id]\n",
    "            print(f\"  {cat_name}: {count} oggetti\")\n",
    "        \n",
    "        return balanced_data\n",
    "\n",
    "# Inizializza il generatore con un target più basso per assicurarci che funzioni\n",
    "print(\"Inizializzando il generatore di dataset bilanciato...\")\n",
    "generator = BalancedDatasetGenerator(\n",
    "    original_annotation_file='../../datasets/taco_official/annotations.json',\n",
    "    original_image_dir='../../datasets/taco_official/',\n",
    "    target_count_per_category=100  # Target: 100 oggetti per categoria\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a360666c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genera il Dataset Bilanciato\n",
    "print(\"=\"*60)\n",
    "print(\"GENERAZIONE DATASET BILANCIATO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Crea directory per il dataset bilanciato\n",
    "balanced_dataset_dir = '../../datasets/taco_balanced'\n",
    "balanced_images_dir = f'{balanced_dataset_dir}/images'\n",
    "Path(balanced_images_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Step 1: Aggiungi immagini originali\n",
    "print(\"\\\\nStep 1: Aggiungendo immagini originali...\")\n",
    "generator.add_original_images(max_images_per_category=50)  # Massimo 50 immagini originali per categoria\n",
    "\n",
    "# Copia le immagini originali selezionate\n",
    "print(\"Copiando immagini originali...\")\n",
    "for image_info in tqdm(generator.new_images, desc=\"Copiando immagini\"):\n",
    "    src_path = find_image_path(generator.original_image_dir, image_info['file_name'])\n",
    "    if src_path:\n",
    "        # Estrai solo il nome del file senza il path della batch\n",
    "        filename_only = os.path.basename(image_info['file_name'])\n",
    "        dst_path = Path(balanced_images_dir) / filename_only\n",
    "        \n",
    "        # Aggiorna il nome del file nell'info per riflettere la nuova struttura\n",
    "        image_info['file_name'] = filename_only\n",
    "        \n",
    "        shutil.copy2(src_path, dst_path)\n",
    "\n",
    "print(f\"\\\\nStatistiche dopo l'aggiunta delle immagini originali:\")\n",
    "for cat_id, count in generator.new_category_counts.items():\n",
    "    cat_name = generator.id_to_category[cat_id]\n",
    "    needed = max(0, generator.target_count - count)\n",
    "    print(f\"  {cat_name}: {count} oggetti (mancanti: {needed})\")\n",
    "\n",
    "# Step 2: Genera immagini sintetiche\n",
    "print(\"\\\\nStep 2: Generando immagini sintetiche...\")\n",
    "generator.generate_synthetic_images(balanced_images_dir)\n",
    "\n",
    "# Step 3: Salva il dataset finale\n",
    "print(\"\\\\nStep 3: Salvando dataset bilanciato...\")\n",
    "balanced_annotation_file = f'{balanced_dataset_dir}/annotations_balanced.json'\n",
    "balanced_data = generator.save_balanced_dataset(balanced_annotation_file)\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*60)\n",
    "print(\"DATASET BILANCIATO COMPLETATO!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Percorso dataset: {balanced_dataset_dir}\")\n",
    "print(f\"File annotazioni: {balanced_annotation_file}\")\n",
    "print(f\"Directory immagini: {balanced_images_dir}\")\n",
    "\n",
    "# Analisi finale del bilanciamento\n",
    "final_category_counts = Counter()\n",
    "for ann in balanced_data['annotations']:\n",
    "    final_category_counts[ann['category_id']] += 1\n",
    "\n",
    "print(\"\\\\nDistribuzione finale:\")\n",
    "print(f\"{'Categoria':<25} {'Originale':<10} {'Bilanciato':<12} {'Miglioramento'}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "# Prima di questo calcolo, dobbiamo assicurarci che category_counts sia disponibile\n",
    "if 'category_counts' not in locals():\n",
    "    category_counts = Counter()\n",
    "    for ann in generator.original_data['annotations']:\n",
    "        category_counts[ann['category_id']] += 1\n",
    "\n",
    "for cat_id in sorted(final_category_counts.keys()):\n",
    "    cat_name = generator.id_to_category[cat_id]\n",
    "    original_count = category_counts.get(cat_id, 0)\n",
    "    balanced_count = final_category_counts[cat_id]\n",
    "    improvement = f\"+{balanced_count - original_count}\" if balanced_count > original_count else str(balanced_count - original_count)\n",
    "    \n",
    "    print(f\"{cat_name[:24]:<25} {original_count:<10} {balanced_count:<12} {improvement}\")\n",
    "\n",
    "# Calcola nuove metriche di bilanciamento\n",
    "new_max = max(final_category_counts.values())\n",
    "new_min = min(final_category_counts.values())\n",
    "new_imbalance_ratio = new_max / new_min if new_min > 0 else float('inf')\n",
    "\n",
    "# Calcola anche l'imbalance ratio originale\n",
    "original_max = max(category_counts.values()) if category_counts else 1\n",
    "original_min = min(category_counts.values()) if category_counts else 1\n",
    "original_imbalance_ratio = original_max / original_min if original_min > 0 else float('inf')\n",
    "\n",
    "print(f\"\\\\nMetriche di bilanciamento:\")\n",
    "print(f\"  Rapporto sbilanciamento originale: {original_imbalance_ratio:.1f}:1\")\n",
    "print(f\"  Rapporto sbilanciamento bilanciato: {new_imbalance_ratio:.1f}:1\")\n",
    "if original_imbalance_ratio > 0:\n",
    "    print(f\"  Miglioramento: {original_imbalance_ratio/new_imbalance_ratio:.1f}x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93c9c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizza Esempi del Dataset Bilanciato\n",
    "print(\"\\\\nVisualizzando esempi dal dataset bilanciato...\")\n",
    "\n",
    "# Carica il dataset bilanciato\n",
    "balanced_coco = COCO(balanced_annotation_file)\n",
    "\n",
    "# Seleziona alcune immagini casuali per ogni tipo (originali vs sintetiche)\n",
    "original_images = [img for img in balanced_data['images'] if not img['file_name'].startswith('synthetic_')]\n",
    "synthetic_images = [img for img in balanced_data['images'] if img['file_name'].startswith('synthetic_')]\n",
    "\n",
    "print(f\"Immagini originali nel dataset bilanciato: {len(original_images)}\")\n",
    "print(f\"Immagini sintetiche generate: {len(synthetic_images)}\")\n",
    "\n",
    "# Visualizza esempi\n",
    "if len(synthetic_images) > 0:\n",
    "    # Caso con immagini sintetiche\n",
    "    num_examples = min(3, len(original_images), len(synthetic_images))\n",
    "    selected_original = random.sample(original_images, num_examples)\n",
    "    selected_synthetic = random.sample(synthetic_images, num_examples)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, num_examples, figsize=(15, 10))\n",
    "    fig.suptitle('Esempi dal Dataset Bilanciato: Originali vs Sintetiche', fontsize=16)\n",
    "    \n",
    "    # Visualizza immagini originali\n",
    "    for i, image_info in enumerate(selected_original):\n",
    "        img_path = Path(balanced_images_dir) / image_info['file_name']\n",
    "        image = cv2.imread(str(img_path))\n",
    "        \n",
    "        if image is not None:\n",
    "            # Ottieni annotazioni\n",
    "            ann_ids = balanced_coco.getAnnIds(imgIds=image_info['id'])\n",
    "            annotations = balanced_coco.loadAnns(ann_ids)\n",
    "            \n",
    "            # Disegna bounding boxes\n",
    "            image_with_boxes = draw_all_bboxes(image, annotations, generator.id_to_category, \n",
    "                                             original_color=(0, 255, 0), synthetic_color=(0, 255, 0))\n",
    "            \n",
    "            axes[0, i].imshow(cv2.cvtColor(image_with_boxes, cv2.COLOR_BGR2RGB))\n",
    "            axes[0, i].set_title(f'Originale: {len(annotations)} oggetti')\n",
    "            axes[0, i].axis('off')\n",
    "\n",
    "    # Visualizza immagini sintetiche\n",
    "    for i, image_info in enumerate(selected_synthetic):\n",
    "        img_path = Path(balanced_images_dir) / image_info['file_name']\n",
    "        image = cv2.imread(str(img_path))\n",
    "        \n",
    "        if image is not None:\n",
    "            # Ottieni annotazioni\n",
    "            ann_ids = balanced_coco.getAnnIds(imgIds=image_info['id'])\n",
    "            annotations = balanced_coco.loadAnns(ann_ids)\n",
    "            \n",
    "            # Disegna bounding boxes\n",
    "            image_with_boxes = draw_all_bboxes(image, annotations, generator.id_to_category,\n",
    "                                             original_color=(255, 0, 0), synthetic_color=(255, 0, 0))\n",
    "            \n",
    "            axes[1, i].imshow(cv2.cvtColor(image_with_boxes, cv2.COLOR_BGR2RGB))\n",
    "            axes[1, i].set_title(f'Sintetica: {len(annotations)} oggetti')\n",
    "            axes[1, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    # Caso senza immagini sintetiche - mostra solo alcune originali\n",
    "    print(\"\\\\nNessuna immagine sintetica generata. Visualizzando solo immagini originali...\")\n",
    "    num_examples = min(5, len(original_images))\n",
    "    selected_original = random.sample(original_images, num_examples)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, num_examples, figsize=(20, 4))\n",
    "    fig.suptitle(f'Esempi dal Dataset Bilanciato (Solo Originali)', fontsize=16)\n",
    "    \n",
    "    if num_examples == 1:\n",
    "        axes = [axes]  # Make it iterable for single plot\n",
    "    \n",
    "    for i, image_info in enumerate(selected_original):\n",
    "        img_path = Path(balanced_images_dir) / image_info['file_name']\n",
    "        image = cv2.imread(str(img_path))\n",
    "        \n",
    "        if image is not None:\n",
    "            # Ottieni annotazioni\n",
    "            ann_ids = balanced_coco.getAnnIds(imgIds=image_info['id'])\n",
    "            annotations = balanced_coco.loadAnns(ann_ids)\n",
    "            \n",
    "            # Disegna bounding boxes\n",
    "            image_with_boxes = draw_all_bboxes(image, annotations, generator.id_to_category, \n",
    "                                             original_color=(0, 255, 0), synthetic_color=(0, 255, 0))\n",
    "            \n",
    "            axes[i].imshow(cv2.cvtColor(image_with_boxes, cv2.COLOR_BGR2RGB))\n",
    "            axes[i].set_title(f'{len(annotations)} oggetti')\n",
    "            axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Statistiche finali dettagliate\n",
    "print(\"\\\\n\" + \"=\"*80)\n",
    "print(\"STATISTICHE FINALI DEL DATASET BILANCIATO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\\\nInformazioni generali:\")\n",
    "print(f\"  Totale immagini: {len(balanced_data['images'])}\")\n",
    "print(f\"  Immagini originali: {len(original_images)}\")\n",
    "print(f\"  Immagini sintetiche: {len(synthetic_images)}\")\n",
    "print(f\"  Totale annotazioni: {len(balanced_data['annotations'])}\")\n",
    "print(f\"  Numero di categorie: {len(balanced_data['categories'])}\")\n",
    "\n",
    "# Calcola final_category_counts se non è già disponibile\n",
    "if 'final_category_counts' not in locals():\n",
    "    final_category_counts = Counter()\n",
    "    for ann in balanced_data['annotations']:\n",
    "        final_category_counts[ann['category_id']] += 1\n",
    "\n",
    "print(f\"\\\\nDistribuzione per categoria nel dataset bilanciato:\")\n",
    "for cat_id, count in sorted(final_category_counts.items()):\n",
    "    cat_name = generator.id_to_category[cat_id]\n",
    "    percentage = (count / len(balanced_data['annotations'])) * 100\n",
    "    print(f\"  {cat_name}: {count} oggetti ({percentage:.1f}%)\")\n",
    "\n",
    "# Calcola statistiche di qualità\n",
    "mean_count = np.mean(list(final_category_counts.values()))\n",
    "std_count = np.std(list(final_category_counts.values()))\n",
    "cv = (std_count / mean_count) * 100  # Coefficiente di variazione\n",
    "\n",
    "# Calcola nuove metriche di bilanciamento\n",
    "new_max = max(final_category_counts.values())\n",
    "new_min = min(final_category_counts.values())\n",
    "new_imbalance_ratio = new_max / new_min if new_min > 0 else float('inf')\n",
    "\n",
    "print(f\"\\\\nMetriche di bilanciamento:\")\n",
    "print(f\"  Media oggetti per categoria: {mean_count:.1f}\")\n",
    "print(f\"  Deviazione standard: {std_count:.1f}\")\n",
    "print(f\"  Coefficiente di variazione: {cv:.1f}%\")\n",
    "print(f\"  Rapporto sbilanciamento finale: {new_imbalance_ratio:.1f}:1\")\n",
    "\n",
    "if cv < 20:\n",
    "    print(\"  ✅ Dataset ben bilanciato (CV < 20%)\")\n",
    "elif cv < 50:\n",
    "    print(\"  ⚠️ Dataset moderatamente bilanciato (20% ≤ CV < 50%)\")\n",
    "else:\n",
    "    print(\"  ❌ Dataset ancora sbilanciato (CV ≥ 50%)\")\n",
    "\n",
    "# Informazioni sui possibili motivi per cui non sono state generate immagini sintetiche\n",
    "if len(synthetic_images) == 0:\n",
    "    print(f\"\\\\n⚠️ NOTA: Non sono state generate immagini sintetiche.\")\n",
    "    print(\"Possibili motivi:\")\n",
    "    print(\"- L'object bank potrebbe essere vuoto o avere pochi oggetti\")\n",
    "    print(\"- Il target per categoria (200) potrebbe essere già raggiunto dalle immagini originali\")\n",
    "    print(\"- Problemi nell'estrazione degli oggetti dalle immagini originali\")\n",
    "    \n",
    "    print(f\"\\\\nSuggerimenti:\")\n",
    "    print(\"- Prova a ridurre il target_count_per_category (es. 100 invece di 200)\")\n",
    "    print(\"- Aumenta il numero di immagini processate per l'object bank\")\n",
    "    print(\"- Verifica che le funzioni di estrazione oggetti funzionino correttamente\")\n",
    "\n",
    "print(f\"\\\\n🎯 Dataset bilanciato salvato in: {balanced_dataset_dir}\")\n",
    "print(\"💡 Pronto per l'addestramento di modelli di object detection!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
