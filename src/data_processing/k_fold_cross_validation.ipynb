{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e915e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up 5-fold cross validation\n",
      "Source dataset: ../../datasets/roboflow_2\n",
      "Output directory: ../../datasets/k_fold_cv\n",
      "Dataset classes: ['glass', 'metal', 'organic', 'paper', 'plastic']\n",
      "Number of classes: 5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yaml\n",
    "import shutil\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import random\n",
    "\n",
    "# Configuration\n",
    "dataset_path = \"../../datasets/roboflow_2\"\n",
    "output_path = \"../../datasets/k_fold_cv\"\n",
    "k_folds = 5\n",
    "random_seed = 42\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "print(f\"Setting up {k_folds}-fold cross validation\")\n",
    "print(f\"Source dataset: {dataset_path}\")\n",
    "print(f\"Output directory: {output_path}\")\n",
    "\n",
    "# Load data.yaml to get class information\n",
    "with open(os.path.join(dataset_path, \"data.yaml\"), 'r') as f:\n",
    "    data_config = yaml.safe_load(f)\n",
    "\n",
    "print(f\"Dataset classes: {data_config.get('names', [])}\")\n",
    "print(f\"Number of classes: {data_config.get('nc', 0)}\")\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76d67978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dataset files...\n",
      "Warning: val directory not found, skipping...\n",
      "Found 12012 image-label pairs\n",
      "Analyzing class distributions...\n",
      "Overall class distribution: {1: 4880, 3: 2855, 2: 1634, 4: 6730, 0: 1262}\n",
      "Overall class distribution: {1: 4880, 3: 2855, 2: 1634, 4: 6730, 0: 1262}\n"
     ]
    }
   ],
   "source": [
    "def collect_dataset_files(dataset_path):\n",
    "    \"\"\"Collect all image and label files from train, test, val directories\"\"\"\n",
    "    all_files = []\n",
    "    \n",
    "    for split in ['train', 'test', 'val']:\n",
    "        images_dir = os.path.join(dataset_path, split, 'images')\n",
    "        labels_dir = os.path.join(dataset_path, split, 'labels')\n",
    "        \n",
    "        if not os.path.exists(images_dir) or not os.path.exists(labels_dir):\n",
    "            print(f\"Warning: {split} directory not found, skipping...\")\n",
    "            continue\n",
    "            \n",
    "        # Get all image files\n",
    "        image_files = [f for f in os.listdir(images_dir) \n",
    "                      if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]\n",
    "        \n",
    "        for img_file in image_files:\n",
    "            # Find corresponding label file\n",
    "            base_name = os.path.splitext(img_file)[0]\n",
    "            label_file = base_name + '.txt'\n",
    "            \n",
    "            img_path = os.path.join(images_dir, img_file)\n",
    "            label_path = os.path.join(labels_dir, label_file)\n",
    "            \n",
    "            if os.path.exists(label_path):\n",
    "                all_files.append({\n",
    "                    'image_path': img_path,\n",
    "                    'label_path': label_path,\n",
    "                    'filename': img_file,\n",
    "                    'original_split': split\n",
    "                })\n",
    "            else:\n",
    "                print(f\"Warning: No label file found for {img_file}\")\n",
    "    \n",
    "    return all_files\n",
    "\n",
    "def analyze_class_distribution(label_path):\n",
    "    \"\"\"Analyze class distribution in a label file\"\"\"\n",
    "    classes = []\n",
    "    if os.path.exists(label_path) and os.path.getsize(label_path) > 0:\n",
    "        with open(label_path, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) >= 5:  # class_id x y w h\n",
    "                    classes.append(int(parts[0]))\n",
    "    return classes\n",
    "\n",
    "# Collect all files\n",
    "print(\"Collecting dataset files...\")\n",
    "all_files = collect_dataset_files(dataset_path)\n",
    "print(f\"Found {len(all_files)} image-label pairs\")\n",
    "\n",
    "# Analyze class distribution for each file\n",
    "print(\"Analyzing class distributions...\")\n",
    "file_classes = {}\n",
    "overall_class_counts = Counter()\n",
    "\n",
    "for file_info in all_files:\n",
    "    classes = analyze_class_distribution(file_info['label_path'])\n",
    "    file_classes[file_info['filename']] = classes\n",
    "    overall_class_counts.update(classes)\n",
    "    \n",
    "print(f\"Overall class distribution: {dict(overall_class_counts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8101e7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determining stratification strategy...\n",
      "Stratification label distribution: {1: 3768, 3: 2628, 2: 1447, 4: 3220, 0: 949}\n",
      "\n",
      "Creating 5-fold splits...\n",
      "Fold 1: Train=8236 (68.6%), Val=1373 (11.4%), Test=2403 (20.0%)\n",
      "Fold 2: Train=8236 (68.6%), Val=1373 (11.4%), Test=2403 (20.0%)\n",
      "Fold 3: Train=8237 (68.6%), Val=1373 (11.4%), Test=2402 (20.0%)\n",
      "Fold 4: Train=8237 (68.6%), Val=1373 (11.4%), Test=2402 (20.0%)\n",
      "Fold 5: Train=8237 (68.6%), Val=1373 (11.4%), Test=2402 (20.0%)\n"
     ]
    }
   ],
   "source": [
    "def get_dominant_class_strategy(file_classes, all_files):\n",
    "    \"\"\"\n",
    "    Assign each image to its dominant class for stratification.\n",
    "    If no objects, assign to a special 'background' class.\n",
    "    \"\"\"\n",
    "    stratification_labels = []\n",
    "    \n",
    "    for file_info in all_files:\n",
    "        filename = file_info['filename']\n",
    "        classes = file_classes[filename]\n",
    "        \n",
    "        if not classes:\n",
    "            # No objects in this image - assign to background class\n",
    "            stratification_labels.append(-1)\n",
    "        else:\n",
    "            # Find the most common class in this image\n",
    "            class_counts = Counter(classes)\n",
    "            dominant_class = class_counts.most_common(1)[0][0]\n",
    "            stratification_labels.append(dominant_class)\n",
    "    \n",
    "    return stratification_labels\n",
    "\n",
    "def create_balanced_splits(all_files, stratification_labels, k_folds):\n",
    "    \"\"\"Create k-fold splits with balanced class distribution (80% train, 20% test, + validation from train)\"\"\"\n",
    "    \n",
    "    # Convert to numpy arrays for easier handling\n",
    "    file_indices = np.arange(len(all_files))\n",
    "    \n",
    "    # Use StratifiedKFold to create 80/20 train/test splits\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=random_seed)  # 5-fold = 80/20 split\n",
    "    \n",
    "    fold_splits = []\n",
    "    splits_list = list(skf.split(file_indices, stratification_labels))\n",
    "    \n",
    "    for fold_idx in range(k_folds):\n",
    "        # Use different splits for each fold\n",
    "        train_test_indices, test_indices = splits_list[fold_idx % len(splits_list)]\n",
    "        \n",
    "        # Now split the train_test_indices into train and validation\n",
    "        # Extract validation from the train set (15% of train set = ~12% of total)\n",
    "        train_test_labels = [stratification_labels[i] for i in train_test_indices]\n",
    "        \n",
    "        # Create another stratified split for train/val\n",
    "        val_skf = StratifiedKFold(n_splits=7, shuffle=True, random_state=random_seed)  # ~85/15 split\n",
    "        inner_splits = list(val_skf.split(train_test_indices, train_test_labels))\n",
    "        \n",
    "        # Take the first split\n",
    "        train_indices_inner, val_indices_inner = inner_splits[0]\n",
    "        train_indices = train_test_indices[train_indices_inner]\n",
    "        val_indices = train_test_indices[val_indices_inner]\n",
    "        \n",
    "        fold_splits.append({\n",
    "            'train': train_indices,\n",
    "            'val': val_indices,\n",
    "            'test': test_indices\n",
    "        })\n",
    "        \n",
    "        total = len(train_indices) + len(val_indices) + len(test_indices)\n",
    "        print(f\"Fold {fold_idx + 1}: Train={len(train_indices)} ({len(train_indices)/total*100:.1f}%), \"\n",
    "              f\"Val={len(val_indices)} ({len(val_indices)/total*100:.1f}%), \"\n",
    "              f\"Test={len(test_indices)} ({len(test_indices)/total*100:.1f}%)\")\n",
    "    \n",
    "    return fold_splits\n",
    "\n",
    "# Get stratification labels using dominant class strategy\n",
    "print(\"Determining stratification strategy...\")\n",
    "stratification_labels = get_dominant_class_strategy(file_classes, all_files)\n",
    "\n",
    "# Check distribution of stratification labels\n",
    "strat_counts = Counter(stratification_labels)\n",
    "print(f\"Stratification label distribution: {dict(strat_counts)}\")\n",
    "\n",
    "# Create balanced k-fold splits\n",
    "print(f\"\\nCreating {k_folds}-fold splits...\")\n",
    "fold_splits = create_balanced_splits(all_files, stratification_labels, k_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3ed7022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating fold directories and copying files...\n",
      "\n",
      "Processing Fold 1/5\n",
      "  train: copied 8236 files\n",
      "    Class distribution: {3: 1974, 4: 4594, 2: 1116, 1: 3268, 0: 851}\n",
      "  val: copied 1373 files\n",
      "    Class distribution: {1: 597, 2: 186, 4: 768, 3: 315, 0: 160}\n",
      "  train: copied 8236 files\n",
      "    Class distribution: {3: 1974, 4: 4594, 2: 1116, 1: 3268, 0: 851}\n",
      "  val: copied 1373 files\n",
      "    Class distribution: {1: 597, 2: 186, 4: 768, 3: 315, 0: 160}\n",
      "  test: copied 2403 files\n",
      "    Class distribution: {4: 1368, 0: 251, 2: 332, 1: 1015, 3: 566}\n",
      "  Created: ../../datasets/k_fold_cv/fold_1/data.yaml\n",
      "\n",
      "Processing Fold 2/5\n",
      "  test: copied 2403 files\n",
      "    Class distribution: {4: 1368, 0: 251, 2: 332, 1: 1015, 3: 566}\n",
      "  Created: ../../datasets/k_fold_cv/fold_1/data.yaml\n",
      "\n",
      "Processing Fold 2/5\n",
      "  train: copied 8236 files\n",
      "    Class distribution: {4: 4690, 2: 1125, 0: 853, 3: 1946, 1: 3358}\n",
      "  val: copied 1373 files\n",
      "    Class distribution: {1: 559, 3: 340, 2: 189, 4: 754, 0: 169}\n",
      "  train: copied 8236 files\n",
      "    Class distribution: {4: 4690, 2: 1125, 0: 853, 3: 1946, 1: 3358}\n",
      "  val: copied 1373 files\n",
      "    Class distribution: {1: 559, 3: 340, 2: 189, 4: 754, 0: 169}\n",
      "  test: copied 2403 files\n",
      "    Class distribution: {4: 1286, 3: 569, 1: 963, 2: 320, 0: 240}\n",
      "  Created: ../../datasets/k_fold_cv/fold_2/data.yaml\n",
      "\n",
      "Processing Fold 3/5\n",
      "  test: copied 2403 files\n",
      "    Class distribution: {4: 1286, 3: 569, 1: 963, 2: 320, 0: 240}\n",
      "  Created: ../../datasets/k_fold_cv/fold_2/data.yaml\n",
      "\n",
      "Processing Fold 3/5\n",
      "  train: copied 8237 files\n",
      "    Class distribution: {2: 1117, 4: 4470, 3: 1961, 0: 869, 1: 3308}\n",
      "  val: copied 1373 files\n",
      "    Class distribution: {1: 622, 4: 791, 2: 197, 3: 339, 0: 135}\n",
      "  train: copied 8237 files\n",
      "    Class distribution: {2: 1117, 4: 4470, 3: 1961, 0: 869, 1: 3308}\n",
      "  val: copied 1373 files\n",
      "    Class distribution: {1: 622, 4: 791, 2: 197, 3: 339, 0: 135}\n",
      "  test: copied 2402 files\n",
      "    Class distribution: {3: 555, 4: 1469, 1: 950, 0: 258, 2: 320}\n",
      "  Created: ../../datasets/k_fold_cv/fold_3/data.yaml\n",
      "\n",
      "Processing Fold 4/5\n",
      "  test: copied 2402 files\n",
      "    Class distribution: {3: 555, 4: 1469, 1: 950, 0: 258, 2: 320}\n",
      "  Created: ../../datasets/k_fold_cv/fold_3/data.yaml\n",
      "\n",
      "Processing Fold 4/5\n",
      "  train: copied 8237 files\n",
      "    Class distribution: {3: 1965, 4: 4688, 2: 1117, 0: 834, 1: 3332}\n",
      "  train: copied 8237 files\n",
      "    Class distribution: {3: 1965, 4: 4688, 2: 1117, 0: 834, 1: 3332}\n",
      "  val: copied 1373 files\n",
      "    Class distribution: {1: 582, 4: 745, 0: 143, 3: 314, 2: 179}\n",
      "  val: copied 1373 files\n",
      "    Class distribution: {1: 582, 4: 745, 0: 143, 3: 314, 2: 179}\n",
      "  test: copied 2402 files\n",
      "    Class distribution: {2: 338, 3: 576, 1: 966, 4: 1297, 0: 285}\n",
      "  Created: ../../datasets/k_fold_cv/fold_4/data.yaml\n",
      "\n",
      "Processing Fold 5/5\n",
      "  test: copied 2402 files\n",
      "    Class distribution: {2: 338, 3: 576, 1: 966, 4: 1297, 0: 285}\n",
      "  Created: ../../datasets/k_fold_cv/fold_4/data.yaml\n",
      "\n",
      "Processing Fold 5/5\n",
      "  train: copied 8237 files\n",
      "    Class distribution: {3: 1937, 2: 1123, 4: 4672, 0: 881, 1: 3335}\n",
      "  val: copied 1373 files\n",
      "    Class distribution: {4: 748, 3: 329, 1: 559, 2: 187, 0: 153}\n",
      "  train: copied 8237 files\n",
      "    Class distribution: {3: 1937, 2: 1123, 4: 4672, 0: 881, 1: 3335}\n",
      "  val: copied 1373 files\n",
      "    Class distribution: {4: 748, 3: 329, 1: 559, 2: 187, 0: 153}\n",
      "  test: copied 2402 files\n",
      "    Class distribution: {1: 986, 4: 1310, 2: 324, 0: 228, 3: 589}\n",
      "  Created: ../../datasets/k_fold_cv/fold_5/data.yaml\n",
      "\n",
      "K-fold cross validation setup complete!\n",
      "Output directory: ../../datasets/k_fold_cv\n",
      "Each fold contains train (~68%), val (~12%), test (20%) splits with balanced class distributions\n",
      "  test: copied 2402 files\n",
      "    Class distribution: {1: 986, 4: 1310, 2: 324, 0: 228, 3: 589}\n",
      "  Created: ../../datasets/k_fold_cv/fold_5/data.yaml\n",
      "\n",
      "K-fold cross validation setup complete!\n",
      "Output directory: ../../datasets/k_fold_cv\n",
      "Each fold contains train (~68%), val (~12%), test (20%) splits with balanced class distributions\n"
     ]
    }
   ],
   "source": [
    "def create_fold_directories(output_path, fold_idx):\n",
    "    \"\"\"Create directory structure for a specific fold\"\"\"\n",
    "    fold_dir = os.path.join(output_path, f\"fold_{fold_idx}\")\n",
    "    \n",
    "    # Create directories (train, val, and test)\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        for subdir in ['images', 'labels']:\n",
    "            dir_path = os.path.join(fold_dir, split, subdir)\n",
    "            os.makedirs(dir_path, exist_ok=True)\n",
    "    \n",
    "    return fold_dir\n",
    "\n",
    "def copy_files_for_split(all_files, indices, fold_dir, split_name):\n",
    "    \"\"\"Copy files for a specific split (train/val/test) to the fold directory\"\"\"\n",
    "    images_dir = os.path.join(fold_dir, split_name, 'images')\n",
    "    labels_dir = os.path.join(fold_dir, split_name, 'labels')\n",
    "    \n",
    "    copied_count = 0\n",
    "    for idx in indices:\n",
    "        file_info = all_files[idx]\n",
    "        \n",
    "        # Copy image file\n",
    "        src_img = file_info['image_path']\n",
    "        dst_img = os.path.join(images_dir, file_info['filename'])\n",
    "        shutil.copy2(src_img, dst_img)\n",
    "        \n",
    "        # Copy label file\n",
    "        src_label = file_info['label_path']\n",
    "        label_filename = os.path.splitext(file_info['filename'])[0] + '.txt'\n",
    "        dst_label = os.path.join(labels_dir, label_filename)\n",
    "        shutil.copy2(src_label, dst_label)\n",
    "        \n",
    "        copied_count += 1\n",
    "    \n",
    "    return copied_count\n",
    "\n",
    "def create_data_yaml(fold_dir, data_config, fold_idx):\n",
    "    \"\"\"Create data.yaml file for the fold\"\"\"\n",
    "    # Update paths to be relative to the fold directory (train, val, and test)\n",
    "    fold_data_config = data_config.copy()\n",
    "    fold_data_config['train'] = 'train/images'\n",
    "    fold_data_config['val'] = 'val/images'\n",
    "    fold_data_config['test'] = 'test/images'\n",
    "    \n",
    "    # Write the data.yaml file\n",
    "    yaml_path = os.path.join(fold_dir, 'data.yaml')\n",
    "    with open(yaml_path, 'w') as f:\n",
    "        yaml.dump(fold_data_config, f, default_flow_style=False)\n",
    "    \n",
    "    return yaml_path\n",
    "\n",
    "def analyze_fold_distribution(all_files, indices, file_classes):\n",
    "    \"\"\"Analyze class distribution for a specific fold\"\"\"\n",
    "    class_counts = Counter()\n",
    "    \n",
    "    for idx in indices:\n",
    "        filename = all_files[idx]['filename']\n",
    "        classes = file_classes[filename]\n",
    "        class_counts.update(classes)\n",
    "    \n",
    "    return dict(class_counts)\n",
    "\n",
    "print(\"Creating fold directories and copying files...\")\n",
    "\n",
    "for fold_idx in range(k_folds):\n",
    "    print(f\"\\nProcessing Fold {fold_idx + 1}/{k_folds}\")\n",
    "    \n",
    "    # Create fold directory structure\n",
    "    fold_dir = create_fold_directories(output_path, fold_idx + 1)\n",
    "    \n",
    "    # Get splits for this fold\n",
    "    splits = fold_splits[fold_idx]\n",
    "    \n",
    "    # Copy files for each split\n",
    "    for split_name, indices in splits.items():\n",
    "        copied_count = copy_files_for_split(all_files, indices, fold_dir, split_name)\n",
    "        print(f\"  {split_name}: copied {copied_count} files\")\n",
    "        \n",
    "        # Analyze class distribution for this split\n",
    "        class_dist = analyze_fold_distribution(all_files, indices, file_classes)\n",
    "        print(f\"    Class distribution: {class_dist}\")\n",
    "    \n",
    "    # Create data.yaml for this fold\n",
    "    yaml_path = create_data_yaml(fold_dir, data_config, fold_idx + 1)\n",
    "    print(f\"  Created: {yaml_path}\")\n",
    "\n",
    "print(f\"\\nK-fold cross validation setup complete!\")\n",
    "print(f\"Output directory: {output_path}\")\n",
    "print(f\"Each fold contains train (~68%), val (~12%), test (20%) splits with balanced class distributions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1c7ba07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "K-FOLD CROSS VALIDATION SUMMARY\n",
      "============================================================\n",
      "Fold 1:\n",
      "  Train: 8236 images (68.6%)\n",
      "  Val:   1373 images (11.4%)\n",
      "  Test:  2403 images (20.0%)\n",
      "  Total: 12012 images\n",
      "\n",
      "Fold 2:\n",
      "  Train: 8236 images (68.6%)\n",
      "  Val:   1373 images (11.4%)\n",
      "  Test:  2403 images (20.0%)\n",
      "  Total: 12012 images\n",
      "\n",
      "Fold 3:\n",
      "  Train: 8237 images (68.6%)\n",
      "  Val:   1373 images (11.4%)\n",
      "  Test:  2402 images (20.0%)\n",
      "  Total: 12012 images\n",
      "\n",
      "Fold 4:\n",
      "  Train: 8237 images (68.6%)\n",
      "  Val:   1373 images (11.4%)\n",
      "  Test:  2402 images (20.0%)\n",
      "  Total: 12012 images\n",
      "\n",
      "Fold 5:\n",
      "  Train: 8237 images (68.6%)\n",
      "  Val:   1373 images (11.4%)\n",
      "  Test:  2402 images (20.0%)\n",
      "  Total: 12012 images\n",
      "\n",
      "Original dataset: 12012 images\n",
      "Total processed: 12012 images per fold\n",
      "Class names: ['glass', 'metal', 'organic', 'paper', 'plastic']\n",
      "\n",
      "Directory structure verification:\n",
      "Fold 1: data.yaml exists = True\n",
      "Fold 2: data.yaml exists = True\n",
      "Fold 3: data.yaml exists = True\n",
      "Fold 4: data.yaml exists = True\n",
      "Fold 5: data.yaml exists = True\n",
      "\n",
      "Setup complete! You can now use each fold for cross-validation training.\n",
      "Each fold is located in: ../../datasets/k_fold_cv/fold_X/\n",
      "Each fold contains a data.yaml file ready for YOLO training.\n"
     ]
    }
   ],
   "source": [
    "# Final validation and summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"K-FOLD CROSS VALIDATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "total_files_processed = 0\n",
    "for fold_idx in range(k_folds):\n",
    "    fold_dir = os.path.join(output_path, f\"fold_{fold_idx + 1}\")\n",
    "    \n",
    "    # Count files in each split (train, val, and test)\n",
    "    train_count = len([f for f in os.listdir(os.path.join(fold_dir, 'train', 'images')) \n",
    "                      if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))])\n",
    "    val_count = len([f for f in os.listdir(os.path.join(fold_dir, 'val', 'images'))\n",
    "                    if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))])\n",
    "    test_count = len([f for f in os.listdir(os.path.join(fold_dir, 'test', 'images'))\n",
    "                     if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))])\n",
    "    \n",
    "    fold_total = train_count + val_count + test_count\n",
    "    total_files_processed += fold_total\n",
    "    \n",
    "    print(f\"Fold {fold_idx + 1}:\")\n",
    "    print(f\"  Train: {train_count} images ({train_count/fold_total*100:.1f}%)\")\n",
    "    print(f\"  Val:   {val_count} images ({val_count/fold_total*100:.1f}%)\")\n",
    "    print(f\"  Test:  {test_count} images ({test_count/fold_total*100:.1f}%)\")\n",
    "    print(f\"  Total: {fold_total} images\")\n",
    "    print()\n",
    "\n",
    "print(f\"Original dataset: {len(all_files)} images\")\n",
    "print(f\"Total processed: {total_files_processed // k_folds} images per fold\")\n",
    "print(f\"Class names: {data_config.get('names', [])}\")\n",
    "\n",
    "# Verify that each fold directory has the correct structure\n",
    "print(\"\\nDirectory structure verification:\")\n",
    "for fold_idx in range(k_folds):\n",
    "    fold_dir = os.path.join(output_path, f\"fold_{fold_idx + 1}\")\n",
    "    data_yaml_exists = os.path.exists(os.path.join(fold_dir, 'data.yaml'))\n",
    "    print(f\"Fold {fold_idx + 1}: data.yaml exists = {data_yaml_exists}\")\n",
    "\n",
    "print(f\"\\nSetup complete! You can now use each fold for cross-validation training.\")\n",
    "print(f\"Each fold is located in: {output_path}/fold_X/\")\n",
    "print(f\"Each fold contains a data.yaml file ready for YOLO training.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
