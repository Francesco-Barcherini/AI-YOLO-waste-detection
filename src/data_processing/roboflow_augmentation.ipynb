{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f0cbcc7",
   "metadata": {},
   "source": [
    "# Roboflow Dataset Augmentation and Synthetic Data Generation\n",
    "1. **Traditional augmentations:** horizontal flip, vertical flip, rotation, tilt, brightness\n",
    "2. **Synthetic data generation:** 70% augmented images + 30% completely synthetic images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ea4cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import yaml\n",
    "from PIL import Image, ImageDraw, ImageEnhance\n",
    "import random\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "from pathlib import Path\n",
    "import albumentations as A\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a25d460",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45eca8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# --- Paths ---\n",
    "BASE_DIR = Path('/home/andrea/work/AI-waste-detection/')\n",
    "K_FOLD_CV_DIR = BASE_DIR / 'datasets/k_fold_cv'  # Source k-fold CV dataset\n",
    "K_FOLD_CV_AUGMENTED_DIR = BASE_DIR / 'datasets/k_fold_cv_augmented'  # Output augmented dataset\n",
    "OBJECT_BANK_DIR = BASE_DIR / 'datasets/object_bank_for_balancing'  # Pre-existing object bank\n",
    "\n",
    "# --- K-Fold Configuration ---\n",
    "NUM_FOLDS = 5  # Number of folds to process (fold_0 to fold_4)\n",
    "\n",
    "# --- Generation Parameters ---\n",
    "IMAGE_SIZE = (640, 640)\n",
    "OBJECTS_PER_IMAGE_RANGE = (1, 7)\n",
    "SCALE_RANGE = (0.2, 0.7)\n",
    "ROTATION_RANGE = (-20, 20)\n",
    "OVERLAP_THRESHOLD = 0.05\n",
    "\n",
    "# --- Augmentation Parameters ---\n",
    "HORIZONTAL_FLIP_PROB = 0.5\n",
    "VERTICAL_FLIP_PROB = 0.5\n",
    "ROTATION_PROB = 0.25  # 25% chance for 0,90,180,270 rotation\n",
    "TILT_RANGE = (-15, 15)  # degrees\n",
    "BRIGHTNESS_RANGE = (0.92, 1.08)  # ¬±8% brightness change\n",
    "\n",
    "# --- Synthetic Data Distribution ---\n",
    "AUGMENTED_SYNTHETIC_RATIO = 0.7  # 70% augmented images\n",
    "PURE_SYNTHETIC_RATIO = 0.3       # 30% pure synthetic images\n",
    "\n",
    "# Create directories\n",
    "K_FOLD_CV_AUGMENTED_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Source K-Fold CV Directory: {K_FOLD_CV_DIR}\")\n",
    "print(f\"Output Augmented Directory: {K_FOLD_CV_AUGMENTED_DIR}\")\n",
    "print(f\"Object Bank Directory: {OBJECT_BANK_DIR}\")\n",
    "print(f\"Number of folds to process: {NUM_FOLDS}\")\n",
    "\n",
    "# Check if source exists\n",
    "if not K_FOLD_CV_DIR.exists():\n",
    "    print(f\"‚ùå ERROR: Source k-fold CV dataset not found at {K_FOLD_CV_DIR}\")\n",
    "else:\n",
    "    print(f\"‚úÖ Source k-fold CV dataset found\")\n",
    "    # Check individual folds\n",
    "    for fold_idx in range(NUM_FOLDS):\n",
    "        fold_dir = K_FOLD_CV_DIR / f'fold_{fold_idx}'\n",
    "        if fold_dir.exists():\n",
    "            print(f\"  ‚úÖ Found fold_{fold_idx}\")\n",
    "        else:\n",
    "            print(f\"  ‚ùå Missing fold_{fold_idx}\")\n",
    "    \n",
    "if not OBJECT_BANK_DIR.exists():\n",
    "    print(f\"‚ùå WARNING: Object bank not found at {OBJECT_BANK_DIR}\")\n",
    "    print(\"  You may need to run synthetic_data_generation.ipynb first to create the object bank\")\n",
    "else:\n",
    "    print(f\"‚úÖ Object bank found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33659d76",
   "metadata": {},
   "source": [
    "## 2. Analyze Original Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5019ee36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_config(dataset_dir):\n",
    "    \"\"\"Loads the data.yaml file from the dataset directory.\"\"\"\n",
    "    config_path = dataset_dir / 'data.yaml'\n",
    "    if not config_path.exists():\n",
    "        raise FileNotFoundError(f\"data.yaml not found in {dataset_dir}\")\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    return config\n",
    "\n",
    "def get_class_distribution(labels_dir, num_classes):\n",
    "    \"\"\"Counts class instances in a directory of YOLO label files.\"\"\"\n",
    "    class_counts = Counter()\n",
    "    if not labels_dir.is_dir():\n",
    "        return class_counts\n",
    "    for label_file in labels_dir.glob('*.txt'):\n",
    "        with open(label_file, 'r') as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    # Convert to float first, then to int to handle cases like '4.0'\n",
    "                    class_id = int(float(line.split()[0]))\n",
    "                    if class_id < num_classes:\n",
    "                        class_counts[class_id] += 1\n",
    "    return class_counts\n",
    "\n",
    "def analyze_kfold_dataset_distribution():\n",
    "    \"\"\"Analyze the class distribution of all folds in the k-fold CV dataset.\"\"\"\n",
    "    print(\"üìä Analyzing K-Fold CV Dataset...\")\n",
    "    \n",
    "    fold_distributions = {}\n",
    "    target_classes = None\n",
    "    num_classes = 0\n",
    "    \n",
    "    try:\n",
    "        # Get class info from first available fold\n",
    "        for fold_idx in range(NUM_FOLDS):\n",
    "            fold_dir = K_FOLD_CV_DIR / f'fold_{fold_idx}'\n",
    "            if fold_dir.exists():\n",
    "                dataset_config = load_dataset_config(fold_dir)\n",
    "                target_classes = dataset_config.get('names', [])\n",
    "                num_classes = len(target_classes)\n",
    "                print(f\"Target classes from fold_{fold_idx}/data.yaml: {target_classes}\")\n",
    "                break\n",
    "        \n",
    "        if not target_classes:\n",
    "            raise FileNotFoundError(\"No valid data.yaml found in any fold\")\n",
    "        \n",
    "        # Analyze each fold\n",
    "        for fold_idx in range(NUM_FOLDS):\n",
    "            fold_dir = K_FOLD_CV_DIR / f'fold_{fold_idx}'\n",
    "            if not fold_dir.exists():\n",
    "                print(f\"‚ö†Ô∏è  Warning: fold_{fold_idx} not found, skipping...\")\n",
    "                continue\n",
    "                \n",
    "            print(f\"\\nüìÅ Analyzing fold_{fold_idx}...\")\n",
    "            \n",
    "            # Analyze train set for this fold\n",
    "            train_labels_dir = fold_dir / 'train/labels'\n",
    "            train_distribution = get_class_distribution(train_labels_dir, num_classes)\n",
    "            \n",
    "            # Analyze validation set for this fold\n",
    "            val_labels_dir = fold_dir / 'val/labels'\n",
    "            val_distribution = get_class_distribution(val_labels_dir, num_classes)\n",
    "            \n",
    "            fold_distributions[fold_idx] = {\n",
    "                'train': train_distribution,\n",
    "                'val': val_distribution\n",
    "            }\n",
    "            \n",
    "            print(f\"  Train Set Distribution:\")\n",
    "            for i, class_name in enumerate(target_classes):\n",
    "                print(f\"    - {class_name} (ID {i}): {train_distribution[i]} instances\")\n",
    "                \n",
    "            print(f\"  Validation Set Distribution:\")\n",
    "            for i, class_name in enumerate(target_classes):\n",
    "                print(f\"    - {class_name} (ID {i}): {val_distribution[i]} instances\")\n",
    "        \n",
    "        # Plot distributions for all folds\n",
    "        if fold_distributions:\n",
    "            num_folds_found = len(fold_distributions)\n",
    "            fig, axes = plt.subplots(2, num_folds_found, figsize=(5*num_folds_found, 10))\n",
    "            if num_folds_found == 1:\n",
    "                axes = axes.reshape(-1, 1)\n",
    "            \n",
    "            for idx, (fold_idx, distributions) in enumerate(fold_distributions.items()):\n",
    "                # Train distribution\n",
    "                train_df = pd.DataFrame.from_dict(distributions['train'], orient='index').sort_index()\n",
    "                if not train_df.empty:\n",
    "                    train_df.plot(kind='bar', legend=False, ax=axes[0, idx], \n",
    "                                title=f'Fold {fold_idx} - Train Set')\n",
    "                    axes[0, idx].set_xlabel('Class ID')\n",
    "                    axes[0, idx].set_ylabel('Instances')\n",
    "                \n",
    "                # Val distribution\n",
    "                val_df = pd.DataFrame.from_dict(distributions['val'], orient='index').sort_index()\n",
    "                if not val_df.empty:\n",
    "                    val_df.plot(kind='bar', legend=False, ax=axes[1, idx], \n",
    "                              title=f'Fold {fold_idx} - Val Set')\n",
    "                    axes[1, idx].set_xlabel('Class ID')\n",
    "                    axes[1, idx].set_ylabel('Instances')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "        return target_classes, num_classes, fold_distributions\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error analyzing k-fold dataset: {e}\")\n",
    "        return [], 0, {}\n",
    "\n",
    "# Analyze the k-fold dataset\n",
    "TARGET_CLASSES, NUM_CLASSES, FOLD_DISTRIBUTIONS = analyze_kfold_dataset_distribution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653ac65f",
   "metadata": {},
   "source": [
    "## 3. Traditional Augmentation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5093775d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_yolo_label(label_line, img_width, img_height):\n",
    "    \"\"\"Parse a YOLO label line into absolute coordinates.\"\"\"\n",
    "    parts = label_line.strip().split()\n",
    "    # Convert to float first, then to int to handle cases like '4.0'\n",
    "    class_id = int(float(parts[0]))\n",
    "    cx, cy, w, h = map(float, parts[1:5])\n",
    "    \n",
    "    # Convert to absolute coordinates\n",
    "    x1 = int((cx - w/2) * img_width)\n",
    "    y1 = int((cy - h/2) * img_height)\n",
    "    x2 = int((cx + w/2) * img_width)\n",
    "    y2 = int((cy + h/2) * img_height)\n",
    "    \n",
    "    return class_id, [x1, y1, x2, y2]\n",
    "\n",
    "def bbox_to_yolo(bbox, img_width, img_height):\n",
    "    \"\"\"Convert absolute bbox to YOLO format.\"\"\"\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    cx = (x1 + x2) / 2 / img_width\n",
    "    cy = (y1 + y2) / 2 / img_height\n",
    "    w = (x2 - x1) / img_width\n",
    "    h = (y2 - y1) / img_height\n",
    "    return cx, cy, w, h\n",
    "\n",
    "def apply_traditional_augmentations(img_path, label_path, output_img_dir, output_label_dir, base_filename):\n",
    "    \"\"\"Apply traditional augmentations to an image and its labels.\"\"\"\n",
    "    # Load image\n",
    "    image = cv2.imread(str(img_path))\n",
    "    if image is None:\n",
    "        return []\n",
    "    \n",
    "    # Convert BGR to RGB for albumentations\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    img_height, img_width = image.shape[:2]\n",
    "    \n",
    "    # Load labels\n",
    "    bboxes = []\n",
    "    class_labels = []\n",
    "    \n",
    "    if label_path.exists():\n",
    "        with open(label_path, 'r') as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    class_id, bbox = parse_yolo_label(line, img_width, img_height)\n",
    "                    # Convert to normalized format [x_min, y_min, x_max, y_max] for albumentations\n",
    "                    x1, y1, x2, y2 = bbox\n",
    "                    norm_bbox = [x1/img_width, y1/img_height, x2/img_width, y2/img_height]\n",
    "                    bboxes.append(norm_bbox)\n",
    "                    class_labels.append(class_id)\n",
    "    \n",
    "    augmented_files = []\n",
    "    \n",
    "    # Define augmentation compositions with bbox_params\n",
    "    transform_configs = [\n",
    "        # Horizontal flip\n",
    "        (A.HorizontalFlip(p=1.0), HORIZONTAL_FLIP_PROB),\n",
    "        # Vertical flip  \n",
    "        (A.VerticalFlip(p=1.0), VERTICAL_FLIP_PROB),\n",
    "        # Random rotation (0, 90, 180, 270)\n",
    "        (A.RandomRotate90(p=1.0), ROTATION_PROB),\n",
    "        # Tilt (affine rotation)\n",
    "        (A.Affine(rotate=random.uniform(*TILT_RANGE), p=1.0), 1.0),\n",
    "        # Brightness change\n",
    "        (A.RandomBrightnessContrast(\n",
    "            brightness_limit=(BRIGHTNESS_RANGE[0]-1, BRIGHTNESS_RANGE[1]-1),\n",
    "            contrast_limit=0,\n",
    "            p=1.0\n",
    "        ), 1.0)\n",
    "    ]\n",
    "    \n",
    "    # Apply augmentations\n",
    "    for aug_idx, (augmentation, prob) in enumerate(transform_configs):\n",
    "        if random.random() >= prob:\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # Create composition with bbox parameters\n",
    "            transform = A.Compose([augmentation], \n",
    "                                bbox_params=A.BboxParams(format='albumentations', \n",
    "                                                       label_fields=['class_labels'],\n",
    "                                                       min_visibility=0.1))\n",
    "            \n",
    "            # Apply augmentation\n",
    "            if len(bboxes) > 0:\n",
    "                augmented = transform(image=image, bboxes=bboxes, class_labels=class_labels)\n",
    "                aug_image = augmented['image']\n",
    "                aug_bboxes = augmented['bboxes']\n",
    "                aug_class_labels = augmented['class_labels']\n",
    "            else:\n",
    "                # If no bboxes, just transform the image\n",
    "                augmented = transform(image=image, bboxes=[], class_labels=[])\n",
    "                aug_image = augmented['image']\n",
    "                aug_bboxes = []\n",
    "                aug_class_labels = []\n",
    "            \n",
    "            # Convert back to BGR for saving\n",
    "            aug_image_bgr = cv2.cvtColor(aug_image, cv2.COLOR_RGB2BGR)\n",
    "            \n",
    "            # Save augmented image\n",
    "            aug_filename = f\"{base_filename}_aug_{aug_idx}\"\n",
    "            aug_img_path = output_img_dir / f\"{aug_filename}.jpg\"\n",
    "            aug_label_path = output_label_dir / f\"{aug_filename}.txt\"\n",
    "            \n",
    "            cv2.imwrite(str(aug_img_path), aug_image_bgr)\n",
    "            \n",
    "            # Save augmented labels\n",
    "            with open(aug_label_path, 'w') as f:\n",
    "                for class_id, norm_bbox in zip(aug_class_labels, aug_bboxes):\n",
    "                    # Convert normalized bbox back to absolute coordinates\n",
    "                    x1_norm, y1_norm, x2_norm, y2_norm = norm_bbox\n",
    "                    x1 = x1_norm * aug_image.shape[1]\n",
    "                    y1 = y1_norm * aug_image.shape[0]\n",
    "                    x2 = x2_norm * aug_image.shape[1]\n",
    "                    y2 = y2_norm * aug_image.shape[0]\n",
    "                    \n",
    "                    # Convert to YOLO format\n",
    "                    cx, cy, w, h = bbox_to_yolo([x1, y1, x2, y2], aug_image.shape[1], aug_image.shape[0])\n",
    "                    f.write(f\"{class_id} {cx:.6f} {cy:.6f} {w:.6f} {h:.6f}\\n\")\n",
    "            \n",
    "            augmented_files.append((aug_img_path, aug_label_path))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Failed to apply augmentation {aug_idx}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    return augmented_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad6b3f2",
   "metadata": {},
   "source": [
    "## 4. Synthetic Data Generation (Based on synthetic_data_generation.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95021acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_object_bank():\n",
    "    \"\"\"Loads the paths of all objects in the bank, organized by class name.\"\"\"\n",
    "    object_bank = defaultdict(list)\n",
    "    print(\"üîé Loading Object Bank...\")\n",
    "    if not OBJECT_BANK_DIR.exists():\n",
    "        print(\"  Object bank directory not found.\")\n",
    "        return object_bank\n",
    "        \n",
    "    for class_dir in OBJECT_BANK_DIR.iterdir():\n",
    "        if class_dir.is_dir():\n",
    "            for obj_file in class_dir.glob('*.png'):\n",
    "                object_bank[class_dir.name].append(obj_file)\n",
    "    \n",
    "    print(\"  Object Bank loaded successfully.\")\n",
    "    for class_name, objects in object_bank.items():\n",
    "        print(f\"  - Found {len(objects)} objects for class '{class_name}'\")\n",
    "    return object_bank\n",
    "\n",
    "def create_gradient_background(size):\n",
    "    \"\"\"Creates a background with a random linear gradient.\"\"\"\n",
    "    width, height = size\n",
    "    color1 = np.random.randint(150, 255, 3)\n",
    "    color2 = np.random.randint(150, 255, 3)\n",
    "    \n",
    "    background = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "    for y in range(height):\n",
    "        ratio = y / height\n",
    "        color = (color1 * (1 - ratio) + color2 * ratio).astype(np.uint8)\n",
    "        background[y, :] = color\n",
    "        \n",
    "    return Image.fromarray(background)\n",
    "\n",
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"Calculates IoU for two boxes in (x1, y1, x2, y2) format.\"\"\"\n",
    "    x1_i = max(box1[0], box2[0])\n",
    "    y1_i = max(box1[1], box2[1])\n",
    "    x2_i = min(box1[2], box2[2])\n",
    "    y2_i = min(box1[3], box2[3])\n",
    "    \n",
    "    inter_area = max(0, x2_i - x1_i) * max(0, y2_i - y1_i)\n",
    "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    \n",
    "    return inter_area / union_area if union_area > 0 else 0\n",
    "\n",
    "def generate_pure_synthetic_image(object_bank, classes_to_add, image_size):\n",
    "    \"\"\"Generates a completely synthetic image with gradient background.\"\"\"\n",
    "    background = create_gradient_background(image_size)\n",
    "    placed_object_bboxes = []\n",
    "    yolo_annotations = []\n",
    "\n",
    "    for class_name in classes_to_add:\n",
    "        if class_name not in TARGET_CLASSES:\n",
    "            continue\n",
    "        class_id = TARGET_CLASSES.index(class_name)\n",
    "        \n",
    "        if not object_bank[class_name]: \n",
    "            continue\n",
    "\n",
    "        obj_path = random.choice(object_bank[class_name])\n",
    "        obj_img = Image.open(obj_path)\n",
    "\n",
    "        # Random transformations\n",
    "        scale = random.uniform(*SCALE_RANGE)\n",
    "        new_size = (int(image_size[0] * scale), int(image_size[1] * scale))\n",
    "        obj_img.thumbnail(new_size, Image.Resampling.LANCZOS)\n",
    "        rotation = random.uniform(*ROTATION_RANGE)\n",
    "        obj_img = obj_img.rotate(rotation, expand=True, resample=Image.Resampling.BICUBIC)\n",
    "\n",
    "        # Find a valid placement\n",
    "        for _ in range(50): # 50 attempts\n",
    "            pos_x = random.randint(0, image_size[0] - obj_img.width)\n",
    "            pos_y = random.randint(0, image_size[1] - obj_img.height)\n",
    "            \n",
    "            new_bbox_corners = (pos_x, pos_y, pos_x + obj_img.width, pos_y + obj_img.height)\n",
    "            \n",
    "            is_overlapping = any(calculate_iou(new_bbox_corners, b) > OVERLAP_THRESHOLD for b in placed_object_bboxes)\n",
    "            \n",
    "            if not is_overlapping:\n",
    "                background.paste(obj_img, (pos_x, pos_y), obj_img)\n",
    "                placed_object_bboxes.append(new_bbox_corners)\n",
    "                \n",
    "                # YOLO format: class_id cx cy w h\n",
    "                cx = (pos_x + obj_img.width / 2) / image_size[0]\n",
    "                cy = (pos_y + obj_img.height / 2) / image_size[1]\n",
    "                w = obj_img.width / image_size[0]\n",
    "                h = obj_img.height / image_size[1]\n",
    "                yolo_annotations.append(f\"{class_id} {cx:.6f} {cy:.6f} {w:.6f} {h:.6f}\")\n",
    "                break\n",
    "                \n",
    "    return background, yolo_annotations\n",
    "\n",
    "def generate_augmented_synthetic_image(original_img_path, original_label_path, object_bank, target_classes):\n",
    "    \"\"\"Takes an existing image and adds synthetic objects to it.\"\"\"\n",
    "    # Load original image\n",
    "    original_img = cv2.imread(str(original_img_path))\n",
    "    if original_img is None:\n",
    "        return None, []\n",
    "    \n",
    "    img_height, img_width = original_img.shape[:2]\n",
    "    original_pil = Image.fromarray(cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    # Resize to target size\n",
    "    original_pil = original_pil.resize(IMAGE_SIZE, Image.Resampling.LANCZOS)\n",
    "    \n",
    "    # Load existing annotations\n",
    "    existing_bboxes = []\n",
    "    yolo_annotations = []\n",
    "    \n",
    "    if original_label_path.exists():\n",
    "        with open(original_label_path, 'r') as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    class_id, bbox = parse_yolo_label(line, IMAGE_SIZE[0], IMAGE_SIZE[1])\n",
    "                    existing_bboxes.append(bbox)\n",
    "                    # Keep original annotations\n",
    "                    cx, cy, w, h = bbox_to_yolo(bbox, IMAGE_SIZE[0], IMAGE_SIZE[1])\n",
    "                    yolo_annotations.append(f\"{class_id} {cx:.6f} {cy:.6f} {w:.6f} {h:.6f}\")\n",
    "    \n",
    "    # Add 1-3 synthetic objects\n",
    "    num_objects_to_add = random.randint(1, 3)\n",
    "    available_classes = [cls for cls in target_classes if object_bank[cls]]\n",
    "    \n",
    "    if not available_classes:\n",
    "        return original_pil, yolo_annotations\n",
    "    \n",
    "    classes_to_add = random.choices(available_classes, k=min(num_objects_to_add, len(available_classes)))\n",
    "    \n",
    "    for class_name in classes_to_add:\n",
    "        class_id = target_classes.index(class_name)\n",
    "        \n",
    "        obj_path = random.choice(object_bank[class_name])\n",
    "        obj_img = Image.open(obj_path)\n",
    "        \n",
    "        # Random transformations\n",
    "        scale = random.uniform(0.1, 0.4)  # Smaller scale for augmented images\n",
    "        new_size = (int(IMAGE_SIZE[0] * scale), int(IMAGE_SIZE[1] * scale))\n",
    "        obj_img.thumbnail(new_size, Image.Resampling.LANCZOS)\n",
    "        rotation = random.uniform(*ROTATION_RANGE)\n",
    "        obj_img = obj_img.rotate(rotation, expand=True, resample=Image.Resampling.BICUBIC)\n",
    "        \n",
    "        # Find placement that doesn't overlap with existing objects\n",
    "        for _ in range(30):  # 30 attempts\n",
    "            pos_x = random.randint(0, IMAGE_SIZE[0] - obj_img.width)\n",
    "            pos_y = random.randint(0, IMAGE_SIZE[1] - obj_img.height)\n",
    "            \n",
    "            new_bbox = (pos_x, pos_y, pos_x + obj_img.width, pos_y + obj_img.height)\n",
    "            \n",
    "            # Check overlap with existing objects\n",
    "            is_overlapping = any(calculate_iou(new_bbox, existing_bbox) > OVERLAP_THRESHOLD for existing_bbox in existing_bboxes)\n",
    "            \n",
    "            if not is_overlapping:\n",
    "                original_pil.paste(obj_img, (pos_x, pos_y), obj_img)\n",
    "                existing_bboxes.append(new_bbox)\n",
    "                \n",
    "                # Add new annotation\n",
    "                cx = (pos_x + obj_img.width / 2) / IMAGE_SIZE[0]\n",
    "                cy = (pos_y + obj_img.height / 2) / IMAGE_SIZE[1]\n",
    "                w = obj_img.width / IMAGE_SIZE[0]\n",
    "                h = obj_img.height / IMAGE_SIZE[1]\n",
    "                yolo_annotations.append(f\"{class_id} {cx:.6f} {cy:.6f} {w:.6f} {h:.6f}\")\n",
    "                break\n",
    "    \n",
    "    return original_pil, yolo_annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4dd432",
   "metadata": {},
   "source": [
    "## 5. Dataset Augmentation and Balancing\n",
    "TARGET_TOTAL_INSTANCES_PER_FOLD desired number of training images per fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aea783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_augmented_kfold_dataset():\n",
    "    \"\"\"Creates the augmented k-fold CV dataset with controlled size and proper balancing.\"\"\"\n",
    "    print(\"üöÄ Creating Augmented K-Fold CV Dataset...\")\n",
    "    \n",
    "    # Target parameters per fold\n",
    "    TARGET_TOTAL_INSTANCES_PER_FOLD = 27000\n",
    "    TARGET_INSTANCES_PER_CLASS_PER_FOLD = TARGET_TOTAL_INSTANCES_PER_FOLD // NUM_CLASSES\n",
    "    \n",
    "    print(f\"üéØ Target per fold: {TARGET_TOTAL_INSTANCES_PER_FOLD} total instances ({TARGET_INSTANCES_PER_CLASS_PER_FOLD} per class)\")\n",
    "    \n",
    "    # Process each fold\n",
    "    for fold_idx in range(NUM_FOLDS):\n",
    "        fold_dir = K_FOLD_CV_DIR / f'fold_{fold_idx}'\n",
    "        augmented_fold_dir = K_FOLD_CV_AUGMENTED_DIR / f'fold_{fold_idx}'\n",
    "        \n",
    "        if not fold_dir.exists():\n",
    "            print(f\"‚ö†Ô∏è  Skipping fold_{fold_idx}: source directory not found\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nüîÑ Processing fold_{fold_idx}...\")\n",
    "        \n",
    "        # Create output directory structure for this fold\n",
    "        train_img_dir = augmented_fold_dir / 'train/images'\n",
    "        train_label_dir = augmented_fold_dir / 'train/labels'\n",
    "        val_img_dir = augmented_fold_dir / 'val/images'\n",
    "        val_label_dir = augmented_fold_dir / 'val/labels'\n",
    "        \n",
    "        for dir_path in [train_img_dir, train_label_dir, val_img_dir, val_label_dir]:\n",
    "            dir_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Copy data.yaml for this fold\n",
    "        shutil.copy2(fold_dir / 'data.yaml', augmented_fold_dir / 'data.yaml')\n",
    "        \n",
    "        # Copy validation set unchanged\n",
    "        print(f\"  üìÅ Copying validation set for fold_{fold_idx}...\")\n",
    "        val_source_dir = fold_dir / 'val'\n",
    "        if val_source_dir.exists():\n",
    "            if (val_source_dir / 'images').exists():\n",
    "                for img_file in (val_source_dir / 'images').glob('*'):\n",
    "                    shutil.copy2(img_file, val_img_dir)\n",
    "            if (val_source_dir / 'labels').exists():\n",
    "                for label_file in (val_source_dir / 'labels').glob('*'):\n",
    "                    shutil.copy2(label_file, val_label_dir)\n",
    "        \n",
    "        # Copy original training set\n",
    "        print(f\"  üìÅ Copying original training set for fold_{fold_idx}...\")\n",
    "        train_source_dir = fold_dir / 'train'\n",
    "        original_train_files = []\n",
    "        \n",
    "        if (train_source_dir / 'images').exists():\n",
    "            for img_file in (train_source_dir / 'images').glob('*'):\n",
    "                shutil.copy2(img_file, train_img_dir)\n",
    "                original_train_files.append(img_file.stem)\n",
    "                \n",
    "        if (train_source_dir / 'labels').exists():\n",
    "            for label_file in (train_source_dir / 'labels').glob('*'):\n",
    "                shutil.copy2(label_file, train_label_dir)\n",
    "        \n",
    "        # Get current class distribution for this fold\n",
    "        original_dist = get_class_distribution(train_label_dir, NUM_CLASSES)\n",
    "        total_original = sum(original_dist.values())\n",
    "        \n",
    "        print(f\"  üìä Original distribution for fold_{fold_idx} (total: {total_original}):\")\n",
    "        for i, class_name in enumerate(TARGET_CLASSES):\n",
    "            count = original_dist.get(i, 0)\n",
    "            print(f\"    - {class_name}: {count} instances\")\n",
    "        \n",
    "        # Calculate what we need per class to reach target\n",
    "        needs_per_class = {}\n",
    "        total_needed_instances = 0\n",
    "        for i in range(NUM_CLASSES):\n",
    "            current_count = original_dist.get(i, 0)\n",
    "            needed = max(0, TARGET_INSTANCES_PER_CLASS_PER_FOLD - current_count)\n",
    "            needs_per_class[i] = needed\n",
    "            total_needed_instances += needed\n",
    "        \n",
    "        print(f\"    üî¢ Total instances needed for fold_{fold_idx}: {total_needed_instances}\")\n",
    "        \n",
    "        if total_needed_instances == 0:\n",
    "            print(f\"    ‚úÖ Fold_{fold_idx} is already balanced at target size!\")\n",
    "            continue\n",
    "        \n",
    "        # Calculate distribution of how to generate the needed instances\n",
    "        traditional_target_instances = int(total_needed_instances * 0.4)  # 40% traditional\n",
    "        synthetic_target_instances = total_needed_instances - traditional_target_instances  # 60% synthetic\n",
    "        \n",
    "        augmented_synthetic_target_instances = int(synthetic_target_instances * AUGMENTED_SYNTHETIC_RATIO)\n",
    "        pure_synthetic_target_instances = synthetic_target_instances - augmented_synthetic_target_instances\n",
    "        \n",
    "        print(f\"    üìã Generation plan for fold_{fold_idx}:\")\n",
    "        print(f\"      - Traditional augmentations: {traditional_target_instances} instances\")\n",
    "        print(f\"      - Synthetic images: {synthetic_target_instances} instances\")\n",
    "        print(f\"        ‚îú‚îÄ‚îÄ Augmented synthetic: {augmented_synthetic_target_instances} instances\")\n",
    "        print(f\"        ‚îî‚îÄ‚îÄ Pure synthetic: {pure_synthetic_target_instances} instances\")\n",
    "        \n",
    "        # Collect images by class for targeted augmentation for this fold\n",
    "        class_to_images = defaultdict(list)\n",
    "        \n",
    "        for label_file in (train_source_dir / 'labels').glob('*.txt'):\n",
    "            img_file = train_source_dir / 'images' / f\"{label_file.stem}.jpg\"\n",
    "            if not img_file.exists():\n",
    "                for ext in ['.png', '.jpeg', '.JPG', '.PNG']:\n",
    "                    alt_path = train_source_dir / 'images' / f\"{label_file.stem}{ext}\"\n",
    "                    if alt_path.exists():\n",
    "                        img_file = alt_path\n",
    "                        break\n",
    "            \n",
    "            if not img_file.exists():\n",
    "                continue\n",
    "            \n",
    "            # Read classes in this image\n",
    "            classes_in_image = set()\n",
    "            try:\n",
    "                with open(label_file, 'r') as f:\n",
    "                    for line in f:\n",
    "                        if line.strip():\n",
    "                            class_id = int(float(line.split()[0]))\n",
    "                            if class_id < NUM_CLASSES:\n",
    "                                classes_in_image.add(class_id)\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            # Add this image to all classes it contains\n",
    "            for class_id in classes_in_image:\n",
    "                class_to_images[class_id].append((img_file, label_file))\n",
    "        \n",
    "        print(f\"    üìã Images available per class for fold_{fold_idx}:\")\n",
    "        for i in range(NUM_CLASSES):\n",
    "            count = len(class_to_images[i])\n",
    "            print(f\"      - Class {i} ({TARGET_CLASSES[i]}): {count} images\")\n",
    "        \n",
    "        # Phase 1: Apply controlled traditional augmentations (40% of needed instances)\n",
    "        print(f\"    üîÑ Phase 1: Applying traditional augmentations for fold_{fold_idx} (target: {traditional_target_instances} instances)...\")\n",
    "        augmented_count = 0\n",
    "        traditional_needs = needs_per_class.copy()\n",
    "        \n",
    "        # Limit traditional augmentations per class to maintain balance\n",
    "        for class_id in range(NUM_CLASSES):\n",
    "            max_traditional_for_class = max(1, int(traditional_target_instances / NUM_CLASSES))\n",
    "            traditional_needs[class_id] = min(traditional_needs[class_id], max_traditional_for_class)\n",
    "        \n",
    "        for class_id in range(NUM_CLASSES):\n",
    "            needed = traditional_needs[class_id]\n",
    "            if needed <= 0:\n",
    "                continue\n",
    "                \n",
    "            class_name = TARGET_CLASSES[class_id]\n",
    "            available_images = class_to_images[class_id]\n",
    "            \n",
    "            if not available_images:\n",
    "                print(f\"      ‚ö†Ô∏è  Warning: No images found for class {class_name} in fold_{fold_idx}\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"      üé® Generating {needed} traditional augmentations for {class_name} in fold_{fold_idx}...\")\n",
    "            \n",
    "            generated_for_class = 0\n",
    "            attempts = 0\n",
    "            max_attempts = len(available_images) * 5  # Limit attempts\n",
    "            \n",
    "            while generated_for_class < needed and attempts < max_attempts:\n",
    "                img_path, label_path = random.choice(available_images)\n",
    "                \n",
    "                base_filename = f\"{img_path.stem}_fold{fold_idx}_cls{class_id}_aug{attempts}\"\n",
    "                aug_files = apply_traditional_augmentations(\n",
    "                    img_path, label_path, train_img_dir, train_label_dir, base_filename\n",
    "                )\n",
    "                \n",
    "                # Count instances of our target class that were generated\n",
    "                for aug_img_path, aug_label_path in aug_files:\n",
    "                    if aug_label_path.exists():\n",
    "                        with open(aug_label_path, 'r') as f:\n",
    "                            for line in f:\n",
    "                                if line.strip():\n",
    "                                    try:\n",
    "                                        line_class_id = int(float(line.split()[0]))\n",
    "                                        if line_class_id == class_id:\n",
    "                                            generated_for_class += 1\n",
    "                                            augmented_count += 1\n",
    "                                            if generated_for_class >= needed:\n",
    "                                                break\n",
    "                                    except:\n",
    "                                        continue\n",
    "                        if generated_for_class >= needed:\n",
    "                            break\n",
    "                \n",
    "                attempts += 1\n",
    "            \n",
    "            # Update original needs\n",
    "            needs_per_class[class_id] = max(0, needs_per_class[class_id] - generated_for_class)\n",
    "            print(f\"        ‚úÖ Generated {generated_for_class} traditional augmentations for {class_name} in fold_{fold_idx}\")\n",
    "        \n",
    "        print(f\"    ‚úÖ Total traditional augmentations for fold_{fold_idx}: {augmented_count}\")\n",
    "        \n",
    "        # Phase 2: Generate synthetic images for remaining needs\n",
    "        remaining_needed = sum(needs_per_class.values())\n",
    "        if remaining_needed > 0:\n",
    "            print(f\"    üß¨ Phase 2: Generating synthetic data for fold_{fold_idx} - {remaining_needed} remaining instances...\")\n",
    "            print(f\"      üìä Target distribution: {AUGMENTED_SYNTHETIC_RATIO:.0%} augmented synthetic + {PURE_SYNTHETIC_RATIO:.0%} pure synthetic\")\n",
    "            \n",
    "            # Load object bank\n",
    "            object_bank = load_object_bank()\n",
    "            \n",
    "            if not any(object_bank.values()):\n",
    "                print(f\"      ‚ùå Cannot generate synthetic data for fold_{fold_idx}: Object bank is empty\")\n",
    "            else:\n",
    "                synthetic_count = 0\n",
    "                augmented_synthetic_count = 0\n",
    "                pure_synthetic_count = 0\n",
    "                needs = needs_per_class.copy()  # Working copy\n",
    "                \n",
    "                # Target synthetic image counts (estimate 2-3 instances per image)\n",
    "                estimated_images_needed = remaining_needed // 2\n",
    "                target_augmented_synthetic_images = int(estimated_images_needed * AUGMENTED_SYNTHETIC_RATIO)\n",
    "                target_pure_synthetic_images = int(estimated_images_needed * PURE_SYNTHETIC_RATIO)\n",
    "                \n",
    "                print(f\"      üéØ Estimated target for fold_{fold_idx}: ~{target_augmented_synthetic_images} augmented synthetic + ~{target_pure_synthetic_images} pure synthetic images\")\n",
    "                \n",
    "                pbar = tqdm(total=remaining_needed, desc=f\"Synthetic generation fold_{fold_idx}\")\n",
    "                \n",
    "                while any(n > 0 for n in needs.values()) and synthetic_count < remaining_needed * 2:  # Safety limit\n",
    "                    needed_classes_ids = [cid for cid, n in needs.items() if n > 0]\n",
    "                    \n",
    "                    if not needed_classes_ids:\n",
    "                        break\n",
    "                    \n",
    "                    # Decide whether to generate augmented synthetic or pure synthetic\n",
    "                    current_total_synthetic = augmented_synthetic_count + pure_synthetic_count\n",
    "                    current_aug_ratio = augmented_synthetic_count / max(1, current_total_synthetic)\n",
    "                    \n",
    "                    should_generate_augmented = (\n",
    "                        current_aug_ratio < AUGMENTED_SYNTHETIC_RATIO and \n",
    "                        augmented_synthetic_count < target_augmented_synthetic_images and\n",
    "                        len(class_to_images.get(random.choice(needed_classes_ids), [])) > 0  # Has source images\n",
    "                    )\n",
    "                    \n",
    "                    if should_generate_augmented:\n",
    "                        # Generate augmented synthetic image\n",
    "                        candidate_classes = [cid for cid in needed_classes_ids if len(class_to_images.get(cid, [])) > 0]\n",
    "                        if candidate_classes:\n",
    "                            class_id = random.choice(candidate_classes)\n",
    "                            source_img_path, source_label_path = random.choice(class_to_images[class_id])\n",
    "                            \n",
    "                            img, annotations = generate_augmented_synthetic_image(\n",
    "                                source_img_path, source_label_path, object_bank, TARGET_CLASSES\n",
    "                            )\n",
    "                            \n",
    "                            if img and annotations:\n",
    "                                timestamp = pd.Timestamp.now().strftime('%Y%m%d%H%M%S%f')\n",
    "                                img_filename = f\"fold{fold_idx}_aug_synthetic_{timestamp}.jpg\"\n",
    "                                img.save(train_img_dir / img_filename)\n",
    "                                \n",
    "                                label_filename = Path(img_filename).with_suffix('.txt')\n",
    "                                with open(train_label_dir / label_filename, 'w') as f:\n",
    "                                    f.write(\"\\n\".join(annotations))\n",
    "                                \n",
    "                                augmented_synthetic_count += 1\n",
    "                            else:\n",
    "                                should_generate_augmented = False\n",
    "                        else:\n",
    "                            should_generate_augmented = False\n",
    "                    \n",
    "                    if not should_generate_augmented:\n",
    "                        # Generate pure synthetic image\n",
    "                        num_objects = random.randint(1, min(4, len(needed_classes_ids)))\n",
    "                        classes_to_request_ids = random.sample(needed_classes_ids, num_objects)\n",
    "                        classes_to_request_names = [TARGET_CLASSES[cid] for cid in classes_to_request_ids]\n",
    "\n",
    "                        img, annotations = generate_pure_synthetic_image(object_bank, classes_to_request_names, IMAGE_SIZE)\n",
    "                        \n",
    "                        if img and annotations:\n",
    "                            timestamp = pd.Timestamp.now().strftime('%Y%m%d%H%M%S%f')\n",
    "                            img_filename = f\"fold{fold_idx}_pure_synthetic_{timestamp}.jpg\"\n",
    "                            img.save(train_img_dir / img_filename)\n",
    "                            \n",
    "                            label_filename = Path(img_filename).with_suffix('.txt')\n",
    "                            with open(train_label_dir / label_filename, 'w') as f:\n",
    "                                f.write(\"\\n\".join(annotations))\n",
    "                            \n",
    "                            pure_synthetic_count += 1\n",
    "                        else:\n",
    "                            continue\n",
    "                    \n",
    "                    # Update needs and progress (for both types)\n",
    "                    if annotations:\n",
    "                        instances_added = 0\n",
    "                        for ann in annotations:\n",
    "                            class_id = int(ann.split()[0])\n",
    "                            if class_id < NUM_CLASSES and needs[class_id] > 0:\n",
    "                                needs[class_id] -= 1\n",
    "                                instances_added += 1\n",
    "                        \n",
    "                        if instances_added > 0:\n",
    "                            pbar.update(instances_added)\n",
    "                        synthetic_count += 1\n",
    "                \n",
    "                pbar.close()\n",
    "                total_synthetic_images = augmented_synthetic_count + pure_synthetic_count\n",
    "                print(f\"      ‚úÖ Generated {total_synthetic_images} synthetic images for fold_{fold_idx}:\")\n",
    "                print(f\"        - Augmented synthetic: {augmented_synthetic_count} images\")\n",
    "                print(f\"        - Pure synthetic: {pure_synthetic_count} images\")\n",
    "                \n",
    "                if total_synthetic_images > 0:\n",
    "                    actual_aug_ratio = augmented_synthetic_count / total_synthetic_images\n",
    "                    actual_pure_ratio = pure_synthetic_count / total_synthetic_images\n",
    "                    print(f\"        - Actual distribution: {actual_aug_ratio:.1%} augmented + {actual_pure_ratio:.1%} pure\")\n",
    "        \n",
    "        # Final summary for this fold\n",
    "        final_dist = get_class_distribution(train_label_dir, NUM_CLASSES)\n",
    "        final_total = sum(final_dist.values())\n",
    "        \n",
    "        print(f\"    üéâ Fold_{fold_idx} augmentation complete!\")\n",
    "        print(f\"      - Original instances: {total_original}\")\n",
    "        print(f\"      - Final instances: {final_total}\")\n",
    "        print(f\"      - Total increase: +{final_total - total_original} (+{((final_total/total_original - 1)*100):.1f}%)\")\n",
    "        print(f\"      - Total training images: {len(list(train_img_dir.glob('*')))}\")\n",
    "        \n",
    "        # Check balance for this fold\n",
    "        min_count = min(final_dist.values()) if final_dist else 0\n",
    "        max_count = max(final_dist.values()) if final_dist else 1\n",
    "        balance_ratio = min_count / max_count if max_count > 0 else 0\n",
    "        \n",
    "        print(f\"      üìä Final class distribution for fold_{fold_idx}:\")\n",
    "        for i, class_name in enumerate(TARGET_CLASSES):\n",
    "            count = final_dist.get(i, 0)\n",
    "            percentage = (count / final_total * 100) if final_total > 0 else 0\n",
    "            print(f\"        - {class_name}: {count} instances ({percentage:.1f}%)\")\n",
    "        \n",
    "        print(f\"      Balance ratio: {balance_ratio:.2f} (1.0 = perfect balance)\")\n",
    "        if balance_ratio >= 0.8:\n",
    "            print(f\"      ‚úÖ Fold_{fold_idx} is well balanced\")\n",
    "        else:\n",
    "            print(f\"      ‚ö†Ô∏è  Fold_{fold_idx} could be better balanced\")\n",
    "    \n",
    "    print(f\"\\nüéâ All folds augmentation completed!\")\n",
    "    print(f\"Augmented k-fold CV dataset available at: {K_FOLD_CV_AUGMENTED_DIR}\")\n",
    "    \n",
    "    return K_FOLD_CV_AUGMENTED_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1216c2ac",
   "metadata": {},
   "source": [
    "## 6. Verification and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc053659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_augmented_kfold_dataset():\n",
    "    \"\"\"Verify the final class distribution of the augmented k-fold CV dataset.\"\"\"\n",
    "    print(\"üìä Verifying Augmented K-Fold CV Dataset...\")\n",
    "    \n",
    "    if not K_FOLD_CV_AUGMENTED_DIR.exists():\n",
    "        print(\"‚ùå Augmented k-fold CV dataset not found.\")\n",
    "        return\n",
    "    \n",
    "    overall_stats = {}\n",
    "    fold_results = {}\n",
    "    \n",
    "    for fold_idx in range(NUM_FOLDS):\n",
    "        augmented_fold_dir = K_FOLD_CV_AUGMENTED_DIR / f'fold_{fold_idx}'\n",
    "        original_fold_dir = K_FOLD_CV_DIR / f'fold_{fold_idx}'\n",
    "        \n",
    "        if not augmented_fold_dir.exists():\n",
    "            print(f\"‚ö†Ô∏è  Augmented fold_{fold_idx} not found, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\nüìÅ Verifying fold_{fold_idx}...\")\n",
    "        \n",
    "        # Get final distribution\n",
    "        train_labels_dir = augmented_fold_dir / 'train/labels'\n",
    "        final_distribution = get_class_distribution(train_labels_dir, NUM_CLASSES)\n",
    "        \n",
    "        val_labels_dir = augmented_fold_dir / 'val/labels'\n",
    "        val_distribution = get_class_distribution(val_labels_dir, NUM_CLASSES)\n",
    "        \n",
    "        # Get original distribution for comparison\n",
    "        original_train_dist = {}\n",
    "        if original_fold_dir.exists():\n",
    "            original_train_labels_dir = original_fold_dir / 'train/labels'\n",
    "            original_train_dist = get_class_distribution(original_train_labels_dir, NUM_CLASSES)\n",
    "        \n",
    "        print(f\"  Final Train Set Distribution for fold_{fold_idx}:\")\n",
    "        if not final_distribution:\n",
    "            print(\"    No labels found.\")\n",
    "        else:\n",
    "            for i, class_name in enumerate(TARGET_CLASSES):\n",
    "                original_count = original_train_dist.get(i, 0)\n",
    "                final_count = final_distribution[i]\n",
    "                increase = final_count - original_count\n",
    "                print(f\"    - {class_name} (ID {i}): {final_count} instances (+{increase})\")\n",
    "        \n",
    "        print(f\"  Final Val Set Distribution for fold_{fold_idx}:\")\n",
    "        for i, class_name in enumerate(TARGET_CLASSES):\n",
    "            print(f\"    - {class_name} (ID {i}): {val_distribution[i]} instances\")\n",
    "        \n",
    "        # Store results for this fold\n",
    "        fold_results[fold_idx] = {\n",
    "            'original_train': original_train_dist,\n",
    "            'final_train': final_distribution,\n",
    "            'val': val_distribution\n",
    "        }\n",
    "    \n",
    "    # Plot comparison for all folds\n",
    "    if fold_results:\n",
    "        num_folds_found = len(fold_results)\n",
    "        fig, axes = plt.subplots(2, num_folds_found, figsize=(6*num_folds_found, 10))\n",
    "        if num_folds_found == 1:\n",
    "            axes = axes.reshape(-1, 1)\n",
    "        \n",
    "        for idx, (fold_idx, results) in enumerate(fold_results.items()):\n",
    "            # Before vs After comparison for train set\n",
    "            class_names = [f\"C{i}\" for i in range(NUM_CLASSES)]\n",
    "            original_counts = [results['original_train'].get(i, 0) for i in range(NUM_CLASSES)]\n",
    "            final_counts = [results['final_train'][i] for i in range(NUM_CLASSES)]\n",
    "            \n",
    "            x = np.arange(len(class_names))\n",
    "            width = 0.35\n",
    "            \n",
    "            axes[0, idx].bar(x - width/2, original_counts, width, label='Original', alpha=0.8)\n",
    "            axes[0, idx].bar(x + width/2, final_counts, width, label='Augmented', alpha=0.8)\n",
    "            axes[0, idx].set_xlabel('Classes')\n",
    "            axes[0, idx].set_ylabel('Instances')\n",
    "            axes[0, idx].set_title(f'Fold {fold_idx} - Before vs After Augmentation')\n",
    "            axes[0, idx].set_xticks(x)\n",
    "            axes[0, idx].set_xticklabels(class_names)\n",
    "            axes[0, idx].legend()\n",
    "            \n",
    "            # Final train distribution\n",
    "            final_df = pd.DataFrame.from_dict(results['final_train'], orient='index').sort_index()\n",
    "            final_df.plot(kind='bar', legend=False, ax=axes[1, idx], \n",
    "                         title=f'Fold {fold_idx} - Final Train Distribution')\n",
    "            axes[1, idx].set_xlabel('Class ID')\n",
    "            axes[1, idx].set_ylabel('Instances')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Overall summary statistics\n",
    "    print(f\"\\nüìà Overall Summary:\")\n",
    "    total_original_across_folds = 0\n",
    "    total_final_across_folds = 0\n",
    "    \n",
    "    for fold_idx, results in fold_results.items():\n",
    "        original_total = sum(results['original_train'].values())\n",
    "        final_total = sum(results['final_train'].values())\n",
    "        increase_total = final_total - original_total\n",
    "        increase_percent = (increase_total / original_total) * 100 if original_total > 0 else 0\n",
    "        \n",
    "        total_original_across_folds += original_total\n",
    "        total_final_across_folds += final_total\n",
    "        \n",
    "        print(f\"  Fold {fold_idx}:\")\n",
    "        print(f\"    - Original training instances: {original_total}\")\n",
    "        print(f\"    - Final training instances: {final_total}\")\n",
    "        print(f\"    - Increase: +{increase_total} (+{increase_percent:.1f}%)\")\n",
    "        \n",
    "        # Check balance for this fold\n",
    "        min_count = min(results['final_train'].values()) if results['final_train'] else 0\n",
    "        max_count = max(results['final_train'].values()) if results['final_train'] else 1\n",
    "        balance_ratio = min_count / max_count if max_count > 0 else 0\n",
    "        \n",
    "        print(f\"    - Balance ratio: {balance_ratio:.2f}\")\n",
    "        \n",
    "        if balance_ratio > 0.8:\n",
    "            print(f\"    - ‚úÖ Well balanced!\")\n",
    "        elif balance_ratio > 0.6:\n",
    "            print(f\"    - ‚ö†Ô∏è Moderate imbalance\")\n",
    "        else:\n",
    "            print(f\"    - ‚ùå Significant imbalance\")\n",
    "    \n",
    "    # Overall stats\n",
    "    if total_original_across_folds > 0:\n",
    "        overall_increase = total_final_across_folds - total_original_across_folds\n",
    "        overall_increase_percent = (overall_increase / total_original_across_folds) * 100\n",
    "        \n",
    "        print(f\"\\nüåü Across all folds:\")\n",
    "        print(f\"  - Total original instances: {total_original_across_folds}\")\n",
    "        print(f\"  - Total final instances: {total_final_across_folds}\")\n",
    "        print(f\"  - Total increase: +{overall_increase} (+{overall_increase_percent:.1f}%)\")\n",
    "        print(f\"  - Average instances per fold: {total_final_across_folds // len(fold_results)}\")\n",
    "    \n",
    "    return fold_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ef268d",
   "metadata": {},
   "source": [
    "## 7. Run Augmentation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8b29a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the complete k-fold augmentation pipeline\n",
    "if TARGET_CLASSES and NUM_CLASSES > 0:\n",
    "    print(\"üöÄ Starting K-Fold CV Dataset Augmentation Pipeline...\")\n",
    "    print(f\"Classes to process: {TARGET_CLASSES}\")\n",
    "    print(f\"Number of folds: {NUM_FOLDS}\")\n",
    "    \n",
    "    # Create the augmented k-fold CV dataset\n",
    "    augmented_dataset_path = create_augmented_kfold_dataset()\n",
    "    \n",
    "    if augmented_dataset_path:\n",
    "        print(f\"\\n‚úÖ Augmented k-fold CV dataset created at: {augmented_dataset_path}\")\n",
    "        \n",
    "        # Verify the results\n",
    "        final_results = verify_augmented_kfold_dataset()\n",
    "        \n",
    "        print(f\"\\nüéâ K-Fold CV augmentation pipeline completed successfully!\")\n",
    "        print(f\"Dataset available at: {K_FOLD_CV_AUGMENTED_DIR}\")\n",
    "        print(f\"Structure:\")\n",
    "        print(f\"  ‚îú‚îÄ‚îÄ fold_0/\")\n",
    "        print(f\"  ‚îÇ   ‚îú‚îÄ‚îÄ train/ (original + augmented + synthetic)\")\n",
    "        print(f\"  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ images/\")\n",
    "        print(f\"  ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ labels/\")\n",
    "        print(f\"  ‚îÇ   ‚îú‚îÄ‚îÄ val/ (copied from original)\")\n",
    "        print(f\"  ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ images/\")\n",
    "        print(f\"  ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ labels/\")\n",
    "        print(f\"  ‚îÇ   ‚îî‚îÄ‚îÄ data.yaml\")\n",
    "        print(f\"  ‚îú‚îÄ‚îÄ fold_1/ (same structure)\")\n",
    "        print(f\"  ‚îú‚îÄ‚îÄ fold_2/ (same structure)\")\n",
    "        print(f\"  ‚îú‚îÄ‚îÄ fold_3/ (same structure)\")\n",
    "        print(f\"  ‚îî‚îÄ‚îÄ fold_4/ (same structure)\")\n",
    "    else:\n",
    "        print(\"‚ùå Failed to create augmented k-fold CV dataset\")\n",
    "else:\n",
    "    print(\"‚ùå Cannot proceed: No target classes found or dataset not properly loaded.\")\n",
    "    print(\"Please check that the k-fold CV dataset exists and has valid data.yaml files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a52ef34",
   "metadata": {},
   "source": [
    "## 8. Optional: Quick Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a7b54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick statistics about the created k-fold CV dataset\n",
    "def show_kfold_dataset_statistics():\n",
    "    \"\"\"Show quick statistics about the augmented k-fold CV dataset.\"\"\"\n",
    "    if not K_FOLD_CV_AUGMENTED_DIR.exists():\n",
    "        print(\"Augmented k-fold CV dataset not found.\")\n",
    "        return\n",
    "    \n",
    "    print(\"üìä K-Fold CV Dataset Statistics:\")\n",
    "    \n",
    "    total_train_images = 0\n",
    "    total_train_labels = 0\n",
    "    total_val_images = 0\n",
    "    total_val_labels = 0\n",
    "    \n",
    "    fold_stats = {}\n",
    "    \n",
    "    for fold_idx in range(NUM_FOLDS):\n",
    "        augmented_fold_dir = K_FOLD_CV_AUGMENTED_DIR / f'fold_{fold_idx}'\n",
    "        if not augmented_fold_dir.exists():\n",
    "            continue\n",
    "            \n",
    "        train_img_dir = augmented_fold_dir / 'train/images'\n",
    "        train_label_dir = augmented_fold_dir / 'train/labels'\n",
    "        val_img_dir = augmented_fold_dir / 'val/images'\n",
    "        val_label_dir = augmented_fold_dir / 'val/labels'\n",
    "        \n",
    "        # Count files for this fold\n",
    "        fold_train_images = len(list(train_img_dir.glob('*'))) if train_img_dir.exists() else 0\n",
    "        fold_train_labels = len(list(train_label_dir.glob('*'))) if train_label_dir.exists() else 0\n",
    "        fold_val_images = len(list(val_img_dir.glob('*'))) if val_img_dir.exists() else 0\n",
    "        fold_val_labels = len(list(val_label_dir.glob('*'))) if val_label_dir.exists() else 0\n",
    "        \n",
    "        total_train_images += fold_train_images\n",
    "        total_train_labels += fold_train_labels\n",
    "        total_val_images += fold_val_images\n",
    "        total_val_labels += fold_val_labels\n",
    "        \n",
    "        print(f\"  Fold {fold_idx}:\")\n",
    "        print(f\"    Training set: {fold_train_images} images, {fold_train_labels} labels\")\n",
    "        print(f\"    Validation set: {fold_val_images} images, {fold_val_labels} labels\")\n",
    "        print(f\"    Fold total: {fold_train_images + fold_val_images} images\")\n",
    "        \n",
    "        # Count different types of training images for this fold\n",
    "        if train_img_dir.exists():\n",
    "            # Count original images (no special prefix/suffix)\n",
    "            original_count = len([f for f in train_img_dir.glob('*') \n",
    "                                if not any(keyword in f.stem for keyword in ['_aug_', f'fold{fold_idx}_aug_synthetic', f'fold{fold_idx}_pure_synthetic'])])\n",
    "            \n",
    "            # Count traditional augmentations (contain '_aug_' but not fold prefixes for synthetic)\n",
    "            traditional_aug_count = len([f for f in train_img_dir.glob('*') \n",
    "                                       if '_aug_' in f.stem and not f.stem.startswith(f'fold{fold_idx}_aug_synthetic') and not f.stem.startswith(f'fold{fold_idx}_pure_synthetic')])\n",
    "            \n",
    "            # Count augmented synthetic (start with 'fold{fold_idx}_aug_synthetic')\n",
    "            aug_synthetic_count = len([f for f in train_img_dir.glob('*') if f.stem.startswith(f'fold{fold_idx}_aug_synthetic')])\n",
    "            \n",
    "            # Count pure synthetic (start with 'fold{fold_idx}_pure_synthetic')\n",
    "            pure_synthetic_count = len([f for f in train_img_dir.glob('*') if f.stem.startswith(f'fold{fold_idx}_pure_synthetic')])\n",
    "            \n",
    "            total_synthetic = aug_synthetic_count + pure_synthetic_count\n",
    "            \n",
    "            print(f\"    üìà Training set breakdown:\")\n",
    "            print(f\"      Original images: {original_count}\")\n",
    "            print(f\"      Traditional augmentations: {traditional_aug_count}\")\n",
    "            print(f\"      Synthetic images total: {total_synthetic}\")\n",
    "            print(f\"        ‚îú‚îÄ‚îÄ Augmented synthetic: {aug_synthetic_count}\")\n",
    "            print(f\"        ‚îî‚îÄ‚îÄ Pure synthetic: {pure_synthetic_count}\")\n",
    "            \n",
    "            # Show percentages for this fold\n",
    "            if fold_train_images > 0:\n",
    "                print(f\"      üìä Distribution percentages:\")\n",
    "                print(f\"        Original: {(original_count/fold_train_images)*100:.1f}%\")\n",
    "                print(f\"        Traditional augmentations: {(traditional_aug_count/fold_train_images)*100:.1f}%\")\n",
    "                print(f\"        Synthetic: {(total_synthetic/fold_train_images)*100:.1f}%\")\n",
    "                \n",
    "                if total_synthetic > 0:\n",
    "                    aug_ratio = aug_synthetic_count / total_synthetic\n",
    "                    pure_ratio = pure_synthetic_count / total_synthetic\n",
    "                    print(f\"      üé® Synthetic data distribution:\")\n",
    "                    print(f\"        Augmented synthetic: {aug_ratio:.1%} (target: {AUGMENTED_SYNTHETIC_RATIO:.1%})\")\n",
    "                    print(f\"        Pure synthetic: {pure_ratio:.1%} (target: {PURE_SYNTHETIC_RATIO:.1%})\")\n",
    "            \n",
    "            fold_stats[fold_idx] = {\n",
    "                'train_images': fold_train_images,\n",
    "                'val_images': fold_val_images,\n",
    "                'original': original_count,\n",
    "                'traditional_aug': traditional_aug_count,\n",
    "                'aug_synthetic': aug_synthetic_count,\n",
    "                'pure_synthetic': pure_synthetic_count\n",
    "            }\n",
    "    \n",
    "    print(f\"\\nüåü Overall Statistics:\")\n",
    "    print(f\"  Total across all folds:\")\n",
    "    print(f\"    Training images: {total_train_images}\")\n",
    "    print(f\"    Training labels: {total_train_labels}\")\n",
    "    print(f\"    Validation images: {total_val_images}\")\n",
    "    print(f\"    Validation labels: {total_val_labels}\")\n",
    "    print(f\"    Grand total images: {total_train_images + total_val_images}\")\n",
    "    \n",
    "    if fold_stats:\n",
    "        # Aggregate statistics\n",
    "        total_original = sum(stats['original'] for stats in fold_stats.values())\n",
    "        total_traditional_aug = sum(stats['traditional_aug'] for stats in fold_stats.values())\n",
    "        total_aug_synthetic = sum(stats['aug_synthetic'] for stats in fold_stats.values())\n",
    "        total_pure_synthetic = sum(stats['pure_synthetic'] for stats in fold_stats.values())\n",
    "        total_all_synthetic = total_aug_synthetic + total_pure_synthetic\n",
    "        \n",
    "        print(f\"\\n  üìà Aggregate breakdown:\")\n",
    "        print(f\"    Total original images: {total_original}\")\n",
    "        print(f\"    Total traditional augmentations: {total_traditional_aug}\")\n",
    "        print(f\"    Total synthetic images: {total_all_synthetic}\")\n",
    "        print(f\"      ‚îú‚îÄ‚îÄ Augmented synthetic: {total_aug_synthetic}\")\n",
    "        print(f\"      ‚îî‚îÄ‚îÄ Pure synthetic: {total_pure_synthetic}\")\n",
    "        \n",
    "        # Overall percentages\n",
    "        if total_train_images > 0:\n",
    "            print(f\"\\n  üìä Overall distribution percentages:\")\n",
    "            print(f\"    Original: {(total_original/total_train_images)*100:.1f}%\")\n",
    "            print(f\"    Traditional augmentations: {(total_traditional_aug/total_train_images)*100:.1f}%\")\n",
    "            print(f\"    Synthetic: {(total_all_synthetic/total_train_images)*100:.1f}%\")\n",
    "            \n",
    "            if total_all_synthetic > 0:\n",
    "                overall_aug_ratio = total_aug_synthetic / total_all_synthetic\n",
    "                overall_pure_ratio = total_pure_synthetic / total_all_synthetic\n",
    "                print(f\"\\n  üé® Overall synthetic data distribution:\")\n",
    "                print(f\"    Augmented synthetic: {overall_aug_ratio:.1%} (target: {AUGMENTED_SYNTHETIC_RATIO:.1%})\")\n",
    "                print(f\"    Pure synthetic: {overall_pure_ratio:.1%} (target: {PURE_SYNTHETIC_RATIO:.1%})\")\n",
    "                \n",
    "                # Show if we're close to target distribution\n",
    "                aug_diff = abs(overall_aug_ratio - AUGMENTED_SYNTHETIC_RATIO)\n",
    "                if aug_diff < 0.1:  # Within 10%\n",
    "                    print(f\"    ‚úÖ Overall synthetic distribution matches target well!\")\n",
    "                else:\n",
    "                    print(f\"    ‚ö†Ô∏è  Overall synthetic distribution differs from target by {aug_diff:.1%}\")\n",
    "\n",
    "# Show statistics\n",
    "show_kfold_dataset_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d281b42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_with_bboxes(image_path, label_path, title, ax):\n",
    "    \"\"\"Show an image with bounding boxes from a YOLO label file on a given axis.\"\"\"\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    if label_path.exists():\n",
    "        with open(label_path, 'r') as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    parts = line.split()\n",
    "                    class_id = int(float(parts[0]))\n",
    "                    cx, cy, w, h = map(float, parts[1:])\n",
    "                    img_width, img_height = img.size\n",
    "                    x1 = int((cx - w / 2) * img_width)\n",
    "                    y1 = int((cy - h / 2) * img_height)\n",
    "                    x2 = int((cx + w / 2) * img_width)\n",
    "                    y2 = int((cy + h / 2) * img_height)\n",
    "                    draw.rectangle([x1, y1, x2, y2], outline='red', width=2)\n",
    "                    draw.text((x1, y1), str(class_id), fill='white')\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off')\n",
    "\n",
    "def show_example_images_kfold():\n",
    "    \"\"\"Show example images with bounding boxes from the k-fold CV dataset.\"\"\"\n",
    "    if not K_FOLD_CV_AUGMENTED_DIR.exists():\n",
    "        print(\"Augmented k-fold CV dataset not found.\")\n",
    "        return\n",
    "    \n",
    "    # Find examples from the first available fold\n",
    "    examples_found = []\n",
    "    \n",
    "    for fold_idx in range(NUM_FOLDS):\n",
    "        fold_dir = K_FOLD_CV_AUGMENTED_DIR / f'fold_{fold_idx}'\n",
    "        if not fold_dir.exists():\n",
    "            continue\n",
    "            \n",
    "        train_img_dir = fold_dir / 'train/images'\n",
    "        train_label_dir = fold_dir / 'train/labels'\n",
    "        \n",
    "        if not train_img_dir.exists():\n",
    "            continue\n",
    "        \n",
    "        # Look for different types of examples\n",
    "        traditional_example = next(train_img_dir.glob('*_aug_*.jpg'), None)\n",
    "        if traditional_example and not traditional_example.stem.startswith(f'fold{fold_idx}_'):\n",
    "            examples_found.append((traditional_example, f\"Traditional Augmentation Example (Fold {fold_idx})\"))\n",
    "        \n",
    "        aug_synthetic_example = next(train_img_dir.glob(f'fold{fold_idx}_aug_synthetic_*.jpg'), None)\n",
    "        if aug_synthetic_example:\n",
    "            examples_found.append((aug_synthetic_example, f\"Augmented Synthetic Example (Fold {fold_idx})\"))\n",
    "        \n",
    "        pure_synthetic_example = next(train_img_dir.glob(f'fold{fold_idx}_pure_synthetic_*.jpg'), None)\n",
    "        if pure_synthetic_example:\n",
    "            examples_found.append((pure_synthetic_example, f\"Pure Synthetic Example (Fold {fold_idx})\"))\n",
    "        \n",
    "        # If we found examples from this fold, break (we only need one set)\n",
    "        if len(examples_found) >= 3:\n",
    "            break\n",
    "    \n",
    "    # Ensure we have exactly 3 examples (pad with None if needed)\n",
    "    while len(examples_found) < 3:\n",
    "        examples_found.append((None, \"No example found\"))\n",
    "    examples_found = examples_found[:3]  # Take only first 3\n",
    "    \n",
    "    # Create the plot\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    found = False\n",
    "    \n",
    "    for i, (img_path, title) in enumerate(examples_found):\n",
    "        if img_path and img_path.exists():\n",
    "            # Find corresponding label file\n",
    "            fold_idx = None\n",
    "            # Extract fold index from title\n",
    "            for fid in range(NUM_FOLDS):\n",
    "                if f'Fold {fid}' in title:\n",
    "                    fold_idx = fid\n",
    "                    break\n",
    "            \n",
    "            if fold_idx is not None:\n",
    "                fold_dir = K_FOLD_CV_AUGMENTED_DIR / f'fold_{fold_idx}'\n",
    "                train_label_dir = fold_dir / 'train/labels'\n",
    "                label_file = train_label_dir / f\"{img_path.stem}.txt\"\n",
    "            else:\n",
    "                # Fallback: try to find label file in any fold\n",
    "                label_file = None\n",
    "                for fid in range(NUM_FOLDS):\n",
    "                    fold_dir = K_FOLD_CV_AUGMENTED_DIR / f'fold_{fid}'\n",
    "                    potential_label = fold_dir / 'train/labels' / f\"{img_path.stem}.txt\"\n",
    "                    if potential_label.exists():\n",
    "                        label_file = potential_label\n",
    "                        break\n",
    "                if label_file is None:\n",
    "                    label_file = img_path.parent.parent / 'labels' / f\"{img_path.stem}.txt\"\n",
    "            \n",
    "            show_image_with_bboxes(img_path, label_file, title, axes[i])\n",
    "            found = True\n",
    "        else:\n",
    "            axes[i].axis('off')\n",
    "            axes[i].set_title(title)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    if not found:\n",
    "        print(\"No example images found in the augmented k-fold CV dataset.\")\n",
    "    else:\n",
    "        print(\"Example images shown above represent the different types of data generation applied to the k-fold CV dataset.\")\n",
    "\n",
    "show_example_images_kfold()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
