{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a139d10",
   "metadata": {},
   "source": [
    "# K-Fold CV Dataset Subsampling\n",
    "\n",
    "Stratified random subsampling of the **k_fold_cv_augmented** dataset to create a smaller **k_fold_cv_subsampled** dataset. It processes each fold independently, sampling from each fold's training set while preserving the original class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d963fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import defaultdict, Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(17)\n",
    "np.random.seed(17)\n",
    "\n",
    "# Set up visualization\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# K-Fold CV dataset paths\n",
    "SOURCE_DIR = Path(\"datasets/k_fold_cv_augmented\")\n",
    "TARGET_DIR = Path(\"datasets/k_fold_cv_subsampled\")\n",
    "NUM_FOLDS = 5\n",
    "TARGET_TRAIN_SIZE_PER_FOLD = 10000\n",
    "\n",
    "# Waste classes\n",
    "CLASS_NAMES = ['glass', 'metal', 'organic', 'paper', 'plastic']\n",
    "COLORS = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7']\n",
    "\n",
    "print(\"ðŸš€ K-Fold CV Dataset Subsampling Setup Complete\")\n",
    "print(f\"ðŸ“ Source: {SOURCE_DIR}\")\n",
    "print(f\"ðŸ“ Target: {TARGET_DIR}\")\n",
    "print(f\"ðŸ”¢ Number of folds: {NUM_FOLDS}\")\n",
    "print(f\"ðŸŽ¯ Target train size per fold: {TARGET_TRAIN_SIZE_PER_FOLD:,} images\")\n",
    "print(f\"ðŸŽ¯ Total target train size: {TARGET_TRAIN_SIZE_PER_FOLD * NUM_FOLDS:,} images\")\n",
    "print(f\"ðŸ“Š Classes: {CLASS_NAMES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fa8cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_kfold_dataset(dataset_dir):\n",
    "    \"\"\"\n",
    "    Analyze the k-fold CV dataset to understand class distribution across all folds\n",
    "    \"\"\"\n",
    "    print(\"ðŸ” ANALYZING K-FOLD CV DATASET\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if not dataset_dir.exists():\n",
    "        raise FileNotFoundError(f\"Source directory not found: {dataset_dir}\")\n",
    "    \n",
    "    fold_stats = {}\n",
    "    total_stats = {\n",
    "        'class_counts': Counter(),\n",
    "        'file_to_classes': {},\n",
    "        'valid_images': [],\n",
    "        'total_annotations': 0,\n",
    "        'total_images': 0\n",
    "    }\n",
    "    \n",
    "    for fold_idx in range(NUM_FOLDS):\n",
    "        fold_dir = dataset_dir / f\"fold_{fold_idx}\"\n",
    "        print(f\"\\nðŸ“ Analyzing fold_{fold_idx}...\")\n",
    "        \n",
    "        if not fold_dir.exists():\n",
    "            print(f\"âš ï¸  Fold_{fold_idx} not found, skipping...\")\n",
    "            continue\n",
    "        \n",
    "        train_dir = fold_dir / \"train\"\n",
    "        labels_dir = train_dir / \"labels\"\n",
    "        images_dir = train_dir / \"images\"\n",
    "        \n",
    "        if not labels_dir.exists() or not images_dir.exists():\n",
    "            print(f\"âŒ Train directories not found for fold_{fold_idx}\")\n",
    "            continue\n",
    "        \n",
    "        # Count class occurrences for this fold\n",
    "        fold_class_counts = Counter()\n",
    "        fold_file_to_classes = {}\n",
    "        \n",
    "        # Get all label files\n",
    "        label_files = list(labels_dir.glob(\"*.txt\"))\n",
    "        print(f\"  ðŸ“„ Found {len(label_files)} label files\")\n",
    "        \n",
    "        # Analyze each label file\n",
    "        for label_file in label_files:\n",
    "            classes_in_file = set()\n",
    "            \n",
    "            if label_file.stat().st_size == 0:\n",
    "                continue  # Skip empty files\n",
    "                \n",
    "            try:\n",
    "                with open(label_file, 'r') as f:\n",
    "                    for line in f:\n",
    "                        line = line.strip()\n",
    "                        if line:\n",
    "                            parts = line.split()\n",
    "                            if len(parts) >= 5:\n",
    "                                class_id = int(parts[0])\n",
    "                                if 0 <= class_id < len(CLASS_NAMES):\n",
    "                                    class_name = CLASS_NAMES[class_id]\n",
    "                                    fold_class_counts[class_name] += 1\n",
    "                                    classes_in_file.add(class_name)\n",
    "            except Exception as e:\n",
    "                print(f\"    âŒ Error reading {label_file}: {e}\")\n",
    "                continue\n",
    "            \n",
    "            fold_file_to_classes[label_file.stem] = classes_in_file\n",
    "        \n",
    "        # Get available images for this fold\n",
    "        image_files = list(images_dir.glob(\"*\"))\n",
    "        fold_valid_images = []\n",
    "        \n",
    "        for img_file in image_files:\n",
    "            if img_file.stem in fold_file_to_classes:\n",
    "                fold_valid_images.append(img_file.stem)\n",
    "        \n",
    "        fold_total_annotations = sum(fold_class_counts.values())\n",
    "        \n",
    "        print(f\"  ðŸ–¼ï¸ Total images: {len(image_files)}\")\n",
    "        print(f\"  âœ… Valid image-label pairs: {len(fold_valid_images)}\")\n",
    "        print(f\"  ðŸ“Š Total annotations: {fold_total_annotations}\")\n",
    "        \n",
    "        print(f\"  ðŸ“ˆ Class Distribution for fold_{fold_idx}:\")\n",
    "        for class_name in CLASS_NAMES:\n",
    "            count = fold_class_counts.get(class_name, 0)\n",
    "            percentage = (count / fold_total_annotations * 100) if fold_total_annotations > 0 else 0\n",
    "            print(f\"     {class_name:8}: {count:5,} annotations ({percentage:5.1f}%)\")\n",
    "        \n",
    "        # Store fold statistics\n",
    "        fold_stats[fold_idx] = {\n",
    "            'class_counts': fold_class_counts,\n",
    "            'file_to_classes': fold_file_to_classes,\n",
    "            'valid_images': fold_valid_images,\n",
    "            'total_annotations': fold_total_annotations,\n",
    "            'total_images': len(fold_valid_images),\n",
    "            'fold_dir': fold_dir\n",
    "        }\n",
    "        \n",
    "        # Update total statistics\n",
    "        total_stats['class_counts'].update(fold_class_counts)\n",
    "        total_stats['file_to_classes'].update({f\"fold_{fold_idx}_{k}\": v for k, v in fold_file_to_classes.items()})\n",
    "        total_stats['valid_images'].extend([f\"fold_{fold_idx}_{img}\" for img in fold_valid_images])\n",
    "        total_stats['total_annotations'] += fold_total_annotations\n",
    "        total_stats['total_images'] += len(fold_valid_images)\n",
    "    \n",
    "    print(f\"\\nðŸŒŸ OVERALL STATISTICS ACROSS ALL FOLDS:\")\n",
    "    print(f\"  ðŸ“Š Total annotations: {total_stats['total_annotations']:,}\")\n",
    "    print(f\"  ðŸ–¼ï¸ Total valid images: {total_stats['total_images']:,}\")\n",
    "    print(f\"  ðŸ“ˆ Overall class distribution:\")\n",
    "    \n",
    "    for class_name in CLASS_NAMES:\n",
    "        count = total_stats['class_counts'].get(class_name, 0)\n",
    "        percentage = (count / total_stats['total_annotations'] * 100) if total_stats['total_annotations'] > 0 else 0\n",
    "        print(f\"     {class_name:8}: {count:5,} annotations ({percentage:5.1f}%)\")\n",
    "    \n",
    "    return fold_stats, total_stats\n",
    "\n",
    "# Analyze the k-fold CV dataset\n",
    "fold_stats, total_stats = analyze_kfold_dataset(SOURCE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a586e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_stratified_sampling_per_fold(fold_stats, target_size_per_fold):\n",
    "    \"\"\"\n",
    "    Perform stratified sampling for each fold independently\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸŽ² PERFORMING STRATIFIED SAMPLING FOR EACH FOLD\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    fold_sampling_stats = {}\n",
    "    \n",
    "    for fold_idx, stats in fold_stats.items():\n",
    "        print(f\"\\nðŸ”„ Processing fold_{fold_idx}...\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        class_counts = stats['class_counts']\n",
    "        file_to_classes = stats['file_to_classes']\n",
    "        valid_images = stats['valid_images']\n",
    "        total_annotations = stats['total_annotations']\n",
    "        \n",
    "        if total_annotations == 0:\n",
    "            print(f\"âš ï¸  Skipping fold_{fold_idx}: No annotations found\")\n",
    "            continue\n",
    "        \n",
    "        # Calculate proportional targets for each class in this fold\n",
    "        target_class_counts = {}\n",
    "        print(\"ðŸŽ¯ Target class distribution:\")\n",
    "        for class_name in CLASS_NAMES:\n",
    "            original_count = class_counts.get(class_name, 0)\n",
    "            proportion = original_count / total_annotations if total_annotations > 0 else 0\n",
    "            target_count = int(target_size_per_fold * proportion)\n",
    "            target_class_counts[class_name] = target_count\n",
    "            print(f\"   {class_name:8}: {target_count:4,} images ({proportion*100:5.1f}%)\")\n",
    "        \n",
    "        # Group images by the classes they contain\n",
    "        class_to_images = defaultdict(list)\n",
    "        for image_name, classes_in_image in file_to_classes.items():\n",
    "            for class_name in classes_in_image:\n",
    "                class_to_images[class_name].append(image_name)\n",
    "        \n",
    "        print(f\"\\nðŸ“Š Images per class in fold_{fold_idx}:\")\n",
    "        for class_name in CLASS_NAMES:\n",
    "            count = len(class_to_images[class_name])\n",
    "            print(f\"   {class_name:8}: {count:4,} images\")\n",
    "        \n",
    "        # Strategy: Sample images to approximately match target class distribution\n",
    "        selected_images = set()\n",
    "        current_class_counts = Counter()\n",
    "        \n",
    "        # Create a list of all images with their class sets for this fold\n",
    "        image_class_data = [(img, classes) for img, classes in file_to_classes.items()]\n",
    "        random.shuffle(image_class_data)\n",
    "        \n",
    "        # Priority-based selection to balance classes\n",
    "        max_iterations = len(image_class_data) * 2  # Prevent infinite loops\n",
    "        iteration = 0\n",
    "        \n",
    "        while len(selected_images) < target_size_per_fold and iteration < max_iterations:\n",
    "            iteration += 1\n",
    "            \n",
    "            # Find the class that is most under-represented\n",
    "            class_deficits = {}\n",
    "            for class_name in CLASS_NAMES:\n",
    "                target = target_class_counts[class_name]\n",
    "                current = current_class_counts[class_name]\n",
    "                if target > 0:\n",
    "                    deficit_ratio = (target - current) / target\n",
    "                    class_deficits[class_name] = deficit_ratio\n",
    "                else:\n",
    "                    class_deficits[class_name] = 0\n",
    "            \n",
    "            # Sort classes by deficit (most needed first)\n",
    "            most_needed_class = max(class_deficits, key=class_deficits.get)\n",
    "            \n",
    "            # Find unselected images that contain the most needed class\n",
    "            candidates = [\n",
    "                (img, classes) for img, classes in image_class_data \n",
    "                if img not in selected_images and most_needed_class in classes\n",
    "            ]\n",
    "            \n",
    "            if not candidates:\n",
    "                # If no candidates for the most needed class, pick any remaining image\n",
    "                candidates = [\n",
    "                    (img, classes) for img, classes in image_class_data \n",
    "                    if img not in selected_images\n",
    "                ]\n",
    "            \n",
    "            if not candidates:\n",
    "                break  # No more images to select\n",
    "            \n",
    "            # Select the best candidate (prefer images with classes that are under-represented)\n",
    "            best_img, best_classes = None, None\n",
    "            best_score = -float('inf')\n",
    "            \n",
    "            for img, classes in candidates[:100]:  # Limit search for efficiency\n",
    "                score = sum(class_deficits.get(c, 0) for c in classes)\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_img, best_classes = img, classes\n",
    "            \n",
    "            if best_img:\n",
    "                selected_images.add(best_img)\n",
    "                for class_name in best_classes:\n",
    "                    current_class_counts[class_name] += 1\n",
    "        \n",
    "        print(f\"\\nâœ… Selected {len(selected_images)} images for fold_{fold_idx}\")\n",
    "        print(\"ðŸ“Š Achieved class distribution:\")\n",
    "        \n",
    "        sampling_ratio = len(selected_images) / len(valid_images) if len(valid_images) > 0 else 0\n",
    "        \n",
    "        fold_sampling_stats[fold_idx] = {\n",
    "            'selected_images': selected_images,\n",
    "            'target_class_counts': target_class_counts,\n",
    "            'achieved_class_counts': current_class_counts,\n",
    "            'sampling_ratio': sampling_ratio,\n",
    "            'fold_dir': stats['fold_dir']\n",
    "        }\n",
    "        \n",
    "        for class_name in CLASS_NAMES:\n",
    "            target = target_class_counts[class_name]\n",
    "            achieved = current_class_counts[class_name]\n",
    "            ratio = achieved / target if target > 0 else 0\n",
    "            print(f\"   {class_name:8}: {achieved:4,} / {target:4,} ({ratio:5.1%})\")\n",
    "    \n",
    "    # Overall summary\n",
    "    total_selected = sum(len(stats['selected_images']) for stats in fold_sampling_stats.values())\n",
    "    print(f\"\\nðŸŒŸ OVERALL SAMPLING SUMMARY:\")\n",
    "    print(f\"  Total images selected across all folds: {total_selected:,}\")\n",
    "    print(f\"  Average images per fold: {total_selected/len(fold_sampling_stats):.0f}\")\n",
    "    \n",
    "    return fold_sampling_stats\n",
    "\n",
    "# Perform the stratified sampling for each fold\n",
    "fold_sampling_stats = perform_stratified_sampling_per_fold(fold_stats, TARGET_TRAIN_SIZE_PER_FOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce804113",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_subsampled_kfold_dataset(source_dir, target_dir, fold_sampling_stats):\n",
    "    \"\"\"\n",
    "    Create the subsampled k-fold CV dataset by copying selected files from each fold\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸ“ CREATING SUBSAMPLED K-FOLD CV DATASET\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Create target directory structure\n",
    "    target_dir.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"ðŸ“ Created main directory at {target_dir}\")\n",
    "    \n",
    "    total_copied_images = 0\n",
    "    total_copied_labels = 0\n",
    "    \n",
    "    for fold_idx, stats in fold_sampling_stats.items():\n",
    "        print(f\"\\nðŸ”„ Processing fold_{fold_idx}...\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        # Create fold directory structure\n",
    "        fold_target_dir = target_dir / f\"fold_{fold_idx}\"\n",
    "        for split in ['train', 'val']:\n",
    "            for subdir in ['images', 'labels']:\n",
    "                (fold_target_dir / split / subdir).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        print(f\"  ðŸ“ Created directory structure for fold_{fold_idx}\")\n",
    "        \n",
    "        # Copy subsampled training set\n",
    "        selected_images = stats['selected_images']\n",
    "        fold_source_dir = stats['fold_dir']\n",
    "        \n",
    "        source_train_images = fold_source_dir / \"train\" / \"images\"\n",
    "        source_train_labels = fold_source_dir / \"train\" / \"labels\"\n",
    "        target_train_images = fold_target_dir / \"train\" / \"images\"\n",
    "        target_train_labels = fold_target_dir / \"train\" / \"labels\"\n",
    "        \n",
    "        print(f\"  ðŸ“¤ Copying training set ({len(selected_images)} images)...\")\n",
    "        \n",
    "        fold_copied_images = 0\n",
    "        fold_copied_labels = 0\n",
    "        \n",
    "        for img_name in tqdm(selected_images, desc=f\"Copying fold_{fold_idx} train files\"):\n",
    "            # Find the actual image file (could have different extensions)\n",
    "            img_files = list(source_train_images.glob(f\"{img_name}.*\"))\n",
    "            if img_files:\n",
    "                source_img = img_files[0]\n",
    "                target_img = target_train_images / source_img.name\n",
    "                shutil.copy2(source_img, target_img)\n",
    "                fold_copied_images += 1\n",
    "            \n",
    "            # Copy corresponding label file\n",
    "            source_label = source_train_labels / f\"{img_name}.txt\"\n",
    "            if source_label.exists():\n",
    "                target_label = target_train_labels / f\"{img_name}.txt\"\n",
    "                shutil.copy2(source_label, target_label)\n",
    "                fold_copied_labels += 1\n",
    "        \n",
    "        print(f\"  âœ… Copied {fold_copied_images} training images\")\n",
    "        print(f\"  âœ… Copied {fold_copied_labels} training labels\")\n",
    "        \n",
    "        total_copied_images += fold_copied_images\n",
    "        total_copied_labels += fold_copied_labels\n",
    "        \n",
    "        # Copy validation set (unchanged)\n",
    "        print(f\"  ðŸ“¤ Copying validation set (unchanged)...\")\n",
    "        \n",
    "        source_val = fold_source_dir / \"val\"\n",
    "        target_val = fold_target_dir / \"val\"\n",
    "        \n",
    "        if source_val.exists():\n",
    "            # Copy all validation images\n",
    "            source_val_images = source_val / \"images\"\n",
    "            source_val_labels = source_val / \"labels\"\n",
    "            \n",
    "            val_img_count = 0\n",
    "            val_label_count = 0\n",
    "            \n",
    "            if source_val_images.exists():\n",
    "                val_img_files = list(source_val_images.glob(\"*\"))\n",
    "                for img_file in val_img_files:\n",
    "                    shutil.copy2(img_file, target_val / \"images\" / img_file.name)\n",
    "                val_img_count = len(val_img_files)\n",
    "            \n",
    "            if source_val_labels.exists():\n",
    "                val_label_files = list(source_val_labels.glob(\"*.txt\"))\n",
    "                for label_file in val_label_files:\n",
    "                    shutil.copy2(label_file, target_val / \"labels\" / label_file.name)\n",
    "                val_label_count = len(val_label_files)\n",
    "            \n",
    "            print(f\"  âœ… Copied {val_img_count} validation images\")\n",
    "            print(f\"  âœ… Copied {val_label_count} validation labels\")\n",
    "        \n",
    "        # Copy and update data.yaml for this fold\n",
    "        source_yaml = fold_source_dir / \"data.yaml\"\n",
    "        target_yaml = fold_target_dir / \"data.yaml\"\n",
    "        \n",
    "        if source_yaml.exists():\n",
    "            with open(source_yaml, 'r') as f:\n",
    "                data_config = yaml.safe_load(f)\n",
    "            \n",
    "            # Update paths to be relative to fold directory\n",
    "            data_config['train'] = 'train/images'\n",
    "            data_config['val'] = 'val/images'\n",
    "            \n",
    "            # Add metadata\n",
    "            data_config['# Subsampling Info'] = {\n",
    "                'original_dataset': str(fold_source_dir),\n",
    "                'target_train_size': len(selected_images),\n",
    "                'sampling_date': '2025-07-20',\n",
    "                'sampling_seed': 42,\n",
    "                'fold_index': fold_idx\n",
    "            }\n",
    "            \n",
    "            with open(target_yaml, 'w') as f:\n",
    "                yaml.dump(data_config, f, default_flow_style=False)\n",
    "            \n",
    "            print(f\"  âœ… Created data.yaml for fold_{fold_idx}\")\n",
    "    \n",
    "    print(f\"\\nðŸŽ‰ K-Fold CV dataset subsampling complete!\")\n",
    "    print(f\"ðŸ“ New dataset location: {target_dir}\")\n",
    "    print(f\"ðŸ–¼ï¸ Total training images copied: {total_copied_images:,}\")\n",
    "    print(f\"ðŸ“„ Total training labels copied: {total_copied_labels:,}\")\n",
    "    print(f\"ðŸ“Š Average images per fold: {total_copied_images/len(fold_sampling_stats):.0f}\")\n",
    "\n",
    "# Create the subsampled k-fold CV dataset\n",
    "create_subsampled_kfold_dataset(SOURCE_DIR, TARGET_DIR, fold_sampling_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f166c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_subsampled_kfold_dataset(target_dir):\n",
    "    \"\"\"\n",
    "    Validate the created subsampled k-fold CV dataset\n",
    "    \"\"\"\n",
    "    print(f\"\\nâœ… VALIDATING SUBSAMPLED K-FOLD CV DATASET\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    fold_validation_stats = {}\n",
    "    total_validation_stats = Counter()\n",
    "    \n",
    "    for fold_idx in range(NUM_FOLDS):\n",
    "        fold_dir = target_dir / f\"fold_{fold_idx}\"\n",
    "        print(f\"\\nðŸ“ Validating fold_{fold_idx}...\")\n",
    "        \n",
    "        if not fold_dir.exists():\n",
    "            print(f\"âŒ fold_{fold_idx} directory not found!\")\n",
    "            continue\n",
    "        \n",
    "        # Check directory structure\n",
    "        required_dirs = [\n",
    "            fold_dir / \"train\" / \"images\",\n",
    "            fold_dir / \"train\" / \"labels\", \n",
    "            fold_dir / \"val\" / \"images\",\n",
    "            fold_dir / \"val\" / \"labels\"\n",
    "        ]\n",
    "        \n",
    "        for dir_path in required_dirs:\n",
    "            if dir_path.exists():\n",
    "                file_count = len(list(dir_path.glob(\"*\")))\n",
    "                relative_path = dir_path.relative_to(fold_dir)\n",
    "                print(f\"  âœ… {relative_path}: {file_count} files\")\n",
    "            else:\n",
    "                relative_path = dir_path.relative_to(fold_dir)\n",
    "                print(f\"  âŒ {relative_path}: Missing!\")\n",
    "        \n",
    "        # Analyze new train set for this fold\n",
    "        train_labels_dir = fold_dir / \"train\" / \"labels\"\n",
    "        fold_class_counts = Counter()\n",
    "        \n",
    "        if train_labels_dir.exists():\n",
    "            label_files = list(train_labels_dir.glob(\"*.txt\"))\n",
    "            \n",
    "            for label_file in label_files:\n",
    "                if label_file.stat().st_size == 0:\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    with open(label_file, 'r') as f:\n",
    "                        for line in f:\n",
    "                            line = line.strip()\n",
    "                            if line:\n",
    "                                parts = line.split()\n",
    "                                if len(parts) >= 5:\n",
    "                                    class_id = int(parts[0])\n",
    "                                    if 0 <= class_id < len(CLASS_NAMES):\n",
    "                                        class_name = CLASS_NAMES[class_id]\n",
    "                                        fold_class_counts[class_name] += 1\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "            \n",
    "            print(f\"  ðŸ“Š Training set class distribution for fold_{fold_idx}:\")\n",
    "            fold_total = sum(fold_class_counts.values())\n",
    "            for class_name in CLASS_NAMES:\n",
    "                count = fold_class_counts.get(class_name, 0)\n",
    "                percentage = (count / fold_total * 100) if fold_total > 0 else 0\n",
    "                print(f\"     {class_name:8}: {count:5,} annotations ({percentage:5.1f}%)\")\n",
    "        \n",
    "        fold_validation_stats[fold_idx] = fold_class_counts\n",
    "        total_validation_stats.update(fold_class_counts)\n",
    "    \n",
    "    # Overall validation summary\n",
    "    print(f\"\\nðŸŒŸ OVERALL VALIDATION SUMMARY:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    overall_total = sum(total_validation_stats.values())\n",
    "    print(f\"ðŸ“Š Total annotations across all folds: {overall_total:,}\")\n",
    "    \n",
    "    if overall_total > 0:\n",
    "        print(f\"ðŸ“ˆ Overall class distribution:\")\n",
    "        for class_name in CLASS_NAMES:\n",
    "            count = total_validation_stats.get(class_name, 0)\n",
    "            percentage = (count / overall_total * 100) if overall_total > 0 else 0\n",
    "            print(f\"   {class_name:8}: {count:5,} annotations ({percentage:5.1f}%)\")\n",
    "    \n",
    "    return fold_validation_stats, total_validation_stats\n",
    "\n",
    "# Validate the subsampled k-fold CV dataset\n",
    "fold_validation_stats, total_validation_stats = validate_subsampled_kfold_dataset(TARGET_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8609d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_kfold_comparison_visualizations(fold_stats, fold_sampling_stats, fold_validation_stats, total_stats):\n",
    "    \"\"\"\n",
    "    Create visualizations comparing original vs subsampled k-fold CV datasets\n",
    "    \"\"\"\n",
    "    print(f\"\\nðŸ“Š CREATING K-FOLD COMPARISON VISUALIZATIONS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Aggregate data across all folds\n",
    "    original_counts = [total_stats['class_counts'].get(cls, 0) for cls in CLASS_NAMES]\n",
    "    \n",
    "    # Sum achieved counts across all folds\n",
    "    achieved_counts = [0] * len(CLASS_NAMES)\n",
    "    for fold_idx, stats in fold_sampling_stats.items():\n",
    "        for i, class_name in enumerate(CLASS_NAMES):\n",
    "            achieved_counts[i] += stats['achieved_class_counts'].get(class_name, 0)\n",
    "    \n",
    "    # Sum validation counts across all folds\n",
    "    validation_counts = [total_validation_stats.get(cls, 0) for cls in CLASS_NAMES]\n",
    "    \n",
    "    # Calculate proportions\n",
    "    original_total = sum(original_counts)\n",
    "    achieved_total = sum(achieved_counts)\n",
    "    validation_total = sum(validation_counts)\n",
    "    \n",
    "    original_props = [c/original_total*100 if original_total > 0 else 0 for c in original_counts]\n",
    "    achieved_props = [c/achieved_total*100 if achieved_total > 0 else 0 for c in achieved_counts]\n",
    "    validation_props = [c/validation_total*100 if validation_total > 0 else 0 for c in validation_counts]\n",
    "    \n",
    "    # Create comprehensive comparison plot\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('K-Fold CV Dataset Subsampling Comparison', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Absolute counts comparison\n",
    "    x = np.arange(len(CLASS_NAMES))\n",
    "    width = 0.25\n",
    "    \n",
    "    ax1.bar(x - width, original_counts, width, label='Original', color='skyblue', alpha=0.8)\n",
    "    ax1.bar(x, achieved_counts, width, label='Subsampled', color='orange', alpha=0.8)\n",
    "    ax1.bar(x + width, validation_counts, width, label='Validated', color='lightgreen', alpha=0.8)\n",
    "    \n",
    "    ax1.set_title('Absolute Annotation Counts (All Folds)')\n",
    "    ax1.set_xlabel('Classes')\n",
    "    ax1.set_ylabel('Number of Annotations')\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(CLASS_NAMES, rotation=45)\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, (orig, ach, val) in enumerate(zip(original_counts, achieved_counts, validation_counts)):\n",
    "        ax1.text(i - width, orig + max(original_counts)*0.01, f'{orig}', ha='center', va='bottom', fontsize=8)\n",
    "        ax1.text(i, ach + max(achieved_counts)*0.01, f'{ach}', ha='center', va='bottom', fontsize=8)\n",
    "        ax1.text(i + width, val + max(validation_counts)*0.01, f'{val}', ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    # 2. Percentage distribution comparison\n",
    "    ax2.bar(x - width/2, original_props, width, label='Original (%)', color='skyblue', alpha=0.8)\n",
    "    ax2.bar(x + width/2, achieved_props, width, label='Subsampled (%)', color='orange', alpha=0.8)\n",
    "    \n",
    "    ax2.set_title('Percentage Distribution Comparison (All Folds)')\n",
    "    ax2.set_xlabel('Classes')\n",
    "    ax2.set_ylabel('Percentage (%)')\n",
    "    ax2.set_xticks(x)\n",
    "    ax2.set_xticklabels(CLASS_NAMES, rotation=45)\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Per-fold sampling visualization\n",
    "    fold_indices = list(fold_sampling_stats.keys())\n",
    "    fold_sampling_ratios = [fold_sampling_stats[i]['sampling_ratio'] for i in fold_indices]\n",
    "    \n",
    "    bars = ax3.bar([f'Fold {i}' for i in fold_indices], fold_sampling_ratios, \n",
    "                   color=COLORS[:len(fold_indices)], alpha=0.8)\n",
    "    overall_ratio = achieved_total / original_total if original_total > 0 else 0\n",
    "    ax3.axhline(y=overall_ratio, color='red', linestyle='--', \n",
    "               label=f'Overall Ratio: {overall_ratio:.3f}')\n",
    "    ax3.set_title('Sampling Ratio by Fold')\n",
    "    ax3.set_xlabel('Folds')\n",
    "    ax3.set_ylabel('Sampling Ratio')\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (bar, ratio) in enumerate(zip(bars, fold_sampling_ratios)):\n",
    "        ax3.text(bar.get_x() + bar.get_width()/2, ratio + max(fold_sampling_ratios)*0.01, \n",
    "                f'{ratio:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # 4. Dataset size comparison\n",
    "    original_total_images = total_stats['total_images']\n",
    "    subsampled_total_images = sum(len(stats['selected_images']) for stats in fold_sampling_stats.values())\n",
    "    \n",
    "    # Count validation images across all folds\n",
    "    original_val_images = 0\n",
    "    subsampled_val_images = 0\n",
    "    \n",
    "    for fold_idx in range(NUM_FOLDS):\n",
    "        # Original validation count\n",
    "        orig_fold_dir = SOURCE_DIR / f\"fold_{fold_idx}\" / \"val\" / \"images\"\n",
    "        if orig_fold_dir.exists():\n",
    "            original_val_images += len(list(orig_fold_dir.glob(\"*\")))\n",
    "        \n",
    "        # Subsampled validation count\n",
    "        sub_fold_dir = TARGET_DIR / f\"fold_{fold_idx}\" / \"val\" / \"images\"\n",
    "        if sub_fold_dir.exists():\n",
    "            subsampled_val_images += len(list(sub_fold_dir.glob(\"*\")))\n",
    "    \n",
    "    sizes = ['Original\\nTrain', 'Subsampled\\nTrain', 'Original\\nVal', 'Subsampled\\nVal']\n",
    "    counts = [original_total_images, subsampled_total_images, original_val_images, subsampled_val_images]\n",
    "    \n",
    "    colors_size = ['skyblue', 'orange', 'lightblue', 'moccasin']\n",
    "    bars = ax4.bar(sizes, counts, color=colors_size, alpha=0.8)\n",
    "    ax4.set_title('Dataset Size Comparison (All Folds)')\n",
    "    ax4.set_ylabel('Number of Images')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, count in zip(bars, counts):\n",
    "        ax4.text(bar.get_x() + bar.get_width()/2, count + max(counts)*0.01, \n",
    "                f'{count:,}', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Per-fold detailed comparison\n",
    "    if len(fold_indices) > 1:\n",
    "        fig, axes = plt.subplots(1, len(fold_indices), figsize=(4*len(fold_indices), 6))\n",
    "        if len(fold_indices) == 1:\n",
    "            axes = [axes]\n",
    "        \n",
    "        fig.suptitle('Class Distribution Comparison by Fold', fontsize=14, fontweight='bold')\n",
    "        \n",
    "        for idx, fold_idx in enumerate(fold_indices):\n",
    "            # Original vs achieved for this fold\n",
    "            fold_original = [fold_stats[fold_idx]['class_counts'].get(cls, 0) for cls in CLASS_NAMES]\n",
    "            fold_achieved = [fold_sampling_stats[fold_idx]['achieved_class_counts'].get(cls, 0) for cls in CLASS_NAMES]\n",
    "            \n",
    "            x_fold = np.arange(len(CLASS_NAMES))\n",
    "            width_fold = 0.35\n",
    "            \n",
    "            axes[idx].bar(x_fold - width_fold/2, fold_original, width_fold, \n",
    "                         label='Original', color='skyblue', alpha=0.8)\n",
    "            axes[idx].bar(x_fold + width_fold/2, fold_achieved, width_fold, \n",
    "                         label='Subsampled', color='orange', alpha=0.8)\n",
    "            \n",
    "            axes[idx].set_title(f'Fold {fold_idx}')\n",
    "            axes[idx].set_xlabel('Classes')\n",
    "            if idx == 0:\n",
    "                axes[idx].set_ylabel('Annotations')\n",
    "            axes[idx].set_xticks(x_fold)\n",
    "            axes[idx].set_xticklabels([cls[:4] for cls in CLASS_NAMES], rotation=45)\n",
    "            if idx == 0:\n",
    "                axes[idx].legend()\n",
    "            axes[idx].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(f\"\\nðŸ“ˆ K-FOLD SUBSAMPLING SUMMARY\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Original training images (all folds): {original_total_images:,}\")\n",
    "    print(f\"Subsampled training images (all folds): {subsampled_total_images:,}\")\n",
    "    print(f\"Overall sampling ratio: {overall_ratio:.1%}\")\n",
    "    print(f\"Target size achieved: {subsampled_total_images/(TARGET_TRAIN_SIZE_PER_FOLD * NUM_FOLDS):.1%}\")\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ Class Distribution Preservation (Overall):\")\n",
    "    for i, class_name in enumerate(CLASS_NAMES):\n",
    "        original_pct = original_props[i]\n",
    "        achieved_pct = achieved_props[i]\n",
    "        difference = abs(achieved_pct - original_pct)\n",
    "        print(f\"   {class_name:8}: {original_pct:5.1f}% â†’ {achieved_pct:5.1f}% (Î”{difference:4.1f}%)\")\n",
    "    \n",
    "    avg_difference = np.mean([abs(a-o) for a, o in zip(achieved_props, original_props)])\n",
    "    print(f\"\\nAverage distribution difference: {avg_difference:.2f}%\")\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Per-fold statistics:\")\n",
    "    for fold_idx in fold_indices:\n",
    "        fold_ratio = fold_sampling_stats[fold_idx]['sampling_ratio']\n",
    "        fold_images = len(fold_sampling_stats[fold_idx]['selected_images'])\n",
    "        print(f\"   Fold {fold_idx}: {fold_images:3d} images (ratio: {fold_ratio:.3f})\")\n",
    "    \n",
    "    return {\n",
    "        'original_props': original_props,\n",
    "        'achieved_props': achieved_props,\n",
    "        'overall_ratio': overall_ratio,\n",
    "        'avg_difference': avg_difference,\n",
    "        'fold_ratios': {i: fold_sampling_stats[i]['sampling_ratio'] for i in fold_indices}\n",
    "    }\n",
    "\n",
    "# Create comparison visualizations\n",
    "comparison_stats = create_kfold_comparison_visualizations(\n",
    "    fold_stats, fold_sampling_stats, fold_validation_stats, total_stats\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
