{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6c60ee4",
   "metadata": {},
   "source": [
    "# Object Bank Generation for Synthetic Data\n",
    "\n",
    "Object bank generation by extracting objects from the TACO dataset (`datasets/taco_official`). The object bank will be saved to `datasets/object_bank_for_balancing` and can be used by `roboflow_augmentation.ipynb` for synthetic data generation and dataset balancing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba7a791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import yaml\n",
    "from PIL import Image, ImageDraw\n",
    "import random\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d1899b",
   "metadata": {},
   "source": [
    "## 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9df227",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# --- Paths ---\n",
    "BASE_DIR = Path('')\n",
    "TACO_DIR = BASE_DIR / 'datasets/taco_official'\n",
    "TACO_ANNOTATIONS_PATH = TACO_DIR / 'annotations.json'\n",
    "OBJECT_BANK_DIR = BASE_DIR / 'datasets/object_bank_for_balancing'\n",
    "\n",
    "# --- Object Bank Parameters ---\n",
    "OBJECTS_PER_CLASS_IN_BANK = 300  # Number of objects to extract per class\n",
    "MIN_OBJECT_PIXEL_AREA = 40 * 40  # Minimum area for objects (in pixels)\n",
    "\n",
    "# --- Target Classes (standard waste detection classes) ---\n",
    "TARGET_CLASSES = ['glass', 'metal', 'organic', 'paper', 'plastic']\n",
    "\n",
    "# --- TACO to Target Class Mapping ---\n",
    "# This mapping connects the TACO dataset categories to our target classes.\n",
    "TACO_TO_TARGET_MAPPING = {\n",
    "    # Glass (class 0)\n",
    "    'Glass bottle': 0, 'Glass cup': 0, 'Glass jar': 0, 'Broken glass': 0,\n",
    "    \n",
    "    # Metal (class 1) \n",
    "    'Aluminium foil': 1, 'Aluminium blister pack': 1, 'Drink can': 1, \n",
    "    'Food Can': 1, 'Pop tab': 1, 'Scrap metal': 1, 'Aerosol': 1, 'Metal lid': 1,\n",
    "    \n",
    "    # Organic (class 2)\n",
    "    'Food waste': 2,\n",
    "    \n",
    "    # Paper (class 3)\n",
    "    'Paper': 3, 'Paper cup': 3, 'Drink carton': 3, 'Normal paper': 3, \n",
    "    'Tissues': 3, 'Wrapping paper': 3, 'Magazine': 3, 'Carded blister pack': 3, \n",
    "    'Other carton': 3, 'Meal carton': 3, 'Pizza box': 3, 'Paper bag': 3,\n",
    "    \n",
    "    # Plastic (class 4)\n",
    "    'Clear plastic bottle': 4, 'Other plastic bottle': 4, 'Plastic bottle cap': 4, \n",
    "    'Other plastic cup': 4, 'Plastic lid': 4, 'Shopping bag': 4, 'Plastic straw': 4, \n",
    "    'Other plastic wrapper': 4, 'Other plastic': 4, 'Styrofoam piece': 4, \n",
    "    'Plastic film': 4, 'Squeezable tube': 4, 'Plastic utensils': 4, \n",
    "    'Tupperware': 4, 'Plastic glooves': 4, 'Lighter': 4,\n",
    "    \n",
    "    # Ignored categories (mapped to -1)\n",
    "    'Unlabeled litter': -1, 'Cigarette': -1, 'Shoe': -1, 'Battery': -1, \n",
    "    'Rope & strings': -1, 'Medical waste': -1,\n",
    "}\n",
    "\n",
    "# Create object bank directory\n",
    "OBJECT_BANK_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"ðŸš€ Object Bank Generation Setup\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"TACO Dataset Directory: {TACO_DIR}\")\n",
    "print(f\"TACO Annotations: {TACO_ANNOTATIONS_PATH}\")\n",
    "print(f\"Object Bank Output: {OBJECT_BANK_DIR}\")\n",
    "print(f\"Target Classes: {TARGET_CLASSES}\")\n",
    "print(f\"Objects per class: {OBJECTS_PER_CLASS_IN_BANK}\")\n",
    "print(f\"Minimum object area: {MIN_OBJECT_PIXEL_AREA} pixels\")\n",
    "\n",
    "# Verify TACO dataset exists\n",
    "if not TACO_DIR.exists():\n",
    "    print(f\"âŒ ERROR: TACO directory not found at {TACO_DIR}\")\n",
    "elif not TACO_ANNOTATIONS_PATH.exists():\n",
    "    print(f\"âŒ ERROR: TACO annotations not found at {TACO_ANNOTATIONS_PATH}\")\n",
    "else:\n",
    "    print(\"âœ… TACO dataset found\")\n",
    "\n",
    "print(f\"\\nTACO category mappings:\")\n",
    "for taco_cat, target_id in sorted(TACO_TO_TARGET_MAPPING.items()):\n",
    "    if target_id != -1:\n",
    "        target_name = TARGET_CLASSES[target_id]\n",
    "        print(f\"  {taco_cat} â†’ {target_name} (ID: {target_id})\")\n",
    "    else:\n",
    "        print(f\"  {taco_cat} â†’ IGNORED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a7840d",
   "metadata": {},
   "source": [
    "## 2. TACO Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b38f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_taco_dataset():\n",
    "    \"\"\"Analyze the TACO dataset to understand available categories and annotations.\"\"\"\n",
    "    print(\"ðŸ” ANALYZING TACO DATASET\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if not TACO_ANNOTATIONS_PATH.exists():\n",
    "        print(f\"âŒ ERROR: Annotations file not found at {TACO_ANNOTATIONS_PATH}\")\n",
    "        return None, None\n",
    "    \n",
    "    print(\"Loading TACO annotations...\")\n",
    "    with open(TACO_ANNOTATIONS_PATH, 'r') as f:\n",
    "        taco_data = json.load(f)\n",
    "    \n",
    "    print(f\"âœ… Loaded TACO dataset:\")\n",
    "    print(f\"  - Images: {len(taco_data['images']):,}\")\n",
    "    print(f\"  - Annotations: {len(taco_data['annotations']):,}\")\n",
    "    print(f\"  - Categories: {len(taco_data['categories'])}\")\n",
    "    \n",
    "    # Create category lookup\n",
    "    categories_info = {cat['id']: cat for cat in taco_data['categories']}\n",
    "    \n",
    "    print(f\"\\nðŸ“Š TACO Categories:\")\n",
    "    category_stats = {}\n",
    "    for cat_id, cat_info in categories_info.items():\n",
    "        supercategory = cat_info['supercategory']\n",
    "        name = cat_info['name']\n",
    "        target_class_id = TACO_TO_TARGET_MAPPING.get(supercategory, -1)\n",
    "        target_name = TARGET_CLASSES[target_class_id] if target_class_id != -1 else \"IGNORED\"\n",
    "        \n",
    "        print(f\"  {name} ({supercategory}) â†’ {target_name}\")\n",
    "        \n",
    "        if target_class_id != -1:\n",
    "            if target_class_id not in category_stats:\n",
    "                category_stats[target_class_id] = []\n",
    "            category_stats[target_class_id].append({\n",
    "                'id': cat_id,\n",
    "                'name': name,\n",
    "                'supercategory': supercategory\n",
    "            })\n",
    "    \n",
    "    # Count annotations per target class\n",
    "    print(f\"\\nðŸ“ˆ Annotations per target class:\")\n",
    "    target_class_counts = defaultdict(int)\n",
    "    valid_annotations = []\n",
    "    \n",
    "    for ann in taco_data['annotations']:\n",
    "        cat_id = ann.get('category_id')\n",
    "        if cat_id in categories_info:\n",
    "            supercategory = categories_info[cat_id]['supercategory']\n",
    "            target_class_id = TACO_TO_TARGET_MAPPING.get(supercategory, -1)\n",
    "            \n",
    "            if target_class_id != -1 and ann.get('area', 0) >= MIN_OBJECT_PIXEL_AREA:\n",
    "                target_class_counts[target_class_id] += 1\n",
    "                valid_annotations.append(ann)\n",
    "    \n",
    "    for class_id, class_name in enumerate(TARGET_CLASSES):\n",
    "        count = target_class_counts.get(class_id, 0)\n",
    "        print(f\"  {class_name} (ID {class_id}): {count:,} valid annotations\")\n",
    "    \n",
    "    total_valid = len(valid_annotations)\n",
    "    total_annotations = len(taco_data['annotations'])\n",
    "    print(f\"\\nValid annotations (area >= {MIN_OBJECT_PIXEL_AREA} pixels): {total_valid:,} / {total_annotations:,} ({total_valid/total_annotations*100:.1f}%)\")\n",
    "    \n",
    "    # Create visualization\n",
    "    if target_class_counts:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # Bar chart of annotations per class\n",
    "        classes = [TARGET_CLASSES[i] for i in sorted(target_class_counts.keys())]\n",
    "        counts = [target_class_counts[i] for i in sorted(target_class_counts.keys())]\n",
    "        \n",
    "        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7'][:len(classes)]\n",
    "        bars = ax1.bar(classes, counts, color=colors, alpha=0.8)\n",
    "        ax1.set_title('Valid TACO Annotations per Target Class')\n",
    "        ax1.set_xlabel('Target Class')\n",
    "        ax1.set_ylabel('Number of Annotations')\n",
    "        ax1.tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, count in zip(bars, counts):\n",
    "            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(counts)*0.01, \n",
    "                    f'{count:,}', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        # Pie chart of class distribution\n",
    "        ax2.pie(counts, labels=classes, colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "        ax2.set_title('Distribution of Valid Annotations')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return taco_data, categories_info\n",
    "\n",
    "# Run TACO analysis\n",
    "taco_data, categories_info = analyze_taco_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e945cec8",
   "metadata": {},
   "source": [
    "## 3. Object Extraction and Bank Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c452edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_image_path(image_info, taco_dir):\n",
    "    \"\"\"Finds the full path of a TACO image, searching in batch folders.\"\"\"\n",
    "    img_filename = image_info['file_name']\n",
    "    \n",
    "    # First, check if the filename is already a relative path that exists\n",
    "    path1 = taco_dir / img_filename\n",
    "    if path1.exists():\n",
    "        return path1\n",
    "\n",
    "    # If not, search inside batch_* subdirectories, which is the standard TACO structure\n",
    "    if '/' not in str(img_filename) and '\\\\' not in str(img_filename):\n",
    "        for d in os.listdir(taco_dir):\n",
    "            if d.startswith('batch_') and os.path.isdir(taco_dir / d):\n",
    "                path2 = taco_dir / d / img_filename\n",
    "                if path2.exists():\n",
    "                    return path2\n",
    "    return None\n",
    "\n",
    "def extract_object(image, segmentation):\n",
    "    \"\"\"Extracts an object from an image using its segmentation mask, returning an RGBA image.\"\"\"\n",
    "    img_h, img_w = image.shape[:2]\n",
    "    \n",
    "    mask = np.zeros((img_h, img_w), dtype=np.uint8)\n",
    "    for poly in segmentation:\n",
    "        if len(poly) < 6: continue\n",
    "        pts = np.array(poly, np.int32).reshape((-1, 2))\n",
    "        cv2.fillPoly(mask, [pts], 1)\n",
    "\n",
    "    if np.sum(mask) == 0:\n",
    "        return None\n",
    "\n",
    "    # Find bounding box of the mask to crop\n",
    "    y_indices, x_indices = np.where(mask)\n",
    "    if len(y_indices) == 0 or len(x_indices) == 0:\n",
    "        return None\n",
    "        \n",
    "    y_min, y_max = y_indices.min(), y_indices.max()\n",
    "    x_min, x_max = x_indices.min(), x_indices.max()\n",
    "\n",
    "    # Ensure we have a valid bounding box\n",
    "    if y_max <= y_min or x_max <= x_min:\n",
    "        return None\n",
    "\n",
    "    # Crop image and mask\n",
    "    cropped_img_bgr = image[y_min:y_max+1, x_min:x_max+1]\n",
    "    cropped_mask = mask[y_min:y_max+1, x_min:x_max+1]\n",
    "\n",
    "    # Create 4-channel RGBA image\n",
    "    rgba_object = cv2.cvtColor(cropped_img_bgr, cv2.COLOR_BGR2RGBA)\n",
    "    rgba_object[:, :, 3] = cropped_mask * 255  # Apply mask to alpha channel\n",
    "    \n",
    "    return Image.fromarray(rgba_object)\n",
    "\n",
    "def create_object_bank():\n",
    "    \"\"\"Creates the object bank by extracting objects from the TACO dataset.\"\"\"\n",
    "    print(\"\\nðŸŒŸ STARTING OBJECT BANK CREATION\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    if taco_data is None or categories_info is None:\n",
    "        print(\"âŒ ERROR: TACO data not loaded. Please run the analysis first.\")\n",
    "        return False\n",
    "    \n",
    "    print(f\"ðŸ“Š Processing {len(taco_data['annotations'])} total annotations...\")\n",
    "    \n",
    "    images_info = {img['id']: img for img in taco_data['images']}\n",
    "    \n",
    "    # Group annotations by our target classes\n",
    "    class_annotations = defaultdict(list)\n",
    "    print(\"ðŸ” Filtering annotations based on mapping and area...\")\n",
    "    \n",
    "    for ann in tqdm(taco_data['annotations'], desc=\"Filtering annotations\"):\n",
    "        cat_id = ann.get('category_id')\n",
    "        if cat_id in categories_info:\n",
    "            supercategory = categories_info[cat_id]['supercategory']\n",
    "            target_class_id = TACO_TO_TARGET_MAPPING.get(supercategory, -1)\n",
    "            \n",
    "            if target_class_id != -1 and ann.get('area', 0) >= MIN_OBJECT_PIXEL_AREA:\n",
    "                class_annotations[target_class_id].append(ann)\n",
    "    \n",
    "    print(f\"âœ… Found matching annotations:\")\n",
    "    for class_id in range(len(TARGET_CLASSES)):\n",
    "        count = len(class_annotations.get(class_id, []))\n",
    "        print(f\"  {TARGET_CLASSES[class_id]}: {count:,} annotations\")\n",
    "    \n",
    "    if not class_annotations:\n",
    "        print(\"âŒ ERROR: No annotations matched the filter criteria.\")\n",
    "        return False\n",
    "\n",
    "    # Create class directories in object bank\n",
    "    print(f\"\\nðŸ“ Creating class directories...\")\n",
    "    for class_name in TARGET_CLASSES:\n",
    "        class_dir = OBJECT_BANK_DIR / class_name\n",
    "        class_dir.mkdir(exist_ok=True)\n",
    "        print(f\"  Created: {class_dir}\")\n",
    "\n",
    "    # Extract and save objects\n",
    "    print(f\"\\nðŸŽ¨ EXTRACTING OBJECTS\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    total_extracted_count = 0\n",
    "    extraction_stats = {}\n",
    "    \n",
    "    for class_id, class_name in enumerate(TARGET_CLASSES):\n",
    "        print(f\"\\nðŸ”„ Processing class: {class_name}\")\n",
    "        \n",
    "        annotations_for_class = class_annotations.get(class_id, [])\n",
    "        if not annotations_for_class:\n",
    "            print(f\"  âš ï¸ No annotations found for {class_name}\")\n",
    "            extraction_stats[class_name] = {\n",
    "                'extracted': 0,\n",
    "                'attempted': 0,\n",
    "                'img_not_found': 0,\n",
    "                'extraction_failed': 0\n",
    "            }\n",
    "            continue\n",
    "        \n",
    "        # Shuffle annotations for better variety\n",
    "        random.shuffle(annotations_for_class)\n",
    "        \n",
    "        object_count = 0\n",
    "        img_not_found_count = 0\n",
    "        extraction_failed_count = 0\n",
    "        attempted_count = 0\n",
    "        \n",
    "        target_count = min(len(annotations_for_class), OBJECTS_PER_CLASS_IN_BANK)\n",
    "        pbar = tqdm(total=target_count, desc=f\"Extracting {class_name}\")\n",
    "        \n",
    "        for ann in annotations_for_class:\n",
    "            if object_count >= OBJECTS_PER_CLASS_IN_BANK:\n",
    "                break\n",
    "                \n",
    "            attempted_count += 1\n",
    "            img_info = images_info.get(ann['image_id'])\n",
    "            if not img_info: \n",
    "                extraction_failed_count += 1\n",
    "                continue\n",
    "            \n",
    "            img_path = find_image_path(img_info, TACO_DIR)\n",
    "            if not img_path:\n",
    "                img_not_found_count += 1\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                image = cv2.imread(str(img_path))\n",
    "                if image is None:\n",
    "                    extraction_failed_count += 1\n",
    "                    continue\n",
    "            except Exception:\n",
    "                extraction_failed_count += 1\n",
    "                continue\n",
    "\n",
    "            extracted_obj = extract_object(image, ann['segmentation'])\n",
    "            \n",
    "            if extracted_obj is not None:\n",
    "                save_path = OBJECT_BANK_DIR / class_name / f\"{object_count:04d}.png\"\n",
    "                try:\n",
    "                    extracted_obj.save(save_path)\n",
    "                    object_count += 1\n",
    "                    total_extracted_count += 1\n",
    "                    pbar.update(1)\n",
    "                except Exception as e:\n",
    "                    extraction_failed_count += 1\n",
    "                    print(f\"    âš ï¸ Failed to save {save_path}: {e}\")\n",
    "            else:\n",
    "                extraction_failed_count += 1\n",
    "\n",
    "        pbar.close()\n",
    "        \n",
    "        # Store statistics\n",
    "        extraction_stats[class_name] = {\n",
    "            'extracted': object_count,\n",
    "            'attempted': attempted_count,\n",
    "            'img_not_found': img_not_found_count,\n",
    "            'extraction_failed': extraction_failed_count\n",
    "        }\n",
    "        \n",
    "        print(f\"  âœ… Extracted: {object_count}/{target_count} objects\")\n",
    "        if img_not_found_count > 0:\n",
    "            print(f\"  âš ï¸ Images not found: {img_not_found_count}\")\n",
    "        if extraction_failed_count > 0:\n",
    "            print(f\"  âš ï¸ Extraction failures: {extraction_failed_count}\")\n",
    "\n",
    "    # Final summary\n",
    "    print(f\"\\nðŸŽ‰ OBJECT BANK CREATION COMPLETE\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Total objects extracted: {total_extracted_count:,}\")\n",
    "    print(f\"Object bank location: {OBJECT_BANK_DIR}\")\n",
    "    \n",
    "    # Create summary visualization\n",
    "    if extraction_stats:\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # Extracted objects per class\n",
    "        classes = list(extraction_stats.keys())\n",
    "        extracted_counts = [stats['extracted'] for stats in extraction_stats.values()]\n",
    "        target_counts = [OBJECTS_PER_CLASS_IN_BANK] * len(classes)\n",
    "        \n",
    "        x = np.arange(len(classes))\n",
    "        width = 0.35\n",
    "        \n",
    "        bars1 = ax1.bar(x - width/2, extracted_counts, width, label='Extracted', alpha=0.8, color='green')\n",
    "        bars2 = ax1.bar(x + width/2, target_counts, width, label='Target', alpha=0.6, color='lightgray')\n",
    "        \n",
    "        ax1.set_title('Objects Extracted per Class')\n",
    "        ax1.set_xlabel('Class')\n",
    "        ax1.set_ylabel('Number of Objects')\n",
    "        ax1.set_xticks(x)\n",
    "        ax1.set_xticklabels(classes, rotation=45)\n",
    "        ax1.legend()\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar, count in zip(bars1, extracted_counts):\n",
    "            ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(extracted_counts)*0.01, \n",
    "                    f'{count}', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        # Success rate per class\n",
    "        success_rates = []\n",
    "        for stats in extraction_stats.values():\n",
    "            attempted = stats['attempted']\n",
    "            extracted = stats['extracted']\n",
    "            rate = (extracted / attempted * 100) if attempted > 0 else 0\n",
    "            success_rates.append(rate)\n",
    "        \n",
    "        bars3 = ax2.bar(classes, success_rates, alpha=0.8, color='orange')\n",
    "        ax2.set_title('Extraction Success Rate')\n",
    "        ax2.set_xlabel('Class')\n",
    "        ax2.set_ylabel('Success Rate (%)')\n",
    "        ax2.tick_params(axis='x', rotation=45)\n",
    "        ax2.set_ylim(0, 100)\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar, rate in zip(bars3, success_rates):\n",
    "            ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2, \n",
    "                    f'{rate:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    if total_extracted_count == 0:\n",
    "        print(\"âŒ ERROR: No objects were extracted. Please check the configuration and TACO dataset.\")\n",
    "        return False\n",
    "    \n",
    "    print(\"âœ… Object bank creation successful!\")\n",
    "    return True\n",
    "\n",
    "# Create the object bank\n",
    "if taco_data is not None:\n",
    "    success = create_object_bank()\n",
    "else:\n",
    "    print(\"âŒ Cannot create object bank: TACO data not loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f604ff",
   "metadata": {},
   "source": [
    "## 4. Object Bank Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5ab576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_object_bank():\n",
    "    \"\"\"Verifies the created object bank and shows statistics.\"\"\"\n",
    "    print(\"ðŸ” VERIFYING OBJECT BANK\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if not OBJECT_BANK_DIR.exists():\n",
    "        print(f\"âŒ Object bank directory not found: {OBJECT_BANK_DIR}\")\n",
    "        return False\n",
    "    \n",
    "    bank_stats = {}\n",
    "    total_objects = 0\n",
    "    \n",
    "    print(\"ðŸ“Š Object bank contents:\")\n",
    "    for class_name in TARGET_CLASSES:\n",
    "        class_dir = OBJECT_BANK_DIR / class_name\n",
    "        if class_dir.exists():\n",
    "            objects = list(class_dir.glob('*.png'))\n",
    "            count = len(objects)\n",
    "            bank_stats[class_name] = {\n",
    "                'count': count,\n",
    "                'objects': objects[:10]  # Store first 10 for visualization\n",
    "            }\n",
    "            total_objects += count\n",
    "            status = \"âœ…\" if count > 0 else \"âš ï¸\"\n",
    "            print(f\"  {status} {class_name}: {count:,} objects\")\n",
    "        else:\n",
    "            bank_stats[class_name] = {'count': 0, 'objects': []}\n",
    "            print(f\"  âŒ {class_name}: directory not found\")\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ Total objects in bank: {total_objects:,}\")\n",
    "    \n",
    "    if total_objects == 0:\n",
    "        print(\"âŒ Object bank is empty!\")\n",
    "        return False\n",
    "    \n",
    "    # Calculate statistics\n",
    "    counts = [stats['count'] for stats in bank_stats.values()]\n",
    "    avg_per_class = np.mean(counts)\n",
    "    min_count = min(counts)\n",
    "    max_count = max(counts)\n",
    "    \n",
    "    print(f\"ðŸ“Š Statistics:\")\n",
    "    print(f\"  Average per class: {avg_per_class:.1f}\")\n",
    "    print(f\"  Minimum per class: {min_count}\")\n",
    "    print(f\"  Maximum per class: {max_count}\")\n",
    "    print(f\"  Balance ratio: {min_count/max_count:.2f}\" if max_count > 0 else \"  Balance ratio: 0.00\")\n",
    "    \n",
    "    # Create visualization\n",
    "    if any(counts):\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        fig.suptitle('Object Bank Verification', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # 1. Object counts bar chart\n",
    "        colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7']\n",
    "        bars = axes[0,0].bar(TARGET_CLASSES, counts, color=colors, alpha=0.8)\n",
    "        axes[0,0].set_title('Objects per Class')\n",
    "        axes[0,0].set_ylabel('Number of Objects')\n",
    "        axes[0,0].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar, count in zip(bars, counts):\n",
    "            axes[0,0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(counts)*0.01, \n",
    "                          f'{count}', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        # Add target line\n",
    "        axes[0,0].axhline(y=OBJECTS_PER_CLASS_IN_BANK, color='red', linestyle='--', \n",
    "                         label=f'Target: {OBJECTS_PER_CLASS_IN_BANK}')\n",
    "        axes[0,0].legend()\n",
    "        \n",
    "        # 2. Pie chart of distribution\n",
    "        axes[0,1].pie(counts, labels=TARGET_CLASSES, colors=colors, autopct='%1.1f%%', \n",
    "                     startangle=90)\n",
    "        axes[0,1].set_title('Class Distribution')\n",
    "        \n",
    "        # 3. Balance analysis\n",
    "        balance_scores = [count/max_count if max_count > 0 else 0 for count in counts]\n",
    "        bars2 = axes[0,2].bar(TARGET_CLASSES, balance_scores, color=colors, alpha=0.8)\n",
    "        axes[0,2].set_title('Class Balance Score')\n",
    "        axes[0,2].set_ylabel('Balance Score (0-1)')\n",
    "        axes[0,2].tick_params(axis='x', rotation=45)\n",
    "        axes[0,2].set_ylim(0, 1)\n",
    "        \n",
    "        # Add value labels\n",
    "        for bar, score in zip(bars2, balance_scores):\n",
    "            axes[0,2].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, \n",
    "                          f'{score:.2f}', ha='center', va='bottom', fontweight='bold')\n",
    "        \n",
    "        # 4-6. Sample objects from each class (show first 3 classes)\n",
    "        for idx, class_name in enumerate(TARGET_CLASSES[:3]):\n",
    "            ax = axes[1, idx]\n",
    "            objects = bank_stats[class_name]['objects']\n",
    "            \n",
    "            if objects:\n",
    "                # Create a grid of sample objects\n",
    "                sample_objects = objects[:9]  # Show up to 9 objects\n",
    "                grid_size = int(np.ceil(np.sqrt(len(sample_objects))))\n",
    "                \n",
    "                # Create composite image\n",
    "                if sample_objects:\n",
    "                    # Load and resize sample objects\n",
    "                    sample_imgs = []\n",
    "                    for obj_path in sample_objects:\n",
    "                        try:\n",
    "                            img = Image.open(obj_path)\n",
    "                            img.thumbnail((64, 64), Image.Resampling.LANCZOS)\n",
    "                            sample_imgs.append(np.array(img))\n",
    "                        except:\n",
    "                            continue\n",
    "                    \n",
    "                    if sample_imgs:\n",
    "                        # Create grid\n",
    "                        rows = []\n",
    "                        for i in range(0, len(sample_imgs), grid_size):\n",
    "                            row_imgs = sample_imgs[i:i+grid_size]\n",
    "                            # Pad row if needed\n",
    "                            while len(row_imgs) < grid_size:\n",
    "                                row_imgs.append(np.zeros_like(sample_imgs[0]) if sample_imgs else np.zeros((64,64,4), dtype=np.uint8))\n",
    "                            \n",
    "                            # Concatenate horizontally\n",
    "                            row = np.concatenate(row_imgs, axis=1)\n",
    "                            rows.append(row)\n",
    "                        \n",
    "                        if rows:\n",
    "                            # Concatenate vertically\n",
    "                            grid = np.concatenate(rows, axis=0)\n",
    "                            ax.imshow(grid)\n",
    "                            ax.set_title(f'{class_name.title()} Samples\\n({bank_stats[class_name][\"count\"]} objects)')\n",
    "                        else:\n",
    "                            ax.text(0.5, 0.5, f'No valid\\n{class_name} objects', \n",
    "                                   ha='center', va='center', transform=ax.transAxes)\n",
    "                            ax.set_title(f'{class_name.title()}\\n(0 objects)')\n",
    "                    else:\n",
    "                        ax.text(0.5, 0.5, f'Cannot load\\n{class_name} objects', \n",
    "                               ha='center', va='center', transform=ax.transAxes)\n",
    "                        ax.set_title(f'{class_name.title()}\\n({bank_stats[class_name][\"count\"]} objects)')\n",
    "                else:\n",
    "                    ax.text(0.5, 0.5, f'No {class_name}\\nobjects found', \n",
    "                           ha='center', va='center', transform=ax.transAxes)\n",
    "                    ax.set_title(f'{class_name.title()}\\n(0 objects)')\n",
    "            else:\n",
    "                ax.text(0.5, 0.5, f'No {class_name}\\nobjects', \n",
    "                       ha='center', va='center', transform=ax.transAxes)\n",
    "                ax.set_title(f'{class_name.title()}\\n(0 objects)')\n",
    "            \n",
    "            ax.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Quality assessment\n",
    "    if min_count >= OBJECTS_PER_CLASS_IN_BANK * 0.8:\n",
    "        print(\"âœ… EXCELLENT: Object bank is well-populated across all classes!\")\n",
    "    elif min_count >= OBJECTS_PER_CLASS_IN_BANK * 0.5:\n",
    "        print(\"âš ï¸  GOOD: Object bank has reasonable coverage, but some classes are under-represented.\")\n",
    "    elif total_objects > 0:\n",
    "        print(\"âš ï¸  FAIR: Object bank exists but has significant imbalances.\")\n",
    "    else:\n",
    "        print(\"âŒ POOR: Object bank is empty or severely lacking.\")\n",
    "    \n",
    "    return total_objects > 0\n",
    "\n",
    "# Verify the object bank\n",
    "verification_success = verify_object_bank()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
